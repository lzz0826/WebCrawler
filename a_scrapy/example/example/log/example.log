2025-01-16 18:05:09 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: example)
2025-01-16 18:05:09 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.11.0, Python 3.9.6 (default, May  7 2023, 23:32:44) - [Clang 14.0.3 (clang-1403.0.22.14.1)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform macOS-13.2.1-arm64-arm-64bit
2025-01-16 18:05:09 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-16 18:05:09 [asyncio] DEBUG: Using selector: KqueueSelector
2025-01-16 18:05:09 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-16 18:05:09 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-16 18:05:09 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-16 18:05:09 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-16 18:05:09 [scrapy.extensions.telnet] INFO: Telnet Password: 5c66f58255fe13e8
2025-01-16 18:05:09 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-16 18:05:09 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'example',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': '../log/example.log',
 'NEWSPIDER_MODULE': 'example.spiders',
 'SPIDER_MODULES': ['example.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-16 18:05:10 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63030/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"extensions": [], "args": ["--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"extensions": [], "args": ["--headless"]}}}
2025-01-16 18:05:10 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:63030
2025-01-16 18:05:10 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63030 "POST /session HTTP/1.1" 200 892
2025-01-16 18:05:10 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:05:10 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy_selenium.SeleniumMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-16 18:05:10 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-16 18:05:10 [scrapy.middleware] INFO: Enabled item pipelines:
['example.pipelines.ExamplePipeline', 'example.pipelines.ExampleDownloadImg']
2025-01-16 18:05:10 [scrapy.core.engine] INFO: Spider opened
2025-01-16 18:05:10 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-16 18:05:10 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-01-16 18:05:10 [scrapy.core.engine] DEBUG: Crawled (200) <POST https://fanyi.baidu.com/sug> (referer: None)
2025-01-16 18:05:10 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-16 18:05:10 [selenium.webdriver.remote.remote_connection] DEBUG: DELETE http://127.0.0.1:63030/session/af03ad15e1aff806054a6491d26785ea {}
2025-01-16 18:05:10 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63030 "DELETE /session/af03ad15e1aff806054a6491d26785ea HTTP/1.1" 200 14
2025-01-16 18:05:10 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:05:11 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 359,
 'downloader/request_count': 1,
 'downloader/request_method_count/POST': 1,
 'downloader/response_bytes': 881,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.404183,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 16, 10, 5, 10, 930166, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 530,
 'httpcompression/response_count': 1,
 'items_per_minute': None,
 'log_count/DEBUG': 13,
 'log_count/INFO': 10,
 'memusage/max': 60276736,
 'memusage/startup': 60276736,
 'response_received_count': 1,
 'responses_per_minute': None,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2025, 1, 16, 10, 5, 10, 525983, tzinfo=datetime.timezone.utc)}
2025-01-16 18:05:11 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-16 18:05:59 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: example)
2025-01-16 18:05:59 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.11.0, Python 3.9.6 (default, May  7 2023, 23:32:44) - [Clang 14.0.3 (clang-1403.0.22.14.1)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform macOS-13.2.1-arm64-arm-64bit
2025-01-16 18:05:59 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-16 18:05:59 [asyncio] DEBUG: Using selector: KqueueSelector
2025-01-16 18:05:59 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-16 18:05:59 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-16 18:05:59 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-16 18:05:59 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-16 18:05:59 [scrapy.extensions.telnet] INFO: Telnet Password: 8cb72d4974784e65
2025-01-16 18:05:59 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-16 18:05:59 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'example',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': '../log/example.log',
 'NEWSPIDER_MODULE': 'example.spiders',
 'SPIDER_MODULES': ['example.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-16 18:06:00 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63256/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"extensions": [], "args": ["--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"extensions": [], "args": ["--headless"]}}}
2025-01-16 18:06:00 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:63256
2025-01-16 18:06:00 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63256 "POST /session HTTP/1.1" 200 892
2025-01-16 18:06:00 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:00 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy_selenium.SeleniumMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-16 18:06:00 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-16 18:06:00 [scrapy.middleware] INFO: Enabled item pipelines:
['example.pipelines.ExamplePipeline', 'example.pipelines.ExampleDownloadImg']
2025-01-16 18:06:00 [scrapy.core.engine] INFO: Spider opened
2025-01-16 18:06:00 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-16 18:06:00 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-01-16 18:06:00 [scrapy.core.engine] DEBUG: Crawled (200) <POST https://fanyi.baidu.com/sug> (referer: None)
2025-01-16 18:06:01 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-16 18:06:01 [selenium.webdriver.remote.remote_connection] DEBUG: DELETE http://127.0.0.1:63256/session/49805dc75b2b8fe96aba0153300db3e1 {}
2025-01-16 18:06:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63256 "DELETE /session/49805dc75b2b8fe96aba0153300db3e1 HTTP/1.1" 200 14
2025-01-16 18:06:01 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:01 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 359,
 'downloader/request_count': 1,
 'downloader/request_method_count/POST': 1,
 'downloader/response_bytes': 882,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.397878,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 16, 10, 6, 1, 33645, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 530,
 'httpcompression/response_count': 1,
 'items_per_minute': None,
 'log_count/DEBUG': 13,
 'log_count/INFO': 10,
 'memusage/max': 60801024,
 'memusage/startup': 60801024,
 'response_received_count': 1,
 'responses_per_minute': None,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2025, 1, 16, 10, 6, 0, 635767, tzinfo=datetime.timezone.utc)}
2025-01-16 18:06:01 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-16 18:06:48 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: example)
2025-01-16 18:06:48 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.11.0, Python 3.9.6 (default, May  7 2023, 23:32:44) - [Clang 14.0.3 (clang-1403.0.22.14.1)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform macOS-13.2.1-arm64-arm-64bit
2025-01-16 18:06:48 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-16 18:06:48 [asyncio] DEBUG: Using selector: KqueueSelector
2025-01-16 18:06:48 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-16 18:06:48 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-16 18:06:48 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-16 18:06:48 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-16 18:06:48 [scrapy.extensions.telnet] INFO: Telnet Password: 84f0d181dff36ba9
2025-01-16 18:06:48 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-16 18:06:48 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'example',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': '../log/example.log',
 'NEWSPIDER_MODULE': 'example.spiders',
 'SPIDER_MODULES': ['example.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-16 18:06:49 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63481/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"extensions": [], "args": ["--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"extensions": [], "args": ["--headless"]}}}
2025-01-16 18:06:49 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:63481
2025-01-16 18:06:50 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "POST /session HTTP/1.1" 200 892
2025-01-16 18:06:50 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:50 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy_selenium.SeleniumMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-16 18:06:50 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-16 18:06:50 [scrapy.middleware] INFO: Enabled item pipelines:
['example.pipelines.ExamplePipeline', 'example.pipelines.ExampleDownloadImg']
2025-01-16 18:06:50 [scrapy.core.engine] INFO: Spider opened
2025-01-16 18:06:50 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-16 18:06:50 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-01-16 18:06:50 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {"url": "https://forum.gamer.com.tw/B.php?page=1&bsn=18966"}
2025-01-16 18:06:50 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "POST /session/4e850fd1170ee70416590db4df80058e/url HTTP/1.1" 200 14
2025-01-16 18:06:50 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:50 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/source {}
2025-01-16 18:06:50 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "GET /session/4e850fd1170ee70416590db4df80058e/source HTTP/1.1" 200 250876
2025-01-16 18:06:50 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:50 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {}
2025-01-16 18:06:50 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "GET /session/4e850fd1170ee70416590db4df80058e/url HTTP/1.1" 200 61
2025-01-16 18:06:50 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/B.php?page=1&bsn=18966> (referer: None)
2025-01-16 18:06:51 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/execute/sync {"script": "return document.body.scrollHeight", "args": []}
2025-01-16 18:06:51 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "POST /session/4e850fd1170ee70416590db4df80058e/execute/sync HTTP/1.1" 200 14
2025-01-16 18:06:51 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:51 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/execute/sync {"script": "window.scrollTo(0, document.body.scrollHeight);", "args": []}
2025-01-16 18:06:51 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "POST /session/4e850fd1170ee70416590db4df80058e/execute/sync HTTP/1.1" 200 14
2025-01-16 18:06:51 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:53 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/execute/sync {"script": "return document.body.scrollHeight", "args": []}
2025-01-16 18:06:53 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "POST /session/4e850fd1170ee70416590db4df80058e/execute/sync HTTP/1.1" 200 14
2025-01-16 18:06:53 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:53 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/source {}
2025-01-16 18:06:53 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "GET /session/4e850fd1170ee70416590db4df80058e/source HTTP/1.1" 200 252489
2025-01-16 18:06:53 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:53 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {}
2025-01-16 18:06:53 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "GET /session/4e850fd1170ee70416590db4df80058e/url HTTP/1.1" 200 61
2025-01-16 18:06:53 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:53 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139278&tnum=24"}
2025-01-16 18:06:54 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "POST /session/4e850fd1170ee70416590db4df80058e/url HTTP/1.1" 200 14
2025-01-16 18:06:54 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:54 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/source {}
2025-01-16 18:06:54 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "GET /session/4e850fd1170ee70416590db4df80058e/source HTTP/1.1" 200 486506
2025-01-16 18:06:54 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:54 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {}
2025-01-16 18:06:54 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "GET /session/4e850fd1170ee70416590db4df80058e/url HTTP/1.1" 200 73
2025-01-16 18:06:54 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139278&tnum=24> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:06:54 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {"url": "https://forum.gamer.com.tw/B.php?page=2&bsn=18966"}
2025-01-16 18:06:54 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "POST /session/4e850fd1170ee70416590db4df80058e/url HTTP/1.1" 200 14
2025-01-16 18:06:54 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:54 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/source {}
2025-01-16 18:06:54 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "GET /session/4e850fd1170ee70416590db4df80058e/source HTTP/1.1" 200 246793
2025-01-16 18:06:54 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:54 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {}
2025-01-16 18:06:54 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "GET /session/4e850fd1170ee70416590db4df80058e/url HTTP/1.1" 200 61
2025-01-16 18:06:54 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/B.php?page=2&bsn=18966> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:06:54 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=138700&tnum=5"}
2025-01-16 18:06:54 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "POST /session/4e850fd1170ee70416590db4df80058e/url HTTP/1.1" 200 14
2025-01-16 18:06:54 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:54 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/source {}
2025-01-16 18:06:54 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "GET /session/4e850fd1170ee70416590db4df80058e/source HTTP/1.1" 200 215461
2025-01-16 18:06:54 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:54 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {}
2025-01-16 18:06:55 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "GET /session/4e850fd1170ee70416590db4df80058e/url HTTP/1.1" 200 72
2025-01-16 18:06:55 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=138700&tnum=5> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:06:55 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139274&tnum=3"}
2025-01-16 18:06:55 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "POST /session/4e850fd1170ee70416590db4df80058e/url HTTP/1.1" 200 14
2025-01-16 18:06:55 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:55 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/source {}
2025-01-16 18:06:55 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "GET /session/4e850fd1170ee70416590db4df80058e/source HTTP/1.1" 200 163851
2025-01-16 18:06:55 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:55 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {}
2025-01-16 18:06:55 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "GET /session/4e850fd1170ee70416590db4df80058e/url HTTP/1.1" 200 72
2025-01-16 18:06:55 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139274&tnum=3> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:06:55 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139275&tnum=1"}
2025-01-16 18:06:55 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "POST /session/4e850fd1170ee70416590db4df80058e/url HTTP/1.1" 200 14
2025-01-16 18:06:55 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:55 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/source {}
2025-01-16 18:06:55 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "GET /session/4e850fd1170ee70416590db4df80058e/source HTTP/1.1" 200 139596
2025-01-16 18:06:55 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:55 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {}
2025-01-16 18:06:55 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "GET /session/4e850fd1170ee70416590db4df80058e/url HTTP/1.1" 200 72
2025-01-16 18:06:55 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139275&tnum=1> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:06:55 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139231&tnum=11"}
2025-01-16 18:06:56 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "POST /session/4e850fd1170ee70416590db4df80058e/url HTTP/1.1" 200 14
2025-01-16 18:06:56 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:56 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/source {}
2025-01-16 18:06:56 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "GET /session/4e850fd1170ee70416590db4df80058e/source HTTP/1.1" 200 264412
2025-01-16 18:06:56 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:56 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {}
2025-01-16 18:06:56 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "GET /session/4e850fd1170ee70416590db4df80058e/url HTTP/1.1" 200 73
2025-01-16 18:06:56 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139231&tnum=11> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:06:56 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=138616&tnum=5"}
2025-01-16 18:06:57 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "POST /session/4e850fd1170ee70416590db4df80058e/url HTTP/1.1" 200 14
2025-01-16 18:06:57 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:57 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/source {}
2025-01-16 18:06:57 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "GET /session/4e850fd1170ee70416590db4df80058e/source HTTP/1.1" 200 215143
2025-01-16 18:06:57 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:57 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {}
2025-01-16 18:06:57 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "GET /session/4e850fd1170ee70416590db4df80058e/url HTTP/1.1" 200 72
2025-01-16 18:06:57 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=138616&tnum=5> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:06:57 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=138913&tnum=16"}
2025-01-16 18:06:57 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "POST /session/4e850fd1170ee70416590db4df80058e/url HTTP/1.1" 200 14
2025-01-16 18:06:57 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:57 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/source {}
2025-01-16 18:06:57 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "GET /session/4e850fd1170ee70416590db4df80058e/source HTTP/1.1" 200 365850
2025-01-16 18:06:57 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:57 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {}
2025-01-16 18:06:57 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "GET /session/4e850fd1170ee70416590db4df80058e/url HTTP/1.1" 200 73
2025-01-16 18:06:57 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=138913&tnum=16> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:06:57 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139276&tnum=1"}
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "POST /session/4e850fd1170ee70416590db4df80058e/url HTTP/1.1" 200 14
2025-01-16 18:06:58 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:58 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/source {}
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "GET /session/4e850fd1170ee70416590db4df80058e/source HTTP/1.1" 200 149404
2025-01-16 18:06:58 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:58 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {}
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "GET /session/4e850fd1170ee70416590db4df80058e/url HTTP/1.1" 200 72
2025-01-16 18:06:58 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139276&tnum=1> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:06:58 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139277&tnum=1"}
2025-01-16 18:06:58 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2025-01-16 18:06:58 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=138031&tnum=19"}
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (2): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x106f72400>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (3): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x106f725b0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (4): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x106f726a0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (5): 127.0.0.1:63481
2025-01-16 18:06:58 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=137397&tnum=37"}
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (6): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x106f7b3d0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (7): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x106f7b580>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (8): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x106f7b670>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (9): 127.0.0.1:63481
2025-01-16 18:06:58 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=138723&tnum=21"}
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (10): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x106f843a0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (11): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x106f84550>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (12): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x106f84640>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (13): 127.0.0.1:63481
2025-01-16 18:06:58 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=138377&tnum=7"}
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (14): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x106f8f370>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (15): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x106f41550>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (16): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x106f8f520>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (17): 127.0.0.1:63481
2025-01-16 18:06:58 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=138161&tnum=9"}
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (18): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x106f9e250>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (19): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x106f9e400>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (20): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x106f9e4f0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (21): 127.0.0.1:63481
2025-01-16 18:06:58 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139281&tnum=1"}
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (22): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x106fac220>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (23): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x106fac3d0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (24): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x106fac4c0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (25): 127.0.0.1:63481
2025-01-16 18:06:58 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=136522&tnum=120"}
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (26): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x106fbc1f0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (27): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x106fbc3a0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (28): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x106fbc490>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (29): 127.0.0.1:63481
2025-01-16 18:06:58 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139282&tnum=1"}
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (30): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108b011c0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (31): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108b01370>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (32): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108b01460>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (33): 127.0.0.1:63481
2025-01-16 18:06:58 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139283&tnum=1"}
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (34): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108b12190>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (35): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108b12340>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (36): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108b12430>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (37): 127.0.0.1:63481
2025-01-16 18:06:58 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139154&tnum=6"}
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (38): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108b21160>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (39): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108b21310>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (40): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108b21400>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (41): 127.0.0.1:63481
2025-01-16 18:06:58 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139171&tnum=24"}
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (42): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108b32130>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (43): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108b322e0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (44): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108b323d0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (45): 127.0.0.1:63481
2025-01-16 18:06:58 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139280&tnum=2"}
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (46): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108b41100>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (47): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108b412b0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (48): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108b413a0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (49): 127.0.0.1:63481
2025-01-16 18:06:58 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139238&tnum=13"}
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (50): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108b510d0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (51): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108b51280>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (52): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108b51370>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (53): 127.0.0.1:63481
2025-01-16 18:06:58 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=136809&tnum=154"}
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (54): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108b63040>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (55): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108b631f0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (56): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108b632e0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (57): 127.0.0.1:63481
2025-01-16 18:06:58 [scrapy.core.engine] INFO: Closing spider (shutdown)
2025-01-16 18:06:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139278&tnum=24>
{'content': 'https://www.pathofexile.com/forum/view-thread/3695606/page/1#p25859331 '
            '預計明天1/17更新 翻譯僅供參考 沒辦法詳細校對 此篇後其他討論串會隱藏處理 終局改動 新增 4 個塔地圖區域：「阿爾卑斯山脊…',
 'img': None,
 'title': '【情報】Poe 2 0.1.1 Patch note 集中討論串',
 'userName': '33456109'}
2025-01-16 18:06:58 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/execute/sync {"script": "return document.body.scrollHeight", "args": []}
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (58): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/execute/sync'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108d053d0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/execute/sync
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (59): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/execute/sync'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108d054f0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/execute/sync
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (60): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/execute/sync'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108d05670>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/execute/sync
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (61): 127.0.0.1:63481
2025-01-16 18:06:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://forum.gamer.com.tw/B.php?page=2&bsn=18966> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x108d057c0>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/utils/defer.py", line 327, in iter_errback
    yield next(it)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 368, in __next__
    return next(self.data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 368, in __next__
    return next(self.data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 379, in <genexpr>
    return (self._set_referer(r, response) for r in result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 57, in <genexpr>
    return (r for r in result if self._filter(r, spider))
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 54, in <genexpr>
    return (r for r in result if self._filter(r, response, spider))
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/Users/admin/PycharmProjects/WebCrawler/a_scrapy/example/example/spiders/game_content.py", line 51, in parse
    last_height = driver.execute_script("return document.body.scrollHeight")
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 634, in execute_script
    return self.execute(command, {
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=63481): Max retries exceeded with url: /session/4e850fd1170ee70416590db4df80058e/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108d057c0>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:06:58 [scrapy.core.scraper] ERROR: Error processing {'content': '一、前言最近想趁 GGG 大刀闊斧之前跟風玩電法，但對於其中感電時施放這個技能有的觸發機制有疑慮，很多 BD '
            '介紹也沒有特別去提，作為第一次玩 POE 的玩家，目前有錄影將感電過…',
 'img': 'https://truth.bahamut.com.tw/s01/202501/forum/18966/8b27d3635e75d203c8db8b2962bd3b11.JPG?w=300&h=300&fit=o',
 'title': '【心得】感電時施放，觸發機制詢問 (已解決，更新：2025/1/15)',
 'userName': '葳葳'}
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/utils/defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/Users/admin/PycharmProjects/WebCrawler/a_scrapy/example/example/pipelines.py", line 42, in process_item
    request.urlretrieve(url=url, filename=filename)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/urllib/request.py", line 249, in urlretrieve
    tfp = open(filename, 'wb')
FileNotFoundError: [Errno 2] No such file or directory: '../download/imgs/【心得】感電時施放，觸發機制詢問 (已解決，更新：2025/1/15).jpg'
2025-01-16 18:06:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139274&tnum=3>
{'content': 'https://ithome.com.tw/news/166964 '
            '遊戲《流亡黯道2》在搶先體驗階段爆發資安事件，駭客駭入管理者帳號，影響至少66名玩家，損失高價值遊戲資產，開發商GGG承認系統安全漏洞並宣布改進…',
 'img': None,
 'title': '【情報】《流亡黯道2》管理者帳號被駭，玩家資產損失無法追回',
 'userName': 'jacket6719'}
2025-01-16 18:06:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139275&tnum=1>
{'content': 'poe純新手 第一次分享拍片若有錯誤請留言糾正討論感謝你 這個BD簡單有趣 只需一鍵 但是不強 小心一點還是可以在t14 15走走 '
            '影片連結 或是到我的twitch: 聊聊也可以',
 'img': 'https://i1.ytimg.com/vi/WTOkTcOK01I/hqdefault.jpg',
 'title': '【心得】霍格華茲畢業的黑僧 去去詛咒走',
 'userName': '月仔'}
2025-01-16 18:06:58 [scrapy.crawler] INFO: Received SIGINT twice, forcing unclean shutdown
2025-01-16 18:06:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139231&tnum=11>
{'content': '前言:非CI 不撐混抗 容量1萬! 天賦: '
            '藥劑選擇：主要要有傳奇藥劑MP水(必備)因為會先扣魔再扣血加上暴風亂舞速度快!噴魔速度比喝水還快 裝備選擇： ◉武器/副手: '
            '◉胸甲 ◉頭盔 ◉…',
 'img': 'https://truth.bahamut.com.tw/s01/202501/forum/18966/98e4358b6a1f12f52901027f80f1915d.JPG?w=300&h=300&fit=o',
 'title': '【心得】百萬古靈囚神杖!高配版天賦及配置分享',
 'userName': 'az5504156'}
2025-01-16 18:06:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=138616&tnum=5>
{'content': '不建議現在抄.建議等GGG放假回來更新後看看狀況 影片內有天賦跟裝備 補一個造價 大約25D '
            '項鍊.完美工匠.20等彗星佔一大半,項鍊不找法術等級的話很便宜 但消耗跟魔力上限要再另外…',
 'img': 'https://i1.ytimg.com/vi/C8ubRMKVFG8/hqdefault.jpg',
 'title': '【討論】屏障祈願惡魔彗星(五樓小更新)',
 'userName': '天啊你真高'}
2025-01-16 18:06:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=138913&tnum=16>
{'content': '我想各位冰骷髏的玩家~在與圖的過程中肯定被白癡一般的AI噁心到不能自理吧 所以這邊分享一個全新的冰骷髏思路來拯救你的與圖體驗 '
            '隨時可以與輪椅流派切換，讓你在與圖與王戰…',
 'img': None,
 'title': '【攻略】冰骷髏炸彈BUILD 拯救召喚與圖體驗全靠這招!!!',
 'userName': '菠蘿貓'}
2025-01-16 18:06:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139276&tnum=1>
{'content': '受控的蛻變 鑽石：裂痕王 搜尋器選擇： 「只會影響極小範圍內的天賦」 後面的最小最大值可以選 1～8，代表從極小到巨大 '
            '抗性詞綴是基本的查詢，應該不用特別講解 配上 https://max…',
 'img': 'https://truth.bahamut.com.tw/s01/202501/forum/18966/7e5589db4dbde93c002c40f938f327bd.JPG?w=300&h=300&fit=o',
 'title': '【心得】交易所傳奇珠寶查詢方式，台版（國際應該同樣方式）',
 'userName': '影˙焰'}
2025-01-16 18:06:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139277&tnum=1>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 468, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 463, in _make_request
    httplib_response = conn.getresponse()
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1349, in getresponse
    response.begin()
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 316, in begin
    version, status, reason = self._read_status()
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 285, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 552, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/packages/six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 468, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 463, in _make_request
    httplib_response = conn.getresponse()
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1349, in getresponse
    response.begin()
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 316, in begin
    version, status, reason = self._read_status()
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 285, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
2025-01-16 18:06:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=138031&tnum=19>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x106f72820>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=63481): Max retries exceeded with url: /session/4e850fd1170ee70416590db4df80058e/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x106f72820>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:06:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=137397&tnum=37>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x106f7b7f0>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=63481): Max retries exceeded with url: /session/4e850fd1170ee70416590db4df80058e/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x106f7b7f0>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:06:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=138723&tnum=21>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x106f847c0>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=63481): Max retries exceeded with url: /session/4e850fd1170ee70416590db4df80058e/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x106f847c0>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:06:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=138377&tnum=7>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x106f8f6a0>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=63481): Max retries exceeded with url: /session/4e850fd1170ee70416590db4df80058e/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x106f8f6a0>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:06:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=138161&tnum=9>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x106f9e670>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=63481): Max retries exceeded with url: /session/4e850fd1170ee70416590db4df80058e/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x106f9e670>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:06:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139281&tnum=1>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x106fac640>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=63481): Max retries exceeded with url: /session/4e850fd1170ee70416590db4df80058e/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x106fac640>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:06:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=136522&tnum=120>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x106fbc610>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=63481): Max retries exceeded with url: /session/4e850fd1170ee70416590db4df80058e/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x106fbc610>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:06:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139282&tnum=1>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x108b015e0>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=63481): Max retries exceeded with url: /session/4e850fd1170ee70416590db4df80058e/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108b015e0>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:06:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139283&tnum=1>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x108b125b0>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=63481): Max retries exceeded with url: /session/4e850fd1170ee70416590db4df80058e/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108b125b0>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:06:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139154&tnum=6>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x108b21580>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=63481): Max retries exceeded with url: /session/4e850fd1170ee70416590db4df80058e/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108b21580>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:06:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139171&tnum=24>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x108b32550>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=63481): Max retries exceeded with url: /session/4e850fd1170ee70416590db4df80058e/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108b32550>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:06:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139280&tnum=2>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x108b41520>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=63481): Max retries exceeded with url: /session/4e850fd1170ee70416590db4df80058e/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108b41520>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:06:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139238&tnum=13>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x108b514f0>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=63481): Max retries exceeded with url: /session/4e850fd1170ee70416590db4df80058e/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108b514f0>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:06:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=136809&tnum=154>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x108b63460>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=63481): Max retries exceeded with url: /session/4e850fd1170ee70416590db4df80058e/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108b63460>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:07:50 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: example)
2025-01-16 18:07:50 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.11.0, Python 3.9.6 (default, May  7 2023, 23:32:44) - [Clang 14.0.3 (clang-1403.0.22.14.1)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform macOS-13.2.1-arm64-arm-64bit
2025-01-16 18:07:50 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-16 18:07:50 [asyncio] DEBUG: Using selector: KqueueSelector
2025-01-16 18:07:50 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-16 18:07:50 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-16 18:07:50 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-16 18:07:50 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-16 18:07:50 [scrapy.extensions.telnet] INFO: Telnet Password: df8c7ba8a8435f75
2025-01-16 18:07:50 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-16 18:07:50 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'example',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': '../log/example.log',
 'NEWSPIDER_MODULE': 'example.spiders',
 'SPIDER_MODULES': ['example.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-16 18:07:51 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63905/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"extensions": [], "args": ["--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"extensions": [], "args": ["--headless"]}}}
2025-01-16 18:07:51 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:63905
2025-01-16 18:07:51 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63905 "POST /session HTTP/1.1" 200 892
2025-01-16 18:07:51 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:07:51 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy_selenium.SeleniumMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-16 18:07:51 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-16 18:07:51 [scrapy.middleware] INFO: Enabled item pipelines:
['example.pipelines.ExamplePipeline', 'example.pipelines.ExampleDownloadImg']
2025-01-16 18:07:51 [scrapy.core.engine] INFO: Spider opened
2025-01-16 18:07:51 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-16 18:07:51 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-01-16 18:07:52 [scrapy.core.engine] DEBUG: Crawled (200) <POST https://fanyi.baidu.com/sug> (referer: None)
2025-01-16 18:07:52 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-16 18:07:52 [selenium.webdriver.remote.remote_connection] DEBUG: DELETE http://127.0.0.1:63905/session/0ffd12d733b81a30beab7fd0e4359a66 {}
2025-01-16 18:07:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63905 "DELETE /session/0ffd12d733b81a30beab7fd0e4359a66 HTTP/1.1" 200 14
2025-01-16 18:07:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:07:52 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 359,
 'downloader/request_count': 1,
 'downloader/request_method_count/POST': 1,
 'downloader/response_bytes': 881,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.503385,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 16, 10, 7, 52, 421012, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 530,
 'httpcompression/response_count': 1,
 'items_per_minute': None,
 'log_count/DEBUG': 13,
 'log_count/INFO': 10,
 'memusage/max': 60981248,
 'memusage/startup': 60981248,
 'response_received_count': 1,
 'responses_per_minute': None,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2025, 1, 16, 10, 7, 51, 917627, tzinfo=datetime.timezone.utc)}
2025-01-16 18:07:52 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-16 18:09:11 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: example)
2025-01-16 18:09:11 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.11.0, Python 3.9.6 (default, May  7 2023, 23:32:44) - [Clang 14.0.3 (clang-1403.0.22.14.1)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform macOS-13.2.1-arm64-arm-64bit
2025-01-16 18:09:11 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-16 18:09:11 [asyncio] DEBUG: Using selector: KqueueSelector
2025-01-16 18:09:11 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-16 18:09:11 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-16 18:09:11 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-16 18:09:11 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-16 18:09:11 [scrapy.extensions.telnet] INFO: Telnet Password: 0ac6241c892dd3b2
2025-01-16 18:09:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-16 18:09:11 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'example',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': '../log/example.log',
 'NEWSPIDER_MODULE': 'example.spiders',
 'SPIDER_MODULES': ['example.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-16 18:09:12 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"extensions": [], "args": ["--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"extensions": [], "args": ["--headless"]}}}
2025-01-16 18:09:12 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:64261
2025-01-16 18:09:13 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session HTTP/1.1" 200 892
2025-01-16 18:09:13 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy_selenium.SeleniumMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-16 18:09:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-16 18:09:13 [scrapy.middleware] INFO: Enabled item pipelines:
['example.pipelines.ExamplePipeline', 'example.pipelines.ExampleDownloadImg']
2025-01-16 18:09:13 [scrapy.core.engine] INFO: Spider opened
2025-01-16 18:09:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-16 18:09:13 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-01-16 18:09:13 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/B.php?page=1&bsn=18966"}
2025-01-16 18:09:14 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:14 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:14 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:14 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 250324
2025-01-16 18:09:14 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:14 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:14 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 61
2025-01-16 18:09:14 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/B.php?page=1&bsn=18966> (referer: None)
2025-01-16 18:09:14 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync {"script": "return document.body.scrollHeight", "args": []}
2025-01-16 18:09:14 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync HTTP/1.1" 200 14
2025-01-16 18:09:14 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:14 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync {"script": "window.scrollTo(0, document.body.scrollHeight);", "args": []}
2025-01-16 18:09:14 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync HTTP/1.1" 200 14
2025-01-16 18:09:14 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:16 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync {"script": "return document.body.scrollHeight", "args": []}
2025-01-16 18:09:16 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync HTTP/1.1" 200 14
2025-01-16 18:09:16 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:16 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:16 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 253413
2025-01-16 18:09:16 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:16 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:16 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 61
2025-01-16 18:09:16 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:16 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139278&tnum=24"}
2025-01-16 18:09:17 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:17 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:17 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:17 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 485632
2025-01-16 18:09:17 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:17 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:17 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 73
2025-01-16 18:09:17 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139278&tnum=24> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:09:17 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/B.php?page=2&bsn=18966"}
2025-01-16 18:09:17 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:17 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:17 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:17 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 247823
2025-01-16 18:09:17 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:17 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:17 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 61
2025-01-16 18:09:17 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/B.php?page=2&bsn=18966> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:09:17 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=138700&tnum=5"}
2025-01-16 18:09:17 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:17 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:17 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:17 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 215228
2025-01-16 18:09:17 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:17 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:17 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 72
2025-01-16 18:09:17 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=138700&tnum=5> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:09:17 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139274&tnum=3"}
2025-01-16 18:09:18 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:18 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:18 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:18 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 163743
2025-01-16 18:09:18 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:18 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:18 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 72
2025-01-16 18:09:18 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139274&tnum=3> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:09:18 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139275&tnum=1"}
2025-01-16 18:09:18 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:18 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:18 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:18 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 139195
2025-01-16 18:09:18 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:18 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:18 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 72
2025-01-16 18:09:18 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139275&tnum=1> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:09:18 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139231&tnum=11"}
2025-01-16 18:09:19 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:19 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:19 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:19 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 264132
2025-01-16 18:09:19 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:19 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:19 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 73
2025-01-16 18:09:19 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139231&tnum=11> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:09:19 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=138616&tnum=5"}
2025-01-16 18:09:19 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:19 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:19 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:19 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 214531
2025-01-16 18:09:19 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:19 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:19 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 72
2025-01-16 18:09:19 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=138616&tnum=5> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:09:19 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=138913&tnum=16"}
2025-01-16 18:09:20 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:20 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:20 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:20 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 370931
2025-01-16 18:09:20 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:20 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:20 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 73
2025-01-16 18:09:20 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=138913&tnum=16> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:09:20 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139276&tnum=1"}
2025-01-16 18:09:20 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:20 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:20 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:20 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 148235
2025-01-16 18:09:20 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:20 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:20 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 72
2025-01-16 18:09:20 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139276&tnum=1> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:09:20 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139277&tnum=1"}
2025-01-16 18:09:21 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:21 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:21 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:21 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 152301
2025-01-16 18:09:21 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:21 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:21 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 72
2025-01-16 18:09:21 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139277&tnum=1> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:09:21 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=138031&tnum=19"}
2025-01-16 18:09:21 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:21 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:21 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:21 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 479828
2025-01-16 18:09:21 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:21 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:21 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 73
2025-01-16 18:09:21 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=138031&tnum=19> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:09:21 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=137397&tnum=37"}
2025-01-16 18:09:22 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:22 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:22 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:22 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 413215
2025-01-16 18:09:22 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:22 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:22 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 73
2025-01-16 18:09:22 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=137397&tnum=37> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:09:22 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=138723&tnum=21"}
2025-01-16 18:09:23 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:23 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:23 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:23 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 397261
2025-01-16 18:09:23 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:23 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:23 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 73
2025-01-16 18:09:23 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=138723&tnum=21> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:09:23 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=138377&tnum=7"}
2025-01-16 18:09:24 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:24 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:24 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:24 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 291884
2025-01-16 18:09:24 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:24 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:24 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 72
2025-01-16 18:09:24 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=138377&tnum=7> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:09:24 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=138161&tnum=9"}
2025-01-16 18:09:24 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:24 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:24 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:24 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 266859
2025-01-16 18:09:24 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:24 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:24 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 72
2025-01-16 18:09:24 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=138161&tnum=9> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:09:24 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139281&tnum=1"}
2025-01-16 18:09:24 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:24 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:24 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:24 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 145069
2025-01-16 18:09:24 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:24 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:24 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 72
2025-01-16 18:09:24 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139281&tnum=1> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:09:24 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=136522&tnum=120"}
2025-01-16 18:09:25 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:25 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:25 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:25 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 613024
2025-01-16 18:09:25 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:25 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:25 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 74
2025-01-16 18:09:25 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=136522&tnum=120> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:09:25 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139282&tnum=1"}
2025-01-16 18:09:25 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:25 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:25 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:25 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 139353
2025-01-16 18:09:25 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:25 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:25 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 72
2025-01-16 18:09:25 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139282&tnum=1> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:09:25 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139283&tnum=1"}
2025-01-16 18:09:26 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:26 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:26 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:26 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 147020
2025-01-16 18:09:26 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:26 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:26 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 72
2025-01-16 18:09:26 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139283&tnum=1> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:09:26 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139154&tnum=6"}
2025-01-16 18:09:26 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:26 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:26 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:26 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 246664
2025-01-16 18:09:26 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:26 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:26 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 72
2025-01-16 18:09:26 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139154&tnum=6> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:09:26 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139171&tnum=24"}
2025-01-16 18:09:27 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:27 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:27 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:27 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 451299
2025-01-16 18:09:27 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:27 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:27 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 73
2025-01-16 18:09:27 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139171&tnum=24> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:09:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139278&tnum=24>
{'content': 'https://www.pathofexile.com/forum/view-thread/3695606/page/1#p25859331 '
            '預計明天1/17更新 翻譯僅供參考 沒辦法詳細校對 此篇後其他討論串會隱藏處理 終局改動 新增 4 個塔地圖區域：「阿爾卑斯山脊…',
 'img': None,
 'title': '【情報】Poe 2 0.1.1 Patch note 集中討論串',
 'userName': '33456109'}
2025-01-16 18:09:27 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync {"script": "return document.body.scrollHeight", "args": []}
2025-01-16 18:09:27 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync HTTP/1.1" 200 15
2025-01-16 18:09:27 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:27 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync {"script": "window.scrollTo(0, document.body.scrollHeight);", "args": []}
2025-01-16 18:09:27 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync HTTP/1.1" 200 14
2025-01-16 18:09:27 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:29 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync {"script": "return document.body.scrollHeight", "args": []}
2025-01-16 18:09:29 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync HTTP/1.1" 200 15
2025-01-16 18:09:29 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:29 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync {"script": "window.scrollTo(0, document.body.scrollHeight);", "args": []}
2025-01-16 18:09:29 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync HTTP/1.1" 200 14
2025-01-16 18:09:29 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:31 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync {"script": "return document.body.scrollHeight", "args": []}
2025-01-16 18:09:31 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync HTTP/1.1" 200 15
2025-01-16 18:09:31 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:31 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:31 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 455331
2025-01-16 18:09:31 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:31 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:31 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 73
2025-01-16 18:09:31 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:31 [scrapy.core.scraper] ERROR: Error processing {'content': '一、前言最近想趁 GGG 大刀闊斧之前跟風玩電法，但對於其中感電時施放這個技能有的觸發機制有疑慮，很多 BD '
            '介紹也沒有特別去提，作為第一次玩 POE 的玩家，目前有錄影將感電過…',
 'img': 'https://truth.bahamut.com.tw/s01/202501/forum/18966/8b27d3635e75d203c8db8b2962bd3b11.JPG?w=300&h=300&fit=o',
 'title': '【心得】感電時施放，觸發機制詢問 (已解決，更新：2025/1/15)',
 'userName': '葳葳'}
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/utils/defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/Users/admin/PycharmProjects/WebCrawler/a_scrapy/example/example/pipelines.py", line 42, in process_item
    request.urlretrieve(url=url, filename=filename)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/urllib/request.py", line 249, in urlretrieve
    tfp = open(filename, 'wb')
FileNotFoundError: [Errno 2] No such file or directory: '../download/imgs/【心得】感電時施放，觸發機制詢問 (已解決，更新：2025/1/15).jpg'
2025-01-16 18:09:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139274&tnum=3>
{'content': 'https://ithome.com.tw/news/166964 '
            '遊戲《流亡黯道2》在搶先體驗階段爆發資安事件，駭客駭入管理者帳號，影響至少66名玩家，損失高價值遊戲資產，開發商GGG承認系統安全漏洞並宣布改進…',
 'img': None,
 'title': '【情報】《流亡黯道2》管理者帳號被駭，玩家資產損失無法追回',
 'userName': 'jacket6719'}
2025-01-16 18:09:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139275&tnum=1>
{'content': 'poe純新手 第一次分享拍片若有錯誤請留言糾正討論感謝你 這個BD簡單有趣 只需一鍵 但是不強 小心一點還是可以在t14 15走走 '
            '影片連結 或是到我的twitch: 聊聊也可以',
 'img': 'https://i1.ytimg.com/vi/WTOkTcOK01I/hqdefault.jpg',
 'title': '【心得】霍格華茲畢業的黑僧 去去詛咒走',
 'userName': '月仔'}
2025-01-16 18:09:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139231&tnum=11>
{'content': '前言:非CI 不撐混抗 容量1萬! 天賦: '
            '藥劑選擇：主要要有傳奇藥劑MP水(必備)因為會先扣魔再扣血加上暴風亂舞速度快!噴魔速度比喝水還快 裝備選擇： ◉武器/副手: '
            '◉胸甲 ◉頭盔 ◉…',
 'img': 'https://truth.bahamut.com.tw/s01/202501/forum/18966/98e4358b6a1f12f52901027f80f1915d.JPG?w=300&h=300&fit=o',
 'title': '【心得】百萬古靈囚神杖!高配版天賦及配置分享',
 'userName': 'az5504156'}
2025-01-16 18:09:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=138616&tnum=5>
{'content': '不建議現在抄.建議等GGG放假回來更新後看看狀況 影片內有天賦跟裝備 補一個造價 大約25D '
            '項鍊.完美工匠.20等彗星佔一大半,項鍊不找法術等級的話很便宜 但消耗跟魔力上限要再另外…',
 'img': 'https://i1.ytimg.com/vi/C8ubRMKVFG8/hqdefault.jpg',
 'title': '【討論】屏障祈願惡魔彗星(五樓小更新)',
 'userName': '天啊你真高'}
2025-01-16 18:09:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=138913&tnum=16>
{'content': '我想各位冰骷髏的玩家~在與圖的過程中肯定被白癡一般的AI噁心到不能自理吧 所以這邊分享一個全新的冰骷髏思路來拯救你的與圖體驗 '
            '隨時可以與輪椅流派切換，讓你在與圖與王戰…',
 'img': None,
 'title': '【攻略】冰骷髏炸彈BUILD 拯救召喚與圖體驗全靠這招!!!',
 'userName': '菠蘿貓'}
2025-01-16 18:09:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139276&tnum=1>
{'content': '受控的蛻變 鑽石：裂痕王 搜尋器選擇： 「只會影響極小範圍內的天賦」 後面的最小最大值可以選 1～8，代表從極小到巨大 '
            '抗性詞綴是基本的查詢，應該不用特別講解 配上 https://max…',
 'img': 'https://truth.bahamut.com.tw/s01/202501/forum/18966/7e5589db4dbde93c002c40f938f327bd.JPG?w=300&h=300&fit=o',
 'title': '【心得】交易所傳奇珠寶查詢方式，台版（國際應該同樣方式）',
 'userName': '影˙焰'}
2025-01-16 18:09:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139277&tnum=1>
{'content': 'https://www.pixiv.net/artworks/125927689 物品稀有度16%、國際服物價。 '
            '收益來源大致能分為： 基礎收益： 1.油 2.融解漩渦(傳奇魔水) 靠賽收益： 3.鑑定/做裝收益 4.妄想症 1.油： 數量 '
            '油:EX EX…',
 'img': 'https://truth.bahamut.com.tw/s01/202501/forum/18966/de8451ed4907cd51622081300a329b38.JPG?w=300&h=300&fit=o',
 'title': '【心得】T4幻象異界50張測試',
 'userName': '芋頭'}
2025-01-16 18:09:31 [scrapy.core.scraper] ERROR: Error processing {'content': 'Never sink編輯網站已上線！目前正在施工Neversink_Strict，將他的分級制度跟我的顏色合併。 '
            '在官網追蹤後就會自動更新，不用一直下載！ 訂閱後（限國際服），就不用下載了，只要按…',
 'img': 'https://truth.bahamut.com.tw/s01/202412/forum/18966/75848e01cf1a2cb2ecb3203b65809fd4.JPG?w=300&h=300&fit=o',
 'title': '【和色過濾器】1/14 Neversink版本測試',
 'userName': '摳捷'}
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/utils/defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/Users/admin/PycharmProjects/WebCrawler/a_scrapy/example/example/pipelines.py", line 42, in process_item
    request.urlretrieve(url=url, filename=filename)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/urllib/request.py", line 249, in urlretrieve
    tfp = open(filename, 'wb')
FileNotFoundError: [Errno 2] No such file or directory: '../download/imgs/【和色過濾器】1/14 Neversink版本測試.jpg'
2025-01-16 18:09:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=137397&tnum=37>
{'content': '前言: 本文轉載自reddit poe 版原文，我負責翻譯跟校對 給剛入門的朋友: '
            '開發商GGG有承諾，所有POE1的商城物品都能通用到POE2 但由於目前是EA(搶先體驗) 階段，故有部分商城物品是還沒…',
 'img': None,
 'title': '【攻略】POE 1&2 通用商城物品一覽表',
 'userName': 'baha0079'}
2025-01-16 18:09:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=138723&tnum=21>
{'content': '影片 天賦 章節天賦 (囚神杵) 血盾天賦 (囚神杵/稀有杖) 轉CI天賦 (囚神杵/稀有杖) 屬性天賦 (囚神杵) '
            '昇華的如急流瀑布(冰點)和若非獨自一人必點(精魂)，剩下兩個可以任意搭配，如…',
 'img': None,
 'title': '【心得】POE 2 武僧囚神杵低配版 十個崇高 一鐘近百萬 1/12 新增稀有杖裂痕四',
 'userName': '隨風飄逝'}
2025-01-16 18:09:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=138377&tnum=7>
{'content': '各位好，我是Ruz，你也可以叫我Rain。 這次為大家帶來的是淺井長政時空術師。 一個打王很強的build。 流派優缺點 優點： '
            '‧T0級別的打王 ‧時空術士自帶時空鎖鏈光環，這東西真的…',
 'img': None,
 'title': '【心得】手把手帶你只用1D組一隻能無傷通這遊戲所有BOSS的時空接技法 ,feat COC , 冰法 更新：改版指南',
 'userName': 'Ruz'}
2025-01-16 18:09:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=138161&tnum=9>
{'content': '重發 先感謝DC群的大佬們依依回答,對於老鳥或是新手們對於這東西有不知道的 看這表會比較明白 '
            '目前已知的有這些,有人知道的可以補充在下方 明日會再修改圖表',
 'img': None,
 'title': '【密技】圖騰是我,我不是圖騰',
 'userName': '楊楊'}
2025-01-16 18:09:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139281&tnum=1>
{'content': '這遊戲精彩又可惜 就像跨年煙火 燦爛但短暫 但能這樣也沒有太多怨言 精彩的是承接了D1 D2的美好 可惜的是 似乎還沒有決心去離開 '
            'D2 開始所謂的 一鍵清怪 與 打寶風氣 玩到接近90級…',
 'img': None,
 'title': '【問題】poe2 好遊戲 小感想',
 'userName': 'evilalways'}
2025-01-16 18:09:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=136522&tnum=120>
{'content': '》目錄《 ✦拓荒✦ ✦裝備✦ ✦技能✦ ✦天賦✦ ✦影片✦ (ctrl+f可輸入關鍵字搜尋) 12/11 '
            '更新成形技能串法、裝備基底敘述，新增畢業天賦、部分附註、過濾器 12/13 更新技能翻譯名…',
 'img': None,
 'title': '【攻略】[星月]-POE2 骷髏縱火者 火系召喚拓荒分享(1/2 更新無火牆玩法、過濾器、裝備詞綴',
 'userName': '星月'}
2025-01-16 18:09:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139282&tnum=1>
{'content': '如題 請問如果都是+10%的狀況下哪一個對於近戰的技能施放速度會比較多?',
 'img': None,
 'title': '【問題】請問技能速度跟攻擊速度哪個對近戰技能施放速度的影響比較多?',
 'userName': 'PosiVibe'}
2025-01-16 18:09:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139283&tnum=1>
{'content': '我花兩分鐘就是為了插一張碑文 那幹嘛不直接讓我路過直插就好了 裡面又沒什麼特殊經濟單位怪讓我打 輿圖抄LE抄成這樣 '
            '不如照搬LE的的塔 裡面直接放一個BOSS打完就加類似雕文效…',
 'img': None,
 'title': '【問題】其實我一直覺得要進入失落之塔很沒意義',
 'userName': '維尼坦克車'}
2025-01-16 18:09:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139154&tnum=6>
{'content': '安安== 此圖鑑純屬學術研究為目的 重練了幾次，發現都還沒靜下心來細細的欣賞2的模組 於是就放慢步調邊玩邊欣賞 '
            '圖鑑順序是照著任務排序 所以就讓我們藉由認識女NPC 再一起重跑…',
 'img': None,
 'title': '【討論】邊玩邊拍照於是收集了一本女NPC圖鑑 (偽劇情攻略)',
 'userName': '不要使用特殊符號字元'}
2025-01-16 18:09:31 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/B.php?page=3&bsn=18966"}
2025-01-16 18:09:32 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:32 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:32 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:32 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 242920
2025-01-16 18:09:32 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:32 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:32 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 61
2025-01-16 18:09:32 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/B.php?page=3&bsn=18966> (referer: https://forum.gamer.com.tw/B.php?page=2&bsn=18966)
2025-01-16 18:09:32 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139280&tnum=2"}
2025-01-16 18:09:32 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:32 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:32 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:32 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 159249
2025-01-16 18:09:32 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:32 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:32 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 72
2025-01-16 18:09:32 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139280&tnum=2> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:09:32 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139238&tnum=13"}
2025-01-16 18:09:33 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:33 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:33 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:33 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 314171
2025-01-16 18:09:33 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:33 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:33 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 73
2025-01-16 18:09:33 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139238&tnum=13> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:09:33 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=136809&tnum=154"}
2025-01-16 18:09:33 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:33 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:33 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:33 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 437249
2025-01-16 18:09:33 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:33 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:33 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 74
2025-01-16 18:09:33 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=136809&tnum=154> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:09:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139171&tnum=24>
{'content': '我是個喜歡玩暗黑類刷寶遊戲的老玩家 一整年除了幾個特定的單機遊戲 我現在大概就是D4 /POE2/火炬 賽季輪著玩 '
            '其實火炬之光對比其他兩者來說 遊戲/劇情/畫面/深度都不在同一個水…',
 'img': None,
 'title': '【討論】 期待POE2的拍賣場可參考隔壁棚的火炬之光再優化',
 'userName': 'allen'}
2025-01-16 18:09:33 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync {"script": "return document.body.scrollHeight", "args": []}
2025-01-16 18:09:33 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync HTTP/1.1" 200 15
2025-01-16 18:09:33 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:33 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync {"script": "window.scrollTo(0, document.body.scrollHeight);", "args": []}
2025-01-16 18:09:33 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync HTTP/1.1" 200 14
2025-01-16 18:09:33 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:35 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync {"script": "return document.body.scrollHeight", "args": []}
2025-01-16 18:09:35 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync HTTP/1.1" 200 15
2025-01-16 18:09:35 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:35 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync {"script": "window.scrollTo(0, document.body.scrollHeight);", "args": []}
2025-01-16 18:09:35 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync HTTP/1.1" 200 14
2025-01-16 18:09:35 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:37 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync {"script": "return document.body.scrollHeight", "args": []}
2025-01-16 18:09:37 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync HTTP/1.1" 200 15
2025-01-16 18:09:37 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:37 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:38 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 438954
2025-01-16 18:09:38 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:38 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:38 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 74
2025-01-16 18:09:38 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:38 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139280&tnum=2>
{'content': '市集密了一件裝備1D沒有回應， 約5分鐘後賣家改價5D，我密他說這價格我ok 隨後賣家組我進隊伍，要求隊伍內玩家競標?_? '
            '改價遇的多了 第一次遇到把人組起來競標的 真的是大開眼界…',
 'img': 'https://truth.bahamut.com.tw/s01/202501/forum/18966/ab4322a4fb4cc154ede306ddc03c0a92.JPG?w=300&h=300&fit=o',
 'title': '【閒聊】改價獸進化 競標獸',
 'userName': '好好先生'}
2025-01-16 18:09:38 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139238&tnum=13>
{'content': '各位安安，我是森林露 前言: 本人算是POE老屁股，一代測試玩到二代測試的玩家， '
            '二代吸引到許多新玩家入坑，身為老玩家也為這款遊戲感到高興。 但...二代的王戰相較一代難上許…',
 'img': 'https://truth.bahamut.com.tw/s01/202501/forum/18966/562818bb7e9382fdb0637dff8f6ae9e4.JPG?w=300&h=300&fit=o',
 'title': '【閒聊】關於二代遊戲風氣...',
 'userName': '森林鹿'}
2025-01-16 18:09:38 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/B.php?page=4&bsn=18966"}
2025-01-16 18:09:38 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:38 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:38 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:38 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 245650
2025-01-16 18:09:38 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:38 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:38 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 61
2025-01-16 18:09:38 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/B.php?page=4&bsn=18966> (referer: https://forum.gamer.com.tw/B.php?page=3&bsn=18966)
2025-01-16 18:09:38 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=136809&tnum=154>
{'content': 'POE2把改造、重鑄、工藝台和各種做裝能力都拔掉之後，現在裝備重點基本上是找好基底點藍點黃，拿崇高點出好詞真快樂，簡單樸實。 '
            '好裝的的出現難度顯著提升，因此他們的價值…',
 'img': 'https://truth.bahamut.com.tw/s01/202412/forum/18966/404f00297ce9b876763a192534b2e3e9.JPG?w=300&h=300&fit=o',
 'title': '【閒聊】POE2裝備展示區～秀秀你的裝備吧',
 'userName': 'War'}
2025-01-16 18:09:38 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync {"script": "return document.body.scrollHeight", "args": []}
2025-01-16 18:09:38 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync HTTP/1.1" 200 14
2025-01-16 18:09:38 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:38 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync {"script": "window.scrollTo(0, document.body.scrollHeight);", "args": []}
2025-01-16 18:09:38 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync HTTP/1.1" 200 14
2025-01-16 18:09:38 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:40 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync {"script": "return document.body.scrollHeight", "args": []}
2025-01-16 18:09:40 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync HTTP/1.1" 200 14
2025-01-16 18:09:40 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:40 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync {"script": "window.scrollTo(0, document.body.scrollHeight);", "args": []}
2025-01-16 18:09:40 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync HTTP/1.1" 200 14
2025-01-16 18:09:40 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:42 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync {"script": "return document.body.scrollHeight", "args": []}
2025-01-16 18:09:42 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync HTTP/1.1" 200 14
2025-01-16 18:09:42 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:42 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:42 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 249022
2025-01-16 18:09:42 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:42 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:42 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 61
2025-01-16 18:09:42 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:42 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139226&tnum=3&bPage=4"}
2025-01-16 18:09:42 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:42 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:42 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:42 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 163046
2025-01-16 18:09:42 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:42 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:42 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 80
2025-01-16 18:09:42 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139226&tnum=3&bPage=4> (referer: https://forum.gamer.com.tw/B.php?page=4&bsn=18966)
2025-01-16 18:09:42 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/B.php?page=5&bsn=18966"}
2025-01-16 18:09:43 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:43 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:43 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:43 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 247436
2025-01-16 18:09:43 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:43 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:43 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 61
2025-01-16 18:09:43 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/B.php?page=5&bsn=18966> (referer: https://forum.gamer.com.tw/B.php?page=4&bsn=18966)
2025-01-16 18:09:43 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139197&tnum=4&bPage=4"}
2025-01-16 18:09:43 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:43 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:43 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:43 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 194677
2025-01-16 18:09:43 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:43 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:43 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 80
2025-01-16 18:09:43 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139197&tnum=4&bPage=4> (referer: https://forum.gamer.com.tw/B.php?page=4&bsn=18966)
2025-01-16 18:09:43 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139201&tnum=1&bPage=4"}
2025-01-16 18:09:44 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:44 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:44 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:44 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 138597
2025-01-16 18:09:44 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:44 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:44 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 80
2025-01-16 18:09:44 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139201&tnum=1&bPage=4> (referer: https://forum.gamer.com.tw/B.php?page=4&bsn=18966)
2025-01-16 18:09:44 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=104740&tnum=1067&bPage=4"}
2025-01-16 18:09:44 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:44 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:44 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:44 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 501232
2025-01-16 18:09:44 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:44 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:44 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 83
2025-01-16 18:09:44 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=104740&tnum=1067&bPage=4> (referer: https://forum.gamer.com.tw/B.php?page=4&bsn=18966)
2025-01-16 18:09:44 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139202&tnum=1&bPage=4"}
2025-01-16 18:09:45 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:45 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:45 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:45 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 152620
2025-01-16 18:09:45 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:45 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:45 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 80
2025-01-16 18:09:45 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139202&tnum=1&bPage=4> (referer: https://forum.gamer.com.tw/B.php?page=4&bsn=18966)
2025-01-16 18:09:45 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139177&tnum=2&bPage=4"}
2025-01-16 18:09:45 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:45 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:45 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:45 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 165409
2025-01-16 18:09:45 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:45 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:45 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 80
2025-01-16 18:09:45 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139177&tnum=2&bPage=4> (referer: https://forum.gamer.com.tw/B.php?page=4&bsn=18966)
2025-01-16 18:09:45 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139204&tnum=1&bPage=4"}
2025-01-16 18:09:45 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:45 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:45 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:45 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 137930
2025-01-16 18:09:45 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:45 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:45 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 80
2025-01-16 18:09:45 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139204&tnum=1&bPage=4> (referer: https://forum.gamer.com.tw/B.php?page=4&bsn=18966)
2025-01-16 18:09:45 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139205&tnum=1&bPage=4"}
2025-01-16 18:09:46 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:46 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:46 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:46 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 154321
2025-01-16 18:09:46 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:46 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:46 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 80
2025-01-16 18:09:46 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139205&tnum=1&bPage=4> (referer: https://forum.gamer.com.tw/B.php?page=4&bsn=18966)
2025-01-16 18:09:46 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139207&tnum=1&bPage=4"}
2025-01-16 18:09:46 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:46 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:46 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:46 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 134894
2025-01-16 18:09:46 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:46 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:46 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 80
2025-01-16 18:09:46 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139207&tnum=1&bPage=4> (referer: https://forum.gamer.com.tw/B.php?page=4&bsn=18966)
2025-01-16 18:09:46 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139208&tnum=1&bPage=4"}
2025-01-16 18:09:46 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:46 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:46 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:46 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 139456
2025-01-16 18:09:46 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:46 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:46 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 80
2025-01-16 18:09:46 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139208&tnum=1&bPage=4> (referer: https://forum.gamer.com.tw/B.php?page=4&bsn=18966)
2025-01-16 18:09:46 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139127&tnum=2&bPage=4"}
2025-01-16 18:09:47 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:47 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:47 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:47 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 149212
2025-01-16 18:09:47 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:47 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:47 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 80
2025-01-16 18:09:47 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139127&tnum=2&bPage=4> (referer: https://forum.gamer.com.tw/B.php?page=4&bsn=18966)
2025-01-16 18:09:47 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139209&tnum=1&bPage=4"}
2025-01-16 18:09:47 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:47 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:47 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:47 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 137861
2025-01-16 18:09:47 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:47 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:47 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 80
2025-01-16 18:09:47 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139209&tnum=1&bPage=4> (referer: https://forum.gamer.com.tw/B.php?page=4&bsn=18966)
2025-01-16 18:09:47 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139211&tnum=1&bPage=4"}
2025-01-16 18:09:47 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:47 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:47 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:47 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 138006
2025-01-16 18:09:47 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:47 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:47 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 80
2025-01-16 18:09:47 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139211&tnum=1&bPage=4> (referer: https://forum.gamer.com.tw/B.php?page=4&bsn=18966)
2025-01-16 18:09:47 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139212&tnum=1&bPage=4"}
2025-01-16 18:09:48 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:48 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:48 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:48 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 153269
2025-01-16 18:09:48 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:48 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:48 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 80
2025-01-16 18:09:48 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139212&tnum=1&bPage=4> (referer: https://forum.gamer.com.tw/B.php?page=4&bsn=18966)
2025-01-16 18:09:48 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139214&tnum=1&bPage=4"}
2025-01-16 18:09:48 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:48 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:48 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:48 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 140596
2025-01-16 18:09:48 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:48 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:48 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 80
2025-01-16 18:09:48 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139214&tnum=1&bPage=4> (referer: https://forum.gamer.com.tw/B.php?page=4&bsn=18966)
2025-01-16 18:09:48 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139215&tnum=1&bPage=4"}
2025-01-16 18:09:48 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:48 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:48 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:48 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 140057
2025-01-16 18:09:48 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:48 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:48 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 80
2025-01-16 18:09:48 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139215&tnum=1&bPage=4> (referer: https://forum.gamer.com.tw/B.php?page=4&bsn=18966)
2025-01-16 18:09:48 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=135168&tnum=3&bPage=4"}
2025-01-16 18:09:49 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:49 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:49 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:49 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 158226
2025-01-16 18:09:49 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:49 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:49 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 80
2025-01-16 18:09:49 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=135168&tnum=3&bPage=4> (referer: https://forum.gamer.com.tw/B.php?page=4&bsn=18966)
2025-01-16 18:09:49 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139216&tnum=1&bPage=4"}
2025-01-16 18:09:49 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:49 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:49 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:49 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 135446
2025-01-16 18:09:49 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:49 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:49 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 80
2025-01-16 18:09:49 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139216&tnum=1&bPage=4> (referer: https://forum.gamer.com.tw/B.php?page=4&bsn=18966)
2025-01-16 18:09:49 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139206&tnum=4&bPage=4"}
2025-01-16 18:09:50 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:50 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:50 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:50 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 207502
2025-01-16 18:09:50 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:50 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:50 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 80
2025-01-16 18:09:50 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139206&tnum=4&bPage=4> (referer: https://forum.gamer.com.tw/B.php?page=4&bsn=18966)
2025-01-16 18:09:50 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139218&tnum=1&bPage=4"}
2025-01-16 18:09:50 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:50 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:50 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:50 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 139524
2025-01-16 18:09:50 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:50 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:50 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 80
2025-01-16 18:09:50 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139218&tnum=1&bPage=4> (referer: https://forum.gamer.com.tw/B.php?page=4&bsn=18966)
2025-01-16 18:09:50 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139219&tnum=1&bPage=4"}
2025-01-16 18:09:50 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:50 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:50 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:50 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 137605
2025-01-16 18:09:50 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:50 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:50 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 80
2025-01-16 18:09:50 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139219&tnum=1&bPage=4> (referer: https://forum.gamer.com.tw/B.php?page=4&bsn=18966)
2025-01-16 18:09:50 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139213&tnum=2&bPage=4"}
2025-01-16 18:09:51 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:51 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:51 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:51 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 131078
2025-01-16 18:09:51 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:51 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:51 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 80
2025-01-16 18:09:51 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139213&tnum=2&bPage=4> (referer: https://forum.gamer.com.tw/B.php?page=4&bsn=18966)
2025-01-16 18:09:51 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139220&tnum=1&bPage=4"}
2025-01-16 18:09:51 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:51 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:51 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:51 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 141624
2025-01-16 18:09:51 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:51 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:51 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 80
2025-01-16 18:09:51 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139220&tnum=1&bPage=4> (referer: https://forum.gamer.com.tw/B.php?page=4&bsn=18966)
2025-01-16 18:09:51 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139221&tnum=1&bPage=4"}
2025-01-16 18:09:51 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:51 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:51 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:51 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 128044
2025-01-16 18:09:51 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:51 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:51 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 80
2025-01-16 18:09:51 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139221&tnum=1&bPage=4> (referer: https://forum.gamer.com.tw/B.php?page=4&bsn=18966)
2025-01-16 18:09:51 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139222&tnum=1&bPage=4"}
2025-01-16 18:09:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:52 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 139852
2025-01-16 18:09:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:52 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 80
2025-01-16 18:09:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139222&tnum=1&bPage=4> (referer: https://forum.gamer.com.tw/B.php?page=4&bsn=18966)
2025-01-16 18:09:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139223&tnum=1&bPage=4"}
2025-01-16 18:09:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:52 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 138991
2025-01-16 18:09:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:52 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 80
2025-01-16 18:09:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139223&tnum=1&bPage=4> (referer: https://forum.gamer.com.tw/B.php?page=4&bsn=18966)
2025-01-16 18:09:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139224&tnum=1&bPage=4"}
2025-01-16 18:09:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:52 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 140320
2025-01-16 18:09:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:52 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 80
2025-01-16 18:09:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139224&tnum=1&bPage=4> (referer: https://forum.gamer.com.tw/B.php?page=4&bsn=18966)
2025-01-16 18:09:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139225&tnum=1&bPage=4"}
2025-01-16 18:09:53 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:53 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:53 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:53 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 129180
2025-01-16 18:09:53 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:53 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:53 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 80
2025-01-16 18:09:53 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139225&tnum=1&bPage=4> (referer: https://forum.gamer.com.tw/B.php?page=4&bsn=18966)
2025-01-16 18:09:53 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=138904&tnum=5&bPage=4"}
2025-01-16 18:09:57 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:57 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:57 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:57 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 198534
2025-01-16 18:09:57 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:57 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:57 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 80
2025-01-16 18:09:57 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=138904&tnum=5&bPage=4> (referer: https://forum.gamer.com.tw/B.php?page=4&bsn=18966)
2025-01-16 18:09:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139226&tnum=3&bPage=4>
{'content': '有鑑於上次被說我分享的流派影片廢話太多大家覺得不好看 那我這邊分享一個絕對精華 從頭到尾沒有廢話 並且非常讚的一個頻道 '
            '我是懂得反省的人 絕對沒有引戰的啦',
 'img': 'https://i1.ytimg.com/vi/uzjXtylbNlg/hqdefault.jpg',
 'title': '【情報】這邊分享一個 四秒擊殺終極boss的流派 並且刷圖又快範圍又大',
 'userName': '西門汁妹~汁汁'}
2025-01-16 18:09:57 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync {"script": "return document.body.scrollHeight", "args": []}
2025-01-16 18:09:57 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync HTTP/1.1" 200 14
2025-01-16 18:09:57 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:57 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync {"script": "window.scrollTo(0, document.body.scrollHeight);", "args": []}
2025-01-16 18:09:57 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync HTTP/1.1" 200 14
2025-01-16 18:09:57 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:59 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync {"script": "return document.body.scrollHeight", "args": []}
2025-01-16 18:09:59 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync HTTP/1.1" 200 14
2025-01-16 18:09:59 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:59 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync {"script": "window.scrollTo(0, document.body.scrollHeight);", "args": []}
2025-01-16 18:09:59 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync HTTP/1.1" 200 14
2025-01-16 18:09:59 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:01 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync {"script": "return document.body.scrollHeight", "args": []}
2025-01-16 18:10:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync HTTP/1.1" 200 14
2025-01-16 18:10:01 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:01 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:10:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 201105
2025-01-16 18:10:01 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:01 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:10:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 80
2025-01-16 18:10:01 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139197&tnum=4&bPage=4>
{'content': '換了四天了現在lv44 但現在打不過煉治師 而且傷害也不夠 上網找了很多玩法但發現大部份也玩不到 '
            '請問有沒有什麼流派是我現在可以玩的',
 'img': None,
 'title': '【問題】請問血法師應該怎樣玩',
 'userName': 'Oscar8605'}
2025-01-16 18:10:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139201&tnum=1&bPage=4>
{'content': '各位大大新年好 請問一下有關雙天賦系統的問題 就是技能格只有9格 雙武器沒有各自的技能格嗎？ 記得應該是有可以切換才對 '
            '但一直找不到 該不會是兩種武器的技能共用9格吧',
 'img': None,
 'title': '【問題】請問有關雙武器天系統問題',
 'userName': 'TGX'}
2025-01-16 18:10:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=104740&tnum=1067&bPage=4>
{'content': '【聲明】:想組新電腦的請自行去『原價屋或欣亞網站』嘗試開單，再用站內信給我 '
            '(我會提出修正建議跟理由~僅供參考用，畢竟$$是你自己的，花得爽更重要) 【軟體,網路】的問題，…',
 'img': None,
 'title': '【討論】舊電腦無痛升級討論專區(不想花大錢組新電腦的朋友們可留言詢問)',
 'userName': 'kevin54099'}
2025-01-16 18:10:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139202&tnum=1&bPage=4>
{'content': '聲明先上，此流派造價很高，超過200神聖 這流派是我在youtube上看到覺得有意思就抄來玩玩看 Youtube連結在此 '
            '包括作者本人也這麼說，目前這流派利用到的機制基本上就是個Bug，未來…',
 'img': None,
 'title': '【心得】POE2 風暴編織者 閃避時施放彗星自走砲分享',
 'userName': '維Wei'}
2025-01-16 18:10:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139177&tnum=2&bPage=4>
{'content': '懶人包就是其中一個GGG的管理員帳號被盗了 而管理員帳號有管理員專用面板 可以看到一般帳號的所有資料 所以確定是GGG的資料外洩 '
            '不是什麼第三方軟件的問題 reddit中流出的管理員…',
 'img': 'https://truth.bahamut.com.tw/s01/202501/forum/18966/8fb8a00f7905891dadaa6b6c2479a8fe.JPG?w=300&h=300&fit=o',
 'title': '【問題】近期很多人被盗的真正原因(Jonathan在訪談中承認資料外洩)',
 'userName': '巴哈真男人'}
2025-01-16 18:10:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139204&tnum=1&bPage=4>
{'content': '好像只有開圖者看得到NPC!!!',
 'img': 'https://truth.bahamut.com.tw/s01/202501/forum/18966/d58e9d28358e4ee9083d5f9de42bb3e9.JPG?w=300&h=300&fit=o',
 'title': '【討論】應各位觀眾要求~~~',
 'userName': '地瓜王國'}
2025-01-16 18:10:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139205&tnum=1&bPage=4>
{'content': '大家好，我又來爆破冰牆了 今天要來介紹用來爆破冰牆的方法是"飛雷神"，也就是天雷之珠+閃電傳送 主要想法: '
            '相信很多人都有嘗試過天雷串散射、閃傳串釋放這個 Combo 一次…',
 'img': 'https://truth.bahamut.com.tw/s01/202501/forum/18966/8f4c4dcc738d9c9aeff0548515936a23.JPG?w=300&h=300&fit=o',
 'title': '【心得】冰牆飛雷神 風暴編織者 難道爆破冰牆的最終手段就是成為四代目?!(還是皮卡丘?)',
 'userName': 'BlueGun'}
2025-01-16 18:10:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139207&tnum=1&bPage=4>
{'content': '請問哪邊可以查詢，搜記錄好像只有POE1有，請大神幫解惑或是創角時間之類的',
 'img': None,
 'title': '【問題】請問是否有查詢POE2角色紀錄',
 'userName': '哪裡來的駱駝客'}
2025-01-16 18:10:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139208&tnum=1&bPage=4>
{'content': '聖物祭壇點了沒反應，放硬幣的視窗沒開啟... 第一次昇華是正常的 請問有人有頭緒嗎 補上一些現狀 1. 這是重練第三隻角色 '
            '78等，過完昇華2 我有換前面兩隻來點祭壇都是正常可以開…',
 'img': None,
 'title': '【問題】POE2 聖物祭壇無法點擊',
 'userName': 'dddd'}
2025-01-16 18:10:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139127&tnum=2&bPage=4>
{'content': '大家好 ! 預祝各位新年快樂 !!! 這邊跟各位分享個人自製的簡易計算刷圖收益的表格 第一次發這類文章，排版醜請見諒(；・∀・) '
            '本表的最終收益計算統一以崇高石(Exalted)及神聖石(Di…',
 'img': None,
 'title': '【心得】【PoE2】刷圖收益計算表',
 'userName': 'Sasin'}
2025-01-16 18:10:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139209&tnum=1&bPage=4>
{'content': '如題~ 請問大家如何在使用手把的時候，觀看自己的恩次跟痛苦呢！？ 我老是看不到自己得到那些種類',
 'img': None,
 'title': '【問題】昇華試煉 使用手把',
 'userName': '三碗豬腳'}
2025-01-16 18:10:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139211&tnum=1&bPage=4>
{'content': '有15波怪 想問這流派好打嗎 好少看有影片放上來。',
 'img': None,
 'title': '【問題】請問武僧冰擊流派 能打譫妄王嗎',
 'userName': '小偉'}
2025-01-16 18:10:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139212&tnum=1&bPage=4>
{'content': '1/17PN沒被刀 應該是活下來了 時空衣稍微便宜一點 魔力藥劑應該會陸續降 勉強算是有前途了?  嗨 '
            '我温温這次要來分享的流派是古靈大法師CoD閃現電弧 先打個預防針 只是分享自己捏…',
 'img': None,
 'title': '【心得】POE2 神速 電光石火! 古靈大法師CoD閃現電弧(1/17PN存活)',
 'userName': 'Dizzy2 温温'}
2025-01-16 18:10:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139214&tnum=1&bPage=4>
{'content': '如標題，常常刷圖刷一刷 突然攻速就變慢了很多 高速超跑瞬間變老爺車 而且我是玩囚神古靈，攻速很快 '
            '所以體感更明顯速度變慢了，偶爾打一打會突然恢復，不然就要重登 想請問…',
 'img': None,
 'title': '【問題】【PoE2】 BUG? 打一打攻速突然變慢',
 'userName': '沁°'}
2025-01-16 18:10:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139215&tnum=1&bPage=4>
{'content': '目前小弟是用全閃避+移形幻影 閃避率80%可以閃掉大多數的傷害 '
            '但是只要運氣不好一下沒閃到小弟2000左右的HP馬上就蒸發直接升天了...',
 'img': None,
 'title': '【問題】請問各位遊俠都怎麼提升生存的呢',
 'userName': '天羽'}
2025-01-16 18:10:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=135168&tnum=3&bPage=4>
{'content': '在實況上看到交易時別人密語之後打開倉庫後能標示物品位置 我在國際服上交易時別人密我都沒看到這個功能 是有需要額外裝甚麼才能看到嗎? '
            '還是只是因為中文化所以沒有辦法顯…',
 'img': None,
 'title': '【問題】交易倉庫標示問題',
 'userName': '哈巴德'}
2025-01-16 18:10:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139216&tnum=1&bPage=4>
{'content': '迷霧之王二階段直接卡死不會動,我看別人一代也遇到過,二代BUG照搬,有料',
 'img': None,
 'title': '【問題】87GGG智障bug什麼時候修',
 'userName': 'shouei03'}
2025-01-16 18:10:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139206&tnum=4&bPage=4>
{'content': '我先來. 爛死了.有夠沒意義 號稱無限延伸的大地圖 實際上是電腦生成的各個區塊. 中間靠著演算法自己連結 然後連結的算法一直出錯 '
            '有輿圖完全沒法連出去的 或是有一邊繞一大圈…',
 'img': None,
 'title': '【閒聊】這次POE2輿圖大地圖大家滿意嗎?',
 'userName': 'Human Being'}
2025-01-16 18:10:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139218&tnum=1&bPage=4>
{'content': '黃名怪直接卡在地板裡面一直射一直射 沒血條比npc還猛= =',
 'img': None,
 'title': '【問題】這隻弓箭手是想怎樣啦',
 'userName': '某愛尬利共'}
2025-01-16 18:10:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139219&tnum=1&bPage=4>
{'content': 'POE1/POE2 賣場無意間發現只有1000上限 以前可以黑爽爽 鳥價不回 自出 1跟2是共用那個1000個名單的樣子 '
            '黑單的帳號是同步....還沒賽季就黑了499個了..',
 'img': None,
 'title': '【閒聊】現在的賣場黑單只有1000上限',
 'userName': '里予豕者'}
2025-01-16 18:10:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139213&tnum=2&bPage=4>
{'content': '如題，請問應該如何另一顆戒指也可以使用？謝謝',
 'img': None,
 'title': '【問題】請問為什麼裝備竊罪的戒指後另外一顆顯示無法使用？',
 'userName': 'kemp0518'}
2025-01-16 18:10:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139220&tnum=1&bPage=4>
{'content': '我開閃電之捷 我看戰鬥狂怒的解說是只要觸電也能拿到狂怒球 但是我都拿不到 請大家解惑一下 順便問 '
            '如果我要提升DPS下一步該從哪裡提升 謝謝',
 'img': 'https://truth.bahamut.com.tw/s01/202501/forum/18966/d4b80a4cdbd2479e436ba1c2622adcf7.JPG?w=300&h=300&fit=o',
 'title': '【問題】新手發問-囚神古靈拿不到狂怒球了? 拜託大家幫幫忙',
 'userName': '嵐御攸'}
2025-01-16 18:10:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139221&tnum=1&bPage=4>
{'content': '擊中引起中毒時，每秒造成相當於擊中所造成的物理和混沌傷害的 20% 傷害。 請問看字面上是擊中當下的傷害計算，爆擊傷害會算進去嗎？',
 'img': None,
 'title': '【問題】中毒問題',
 'userName': 'Mark'}
2025-01-16 18:10:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139222&tnum=1&bPage=4>
{'content': '打他他還會用招式還手 還會跟著我走(? 最扯的是 不理它 清完全圖 菁英怪提示位置顯示出來後 去找 居然是他!!!! 我還無法殺他 '
            '無法完成地圖 蛤???? 謝謝你 GGG',
 'img': 'https://i1.ytimg.com/vi/GUQzYwCCWlU/hqdefault.jpg',
 'title': '【閒聊】二代玩到現在有發生有趣的事? 遇上怪怪的無敵敵人',
 'userName': 'spock0626'}
2025-01-16 18:10:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139223&tnum=1&bPage=4>
{'content': '請問有人成功用nvidia geforce now 玩POE2嗎? 我開啟POE2 畫面是黑的 只有聽到遊戲聲音 '
            '有正常能玩的可以分享怎麼解決嗎?',
 'img': None,
 'title': '【問題】nvidia geforce now',
 'userName': '神準'}
2025-01-16 18:10:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139224&tnum=1&bPage=4>
{'content': '之前每次要切換滑鼠跟鍵盤移動都要登入角色選擇畫面才能切換 剛剛無意間發現按紅色框那邊就可以在遊戲內直接切換了! '
            '2025了這UI就不能設計的好看直覺一點嗎...白白一塊還以為是…',
 'img': 'https://truth.bahamut.com.tw/s01/202501/forum/18966/c2ca538dc3ee4eef38b344ce60b2ebb7.JPG?w=300&h=300&fit=o',
 'title': '【密技】切換滑鼠.WASD的方法',
 'userName': 'gary'}
2025-01-16 18:10:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139225&tnum=1&bPage=4>
{'content': '小萌新玩家求解，最近在研究一些技能放副武器（閃現、副手權杖精魂祭祀拿球） '
            '我精魂設置副手，但是平常翻滾沒有閃，要多按切換武器再翻滾才會閃，請問大大們都是這樣嗎，…',
 'img': None,
 'title': '【問題】PS5雙武器疑問',
 'userName': 'Kaws920'}
2025-01-16 18:10:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=138904&tnum=5&bPage=4>
{'content': '有試著再剪一部影片 求推薦一個免費好用的剪輯軟體 目前用兩個都不是很滿意xdd 兩個拓圖技巧: 一、燈塔實際上到底圈到哪裡? '
            '藏身處有BUG是看不到的 目前我知道有兩個方法能看到…',
 'img': 'https://i1.ytimg.com/vi/Y68ImiUOl9g/hqdefault.jpg',
 'title': '【心得】拓圖小技巧與圈地賺錢邏輯分享',
 'userName': '小立'}
2025-01-16 18:10:01 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-16 18:10:01 [selenium.webdriver.remote.remote_connection] DEBUG: DELETE http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af {}
2025-01-16 18:10:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "DELETE /session/dd9226bd0e7ebfbe80a7cd2860d284af HTTP/1.1" 200 14
2025-01-16 18:10:01 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:01 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 10818254,
 'downloader/response_count': 57,
 'downloader/response_status_count/200': 57,
 'elapsed_time_seconds': 48.5865,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 16, 10, 10, 1, 714710, tzinfo=datetime.timezone.utc),
 'item_scraped_count': 50,
 'items_per_minute': None,
 'log_count/DEBUG': 731,
 'log_count/ERROR': 2,
 'log_count/INFO': 10,
 'memusage/max': 60506112,
 'memusage/startup': 60506112,
 'request_depth_max': 4,
 'response_received_count': 57,
 'responses_per_minute': None,
 'scheduler/dequeued': 57,
 'scheduler/dequeued/memory': 57,
 'scheduler/enqueued': 57,
 'scheduler/enqueued/memory': 57,
 'start_time': datetime.datetime(2025, 1, 16, 10, 9, 13, 128210, tzinfo=datetime.timezone.utc)}
2025-01-16 18:10:01 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-16 18:10:39 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: example)
2025-01-16 18:10:39 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.11.0, Python 3.9.6 (default, May  7 2023, 23:32:44) - [Clang 14.0.3 (clang-1403.0.22.14.1)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform macOS-13.2.1-arm64-arm-64bit
2025-01-16 18:10:39 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-16 18:10:39 [asyncio] DEBUG: Using selector: KqueueSelector
2025-01-16 18:10:39 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-16 18:10:39 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-16 18:10:39 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-16 18:10:39 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-16 18:10:39 [scrapy.extensions.telnet] INFO: Telnet Password: 5b1aa728aabc249b
2025-01-16 18:10:39 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-16 18:10:39 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'example',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': '../log/example.log',
 'NEWSPIDER_MODULE': 'example.spiders',
 'SPIDER_MODULES': ['example.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-16 18:10:40 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"extensions": [], "args": ["--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"extensions": [], "args": ["--headless"]}}}
2025-01-16 18:10:40 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:64772
2025-01-16 18:10:41 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session HTTP/1.1" 200 892
2025-01-16 18:10:41 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:41 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy_selenium.SeleniumMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-16 18:10:41 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-16 18:10:41 [scrapy.middleware] INFO: Enabled item pipelines:
['example.pipelines.ExamplePipeline', 'example.pipelines.ExampleDownloadImg']
2025-01-16 18:10:41 [scrapy.core.engine] INFO: Spider opened
2025-01-16 18:10:41 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-16 18:10:41 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-01-16 18:10:41 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {"url": "https://forum.gamer.com.tw/B.php?page=1&bsn=18966"}
2025-01-16 18:10:41 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 14
2025-01-16 18:10:41 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:41 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/source {}
2025-01-16 18:10:41 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/source HTTP/1.1" 200 249249
2025-01-16 18:10:41 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:41 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {}
2025-01-16 18:10:41 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 61
2025-01-16 18:10:41 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/B.php?page=1&bsn=18966> (referer: None)
2025-01-16 18:10:41 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/execute/sync {"script": "return document.body.scrollHeight", "args": []}
2025-01-16 18:10:41 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/execute/sync HTTP/1.1" 200 14
2025-01-16 18:10:41 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:41 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/execute/sync {"script": "window.scrollTo(0, document.body.scrollHeight);", "args": []}
2025-01-16 18:10:41 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/execute/sync HTTP/1.1" 200 14
2025-01-16 18:10:41 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:43 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/execute/sync {"script": "return document.body.scrollHeight", "args": []}
2025-01-16 18:10:43 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/execute/sync HTTP/1.1" 200 14
2025-01-16 18:10:43 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:43 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/execute/sync {"script": "window.scrollTo(0, document.body.scrollHeight);", "args": []}
2025-01-16 18:10:43 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/execute/sync HTTP/1.1" 200 14
2025-01-16 18:10:43 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:46 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/execute/sync {"script": "return document.body.scrollHeight", "args": []}
2025-01-16 18:10:46 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/execute/sync HTTP/1.1" 200 14
2025-01-16 18:10:46 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:46 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/source {}
2025-01-16 18:10:46 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/source HTTP/1.1" 200 252120
2025-01-16 18:10:46 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:46 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {}
2025-01-16 18:10:46 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 61
2025-01-16 18:10:46 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:46 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139283&tnum=2"}
2025-01-16 18:10:46 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 14
2025-01-16 18:10:46 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:46 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/source {}
2025-01-16 18:10:46 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/source HTTP/1.1" 200 155318
2025-01-16 18:10:46 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:46 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {}
2025-01-16 18:10:46 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 72
2025-01-16 18:10:46 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139283&tnum=2> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:10:46 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {"url": "https://forum.gamer.com.tw/B.php?page=2&bsn=18966"}
2025-01-16 18:10:47 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 14
2025-01-16 18:10:47 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:47 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/source {}
2025-01-16 18:10:47 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/source HTTP/1.1" 200 246868
2025-01-16 18:10:47 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:47 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {}
2025-01-16 18:10:47 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 61
2025-01-16 18:10:47 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/B.php?page=2&bsn=18966> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:10:47 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=138700&tnum=5"}
2025-01-16 18:10:47 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 14
2025-01-16 18:10:47 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:47 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/source {}
2025-01-16 18:10:47 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/source HTTP/1.1" 200 215852
2025-01-16 18:10:47 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:47 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {}
2025-01-16 18:10:47 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 72
2025-01-16 18:10:47 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=138700&tnum=5> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:10:47 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139274&tnum=3"}
2025-01-16 18:10:47 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 14
2025-01-16 18:10:47 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:47 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/source {}
2025-01-16 18:10:47 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/source HTTP/1.1" 200 164332
2025-01-16 18:10:47 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:47 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {}
2025-01-16 18:10:47 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 72
2025-01-16 18:10:47 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139274&tnum=3> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:10:47 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139275&tnum=1"}
2025-01-16 18:10:48 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 14
2025-01-16 18:10:48 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:48 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/source {}
2025-01-16 18:10:48 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/source HTTP/1.1" 200 139578
2025-01-16 18:10:48 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:48 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {}
2025-01-16 18:10:48 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 72
2025-01-16 18:10:48 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139275&tnum=1> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:10:48 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139231&tnum=11"}
2025-01-16 18:10:48 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 14
2025-01-16 18:10:48 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:48 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/source {}
2025-01-16 18:10:48 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/source HTTP/1.1" 200 264187
2025-01-16 18:10:48 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:48 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {}
2025-01-16 18:10:48 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 73
2025-01-16 18:10:48 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139231&tnum=11> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:10:48 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=138616&tnum=5"}
2025-01-16 18:10:49 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 14
2025-01-16 18:10:49 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:49 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/source {}
2025-01-16 18:10:49 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/source HTTP/1.1" 200 216156
2025-01-16 18:10:49 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:49 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {}
2025-01-16 18:10:49 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 72
2025-01-16 18:10:49 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=138616&tnum=5> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:10:49 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=138913&tnum=16"}
2025-01-16 18:10:49 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 14
2025-01-16 18:10:49 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:49 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/source {}
2025-01-16 18:10:49 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/source HTTP/1.1" 200 370228
2025-01-16 18:10:49 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:49 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {}
2025-01-16 18:10:49 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 73
2025-01-16 18:10:49 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=138913&tnum=16> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:10:49 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139276&tnum=1"}
2025-01-16 18:10:50 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 14
2025-01-16 18:10:50 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:50 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/source {}
2025-01-16 18:10:50 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/source HTTP/1.1" 200 148144
2025-01-16 18:10:50 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:50 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {}
2025-01-16 18:10:50 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 72
2025-01-16 18:10:50 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139276&tnum=1> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:10:50 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139277&tnum=1"}
2025-01-16 18:10:50 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 14
2025-01-16 18:10:50 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:50 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/source {}
2025-01-16 18:10:50 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/source HTTP/1.1" 200 152907
2025-01-16 18:10:50 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:50 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {}
2025-01-16 18:10:50 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 72
2025-01-16 18:10:50 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139277&tnum=1> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:10:50 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=138031&tnum=19"}
2025-01-16 18:10:51 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 14
2025-01-16 18:10:51 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:51 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/source {}
2025-01-16 18:10:51 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/source HTTP/1.1" 200 479853
2025-01-16 18:10:51 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:51 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {}
2025-01-16 18:10:51 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 73
2025-01-16 18:10:51 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=138031&tnum=19> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:10:51 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=137397&tnum=37"}
2025-01-16 18:10:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 14
2025-01-16 18:10:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:52 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/source {}
2025-01-16 18:10:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/source HTTP/1.1" 200 413454
2025-01-16 18:10:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:52 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {}
2025-01-16 18:10:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 73
2025-01-16 18:10:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=137397&tnum=37> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:10:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=138723&tnum=21"}
2025-01-16 18:10:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 14
2025-01-16 18:10:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:52 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/source {}
2025-01-16 18:10:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/source HTTP/1.1" 200 397263
2025-01-16 18:10:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:52 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {}
2025-01-16 18:10:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 73
2025-01-16 18:10:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=138723&tnum=21> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:10:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=138377&tnum=7"}
2025-01-16 18:10:53 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 14
2025-01-16 18:10:53 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:53 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/source {}
2025-01-16 18:10:53 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/source HTTP/1.1" 200 291313
2025-01-16 18:10:53 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:53 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {}
2025-01-16 18:10:53 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 72
2025-01-16 18:10:53 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=138377&tnum=7> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:10:53 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=138161&tnum=9"}
2025-01-16 18:10:54 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 14
2025-01-16 18:10:54 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:54 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/source {}
2025-01-16 18:10:54 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/source HTTP/1.1" 200 266982
2025-01-16 18:10:54 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:54 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {}
2025-01-16 18:10:54 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 72
2025-01-16 18:10:54 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=138161&tnum=9> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:10:54 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139281&tnum=1"}
2025-01-16 18:10:54 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 14
2025-01-16 18:10:54 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:54 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/source {}
2025-01-16 18:10:54 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/source HTTP/1.1" 200 144359
2025-01-16 18:10:54 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:54 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {}
2025-01-16 18:10:54 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 72
2025-01-16 18:10:54 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139281&tnum=1> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:10:54 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=136522&tnum=120"}
2025-01-16 18:10:55 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 14
2025-01-16 18:10:55 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:55 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/source {}
2025-01-16 18:10:55 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/source HTTP/1.1" 200 613553
2025-01-16 18:10:55 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:55 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {}
2025-01-16 18:10:55 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 74
2025-01-16 18:10:55 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=136522&tnum=120> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:10:55 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139282&tnum=1"}
2025-01-16 18:10:55 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 14
2025-01-16 18:10:55 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:55 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/source {}
2025-01-16 18:10:55 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/source HTTP/1.1" 200 140053
2025-01-16 18:10:55 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:55 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {}
2025-01-16 18:10:55 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 72
2025-01-16 18:10:55 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139282&tnum=1> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:10:55 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139154&tnum=6"}
2025-01-16 18:10:56 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 14
2025-01-16 18:10:56 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:56 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/source {}
2025-01-16 18:10:56 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/source HTTP/1.1" 200 247576
2025-01-16 18:10:56 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:56 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {}
2025-01-16 18:10:56 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 72
2025-01-16 18:10:56 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139154&tnum=6> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:10:56 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139171&tnum=24"}
2025-01-16 18:10:56 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 14
2025-01-16 18:10:56 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:56 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/source {}
2025-01-16 18:10:56 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/source HTTP/1.1" 200 451750
2025-01-16 18:10:56 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:56 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {}
2025-01-16 18:10:56 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 73
2025-01-16 18:10:56 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139171&tnum=24> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:10:56 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139280&tnum=2"}
2025-01-16 18:10:57 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 14
2025-01-16 18:10:57 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:57 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/source {}
2025-01-16 18:10:57 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/source HTTP/1.1" 200 159087
2025-01-16 18:10:57 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:57 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {}
2025-01-16 18:10:57 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 72
2025-01-16 18:10:57 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139280&tnum=2> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:10:57 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139238&tnum=13"}
2025-01-16 18:10:57 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 14
2025-01-16 18:10:57 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:57 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/source {}
2025-01-16 18:10:57 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/source HTTP/1.1" 200 314701
2025-01-16 18:10:57 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:57 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {}
2025-01-16 18:10:57 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 73
2025-01-16 18:10:57 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139238&tnum=13> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:10:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139283&tnum=2>
{'content': '我花兩分鐘就是為了插一張碑文 那幹嘛不直接讓我路過直插就好了 裡面又沒什麼特殊經濟單位怪讓我打 輿圖抄LE抄成這樣 '
            '不如照搬LE的的塔 裡面直接放一個BOSS打完就加類似雕文效…',
 'img': 'https://truth.bahamut.com.tw/s01/202501/forum/18966/c85354234d3c5862f128fd5529d949d9.JPG?w=300&h=300&fit=o',
 'title': '【問題】其實我一直覺得要進入失落之塔很沒意義',
 'userName': '維尼坦克車'}
2025-01-16 18:10:57 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/execute/sync {"script": "return document.body.scrollHeight", "args": []}
2025-01-16 18:10:57 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/execute/sync HTTP/1.1" 200 14
2025-01-16 18:10:57 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:57 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/execute/sync {"script": "window.scrollTo(0, document.body.scrollHeight);", "args": []}
2025-01-16 18:10:57 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/execute/sync HTTP/1.1" 200 14
2025-01-16 18:10:57 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:59 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/execute/sync {"script": "return document.body.scrollHeight", "args": []}
2025-01-16 18:10:59 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/execute/sync HTTP/1.1" 200 14
2025-01-16 18:10:59 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:59 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/source {}
2025-01-16 18:10:59 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/source HTTP/1.1" 200 317778
2025-01-16 18:10:59 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:59 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {}
2025-01-16 18:10:59 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 73
2025-01-16 18:10:59 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:59 [scrapy.core.scraper] ERROR: Error processing {'content': '一、前言最近想趁 GGG 大刀闊斧之前跟風玩電法，但對於其中感電時施放這個技能有的觸發機制有疑慮，很多 BD '
            '介紹也沒有特別去提，作為第一次玩 POE 的玩家，目前有錄影將感電過…',
 'img': 'https://truth.bahamut.com.tw/s01/202501/forum/18966/8b27d3635e75d203c8db8b2962bd3b11.JPG?w=300&h=300&fit=o',
 'title': '【心得】感電時施放，觸發機制詢問 (已解決，更新：2025/1/15)',
 'userName': '葳葳'}
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/utils/defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/Users/admin/PycharmProjects/WebCrawler/a_scrapy/example/example/pipelines.py", line 42, in process_item
    request.urlretrieve(url=url, filename=filename)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/urllib/request.py", line 249, in urlretrieve
    tfp = open(filename, 'wb')
FileNotFoundError: [Errno 2] No such file or directory: '../download/imgs/【心得】感電時施放，觸發機制詢問 (已解決，更新：2025/1/15).jpg'
2025-01-16 18:10:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139274&tnum=3>
{'content': 'https://ithome.com.tw/news/166964 '
            '遊戲《流亡黯道2》在搶先體驗階段爆發資安事件，駭客駭入管理者帳號，影響至少66名玩家，損失高價值遊戲資產，開發商GGG承認系統安全漏洞並宣布改進…',
 'img': None,
 'title': '【情報】《流亡黯道2》管理者帳號被駭，玩家資產損失無法追回',
 'userName': 'jacket6719'}
2025-01-16 18:10:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139275&tnum=1>
{'content': 'poe純新手 第一次分享拍片若有錯誤請留言糾正討論感謝你 這個BD簡單有趣 只需一鍵 但是不強 小心一點還是可以在t14 15走走 '
            '影片連結 或是到我的twitch: 聊聊也可以',
 'img': 'https://i1.ytimg.com/vi/WTOkTcOK01I/hqdefault.jpg',
 'title': '【心得】霍格華茲畢業的黑僧 去去詛咒走',
 'userName': '月仔'}
2025-01-16 18:10:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139231&tnum=11>
{'content': '前言:非CI 不撐混抗 容量1萬! 天賦: '
            '藥劑選擇：主要要有傳奇藥劑MP水(必備)因為會先扣魔再扣血加上暴風亂舞速度快!噴魔速度比喝水還快 裝備選擇： ◉武器/副手: '
            '◉胸甲 ◉頭盔 ◉…',
 'img': 'https://truth.bahamut.com.tw/s01/202501/forum/18966/98e4358b6a1f12f52901027f80f1915d.JPG?w=300&h=300&fit=o',
 'title': '【心得】百萬古靈囚神杖!高配版天賦及配置分享',
 'userName': 'az5504156'}
2025-01-16 18:11:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=138616&tnum=5>
{'content': '不建議現在抄.建議等GGG放假回來更新後看看狀況 影片內有天賦跟裝備 補一個造價 大約25D '
            '項鍊.完美工匠.20等彗星佔一大半,項鍊不找法術等級的話很便宜 但消耗跟魔力上限要再另外…',
 'img': 'https://i1.ytimg.com/vi/C8ubRMKVFG8/hqdefault.jpg',
 'title': '【討論】屏障祈願惡魔彗星(五樓小更新)',
 'userName': '天啊你真高'}
2025-01-16 18:11:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=138913&tnum=16>
{'content': '我想各位冰骷髏的玩家~在與圖的過程中肯定被白癡一般的AI噁心到不能自理吧 所以這邊分享一個全新的冰骷髏思路來拯救你的與圖體驗 '
            '隨時可以與輪椅流派切換，讓你在與圖與王戰…',
 'img': None,
 'title': '【攻略】冰骷髏炸彈BUILD 拯救召喚與圖體驗全靠這招!!!',
 'userName': '菠蘿貓'}
2025-01-16 18:11:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139276&tnum=1>
{'content': '受控的蛻變 鑽石：裂痕王 搜尋器選擇： 「只會影響極小範圍內的天賦」 後面的最小最大值可以選 1～8，代表從極小到巨大 '
            '抗性詞綴是基本的查詢，應該不用特別講解 配上 https://max…',
 'img': 'https://truth.bahamut.com.tw/s01/202501/forum/18966/7e5589db4dbde93c002c40f938f327bd.JPG?w=300&h=300&fit=o',
 'title': '【心得】交易所傳奇珠寶查詢方式，台版（國際應該同樣方式）',
 'userName': '影˙焰'}
2025-01-16 18:11:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139277&tnum=1>
{'content': 'https://www.pixiv.net/artworks/125927689 物品稀有度16%、國際服物價。 '
            '收益來源大致能分為： 基礎收益： 1.油 2.融解漩渦(傳奇魔水) 靠賽收益： 3.鑑定/做裝收益 4.妄想症 1.油： 數量 '
            '油:EX EX…',
 'img': 'https://truth.bahamut.com.tw/s01/202501/forum/18966/de8451ed4907cd51622081300a329b38.JPG?w=300&h=300&fit=o',
 'title': '【心得】T4幻象異界50張測試',
 'userName': '芋頭'}
2025-01-16 18:11:00 [scrapy.core.scraper] ERROR: Error processing {'content': 'Never sink編輯網站已上線！目前正在施工Neversink_Strict，將他的分級制度跟我的顏色合併。 '
            '在官網追蹤後就會自動更新，不用一直下載！ 訂閱後（限國際服），就不用下載了，只要按…',
 'img': 'https://truth.bahamut.com.tw/s01/202412/forum/18966/75848e01cf1a2cb2ecb3203b65809fd4.JPG?w=300&h=300&fit=o',
 'title': '【和色過濾器】1/14 Neversink版本測試',
 'userName': '摳捷'}
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/utils/defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/Users/admin/PycharmProjects/WebCrawler/a_scrapy/example/example/pipelines.py", line 42, in process_item
    request.urlretrieve(url=url, filename=filename)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/urllib/request.py", line 249, in urlretrieve
    tfp = open(filename, 'wb')
FileNotFoundError: [Errno 2] No such file or directory: '../download/imgs/【和色過濾器】1/14 Neversink版本測試.jpg'
2025-01-16 18:11:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=137397&tnum=37>
{'content': '前言: 本文轉載自reddit poe 版原文，我負責翻譯跟校對 給剛入門的朋友: '
            '開發商GGG有承諾，所有POE1的商城物品都能通用到POE2 但由於目前是EA(搶先體驗) 階段，故有部分商城物品是還沒…',
 'img': None,
 'title': '【攻略】POE 1&2 通用商城物品一覽表',
 'userName': 'baha0079'}
2025-01-16 18:11:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=138723&tnum=21>
{'content': '影片 天賦 章節天賦 (囚神杵) 血盾天賦 (囚神杵/稀有杖) 轉CI天賦 (囚神杵/稀有杖) 屬性天賦 (囚神杵) '
            '昇華的如急流瀑布(冰點)和若非獨自一人必點(精魂)，剩下兩個可以任意搭配，如…',
 'img': None,
 'title': '【心得】POE 2 武僧囚神杵低配版 十個崇高 一鐘近百萬 1/12 新增稀有杖裂痕四',
 'userName': '隨風飄逝'}
2025-01-16 18:11:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=138377&tnum=7>
{'content': '各位好，我是Ruz，你也可以叫我Rain。 這次為大家帶來的是淺井長政時空術師。 一個打王很強的build。 流派優缺點 優點： '
            '‧T0級別的打王 ‧時空術士自帶時空鎖鏈光環，這東西真的…',
 'img': None,
 'title': '【心得】手把手帶你只用1D組一隻能無傷通這遊戲所有BOSS的時空接技法 ,feat COC , 冰法 更新：改版指南',
 'userName': 'Ruz'}
2025-01-16 18:11:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=138161&tnum=9>
{'content': '重發 先感謝DC群的大佬們依依回答,對於老鳥或是新手們對於這東西有不知道的 看這表會比較明白 '
            '目前已知的有這些,有人知道的可以補充在下方 明日會再修改圖表',
 'img': None,
 'title': '【密技】圖騰是我,我不是圖騰',
 'userName': '楊楊'}
2025-01-16 18:11:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139281&tnum=1>
{'content': '這遊戲精彩又可惜 就像跨年煙火 燦爛但短暫 但能這樣也沒有太多怨言 精彩的是承接了D1 D2的美好 可惜的是 似乎還沒有決心去離開 '
            'D2 開始所謂的 一鍵清怪 與 打寶風氣 玩到接近90級…',
 'img': None,
 'title': '【問題】poe2 好遊戲 小感想',
 'userName': 'evilalways'}
2025-01-16 18:11:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=136522&tnum=120>
{'content': '》目錄《 ✦拓荒✦ ✦裝備✦ ✦技能✦ ✦天賦✦ ✦影片✦ (ctrl+f可輸入關鍵字搜尋) 12/11 '
            '更新成形技能串法、裝備基底敘述，新增畢業天賦、部分附註、過濾器 12/13 更新技能翻譯名…',
 'img': None,
 'title': '【攻略】[星月]-POE2 骷髏縱火者 火系召喚拓荒分享(1/2 更新無火牆玩法、過濾器、裝備詞綴',
 'userName': '星月'}
2025-01-16 18:11:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139282&tnum=1>
{'content': '如題 請問如果都是+10%的狀況下哪一個對於近戰的技能施放速度會比較多?',
 'img': None,
 'title': '【問題】請問技能速度跟攻擊速度哪個對近戰技能施放速度的影響比較多?',
 'userName': 'PosiVibe'}
2025-01-16 18:11:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139154&tnum=6>
{'content': '安安== 此圖鑑純屬學術研究為目的 重練了幾次，發現都還沒靜下心來細細的欣賞2的模組 於是就放慢步調邊玩邊欣賞 '
            '圖鑑順序是照著任務排序 所以就讓我們藉由認識女NPC 再一起重跑…',
 'img': None,
 'title': '【討論】邊玩邊拍照於是收集了一本女NPC圖鑑 (偽劇情攻略)',
 'userName': '不要使用特殊符號字元'}
2025-01-16 18:11:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139171&tnum=24>
{'content': '我是個喜歡玩暗黑類刷寶遊戲的老玩家 一整年除了幾個特定的單機遊戲 我現在大概就是D4 /POE2/火炬 賽季輪著玩 '
            '其實火炬之光對比其他兩者來說 遊戲/劇情/畫面/深度都不在同一個水…',
 'img': None,
 'title': '【討論】 期待POE2的拍賣場可參考隔壁棚的火炬之光再優化',
 'userName': 'allen'}
2025-01-16 18:11:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139280&tnum=2>
{'content': '市集密了一件裝備1D沒有回應， 約5分鐘後賣家改價5D，我密他說這價格我ok 隨後賣家組我進隊伍，要求隊伍內玩家競標?_? '
            '改價遇的多了 第一次遇到把人組起來競標的 真的是大開眼界…',
 'img': None,
 'title': '【閒聊】改價獸進化 競標獸',
 'userName': '好好先生'}
2025-01-16 18:11:00 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=136809&tnum=154"}
2025-01-16 18:11:00 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 14
2025-01-16 18:11:00 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:11:00 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/source {}
2025-01-16 18:11:00 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/source HTTP/1.1" 200 436700
2025-01-16 18:11:00 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:11:00 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {}
2025-01-16 18:11:00 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 74
2025-01-16 18:11:00 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:11:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=136809&tnum=154> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:11:00 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139278&tnum=24"}
2025-01-16 18:11:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 14
2025-01-16 18:11:01 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:11:01 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/source {}
2025-01-16 18:11:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/source HTTP/1.1" 200 486210
2025-01-16 18:11:01 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:11:01 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {}
2025-01-16 18:11:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 73
2025-01-16 18:11:01 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:11:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139278&tnum=24> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:11:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139238&tnum=13>
{'content': '各位安安，我是森林露 前言: 本人算是POE老屁股，一代測試玩到二代測試的玩家， '
            '二代吸引到許多新玩家入坑，身為老玩家也為這款遊戲感到高興。 但...二代的王戰相較一代難上許…',
 'img': 'https://truth.bahamut.com.tw/s01/202501/forum/18966/562818bb7e9382fdb0637dff8f6ae9e4.JPG?w=300&h=300&fit=o',
 'title': '【閒聊】關於二代遊戲風氣...',
 'userName': '森林鹿'}
2025-01-16 18:11:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=136809&tnum=154>
{'content': 'POE2把改造、重鑄、工藝台和各種做裝能力都拔掉之後，現在裝備重點基本上是找好基底點藍點黃，拿崇高點出好詞真快樂，簡單樸實。 '
            '好裝的的出現難度顯著提升，因此他們的價值…',
 'img': 'https://truth.bahamut.com.tw/s01/202412/forum/18966/404f00297ce9b876763a192534b2e3e9.JPG?w=300&h=300&fit=o',
 'title': '【閒聊】POE2裝備展示區～秀秀你的裝備吧',
 'userName': 'War'}
2025-01-16 18:11:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139278&tnum=24>
{'content': 'https://www.pathofexile.com/forum/view-thread/3695606/page/1#p25859331 '
            '預計明天1/17更新 翻譯僅供參考 沒辦法詳細校對 此篇後其他討論串會隱藏處理 終局改動 新增 4 個塔地圖區域：「阿爾卑斯山脊…',
 'img': None,
 'title': '【情報】Poe 2 0.1.1 Patch note 集中討論串',
 'userName': '33456109'}
2025-01-16 18:11:01 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-16 18:11:01 [selenium.webdriver.remote.remote_connection] DEBUG: DELETE http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2 {}
2025-01-16 18:11:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "DELETE /session/7703334f5929294336fc39eea45829a2 HTTP/1.1" 200 14
2025-01-16 18:11:01 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:11:01 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 6141261,
 'downloader/response_count': 25,
 'downloader/response_status_count/200': 25,
 'elapsed_time_seconds': 20.462011,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 16, 10, 11, 1, 748929, tzinfo=datetime.timezone.utc),
 'item_scraped_count': 21,
 'items_per_minute': None,
 'log_count/DEBUG': 319,
 'log_count/ERROR': 2,
 'log_count/INFO': 10,
 'memusage/max': 60309504,
 'memusage/startup': 60309504,
 'request_depth_max': 1,
 'response_received_count': 25,
 'responses_per_minute': None,
 'scheduler/dequeued': 25,
 'scheduler/dequeued/memory': 25,
 'scheduler/enqueued': 25,
 'scheduler/enqueued/memory': 25,
 'start_time': datetime.datetime(2025, 1, 16, 10, 10, 41, 286918, tzinfo=datetime.timezone.utc)}
2025-01-16 18:11:01 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-16 18:14:08 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: example)
2025-01-16 18:14:08 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.11.0, Python 3.9.6 (default, May  7 2023, 23:32:44) - [Clang 14.0.3 (clang-1403.0.22.14.1)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform macOS-13.2.1-arm64-arm-64bit
2025-01-16 18:14:08 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-16 18:14:08 [asyncio] DEBUG: Using selector: KqueueSelector
2025-01-16 18:14:08 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-16 18:14:08 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-16 18:14:08 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-16 18:14:08 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-16 18:14:08 [scrapy.extensions.telnet] INFO: Telnet Password: 8cc1d37767ea001f
2025-01-16 18:14:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-16 18:14:08 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'example',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': '../log/example.log',
 'NEWSPIDER_MODULE': 'example.spiders',
 'SPIDER_MODULES': ['example.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-16 18:14:09 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"extensions": [], "args": ["--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"extensions": [], "args": ["--headless"]}}}
2025-01-16 18:14:09 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:49387
2025-01-16 18:14:09 [urllib3.connectionpool] DEBUG: http://127.0.0.1:49387 "POST /session HTTP/1.1" 200 892
2025-01-16 18:14:09 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:14:09 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy_selenium.SeleniumMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-16 18:14:09 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-16 18:14:09 [scrapy.middleware] INFO: Enabled item pipelines:
['example.pipelines.ExamplePipeline', 'example.pipelines.ExampleDownloadImg']
2025-01-16 18:14:09 [scrapy.core.engine] INFO: Spider opened
2025-01-16 18:14:09 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-16 18:14:09 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-01-16 18:14:09 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/url {"url": "https://forum.gamer.com.tw/B.php?page=1&bsn=18966"}
2025-01-16 18:14:10 [urllib3.connectionpool] DEBUG: http://127.0.0.1:49387 "POST /session/55a9a26597a550e1a0efbc46b6615891/url HTTP/1.1" 200 14
2025-01-16 18:14:10 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:14:10 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/source {}
2025-01-16 18:14:10 [urllib3.connectionpool] DEBUG: http://127.0.0.1:49387 "GET /session/55a9a26597a550e1a0efbc46b6615891/source HTTP/1.1" 200 248991
2025-01-16 18:14:10 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:14:10 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/url {}
2025-01-16 18:14:10 [urllib3.connectionpool] DEBUG: http://127.0.0.1:49387 "GET /session/55a9a26597a550e1a0efbc46b6615891/url HTTP/1.1" 200 61
2025-01-16 18:14:10 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:14:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/B.php?page=1&bsn=18966> (referer: None)
2025-01-16 18:14:10 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/execute/sync {"script": "return document.body.scrollHeight", "args": []}
2025-01-16 18:14:10 [urllib3.connectionpool] DEBUG: http://127.0.0.1:49387 "POST /session/55a9a26597a550e1a0efbc46b6615891/execute/sync HTTP/1.1" 200 14
2025-01-16 18:14:10 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:14:10 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/execute/sync {"script": "window.scrollTo(0, document.body.scrollHeight);", "args": []}
2025-01-16 18:14:10 [urllib3.connectionpool] DEBUG: http://127.0.0.1:49387 "POST /session/55a9a26597a550e1a0efbc46b6615891/execute/sync HTTP/1.1" 200 14
2025-01-16 18:14:10 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:14:12 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/execute/sync {"script": "return document.body.scrollHeight", "args": []}
2025-01-16 18:14:12 [urllib3.connectionpool] DEBUG: http://127.0.0.1:49387 "POST /session/55a9a26597a550e1a0efbc46b6615891/execute/sync HTTP/1.1" 200 14
2025-01-16 18:14:12 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:14:12 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/execute/sync {"script": "window.scrollTo(0, document.body.scrollHeight);", "args": []}
2025-01-16 18:14:12 [urllib3.connectionpool] DEBUG: http://127.0.0.1:49387 "POST /session/55a9a26597a550e1a0efbc46b6615891/execute/sync HTTP/1.1" 200 14
2025-01-16 18:14:12 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:14:14 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/execute/sync {"script": "return document.body.scrollHeight", "args": []}
2025-01-16 18:14:14 [urllib3.connectionpool] DEBUG: http://127.0.0.1:49387 "POST /session/55a9a26597a550e1a0efbc46b6615891/execute/sync HTTP/1.1" 200 14
2025-01-16 18:14:14 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:14:14 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/source {}
2025-01-16 18:14:14 [urllib3.connectionpool] DEBUG: http://127.0.0.1:49387 "GET /session/55a9a26597a550e1a0efbc46b6615891/source HTTP/1.1" 200 252130
2025-01-16 18:14:14 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:14:14 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/url {}
2025-01-16 18:14:14 [urllib3.connectionpool] DEBUG: http://127.0.0.1:49387 "GET /session/55a9a26597a550e1a0efbc46b6615891/url HTTP/1.1" 200 61
2025-01-16 18:14:14 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:14:14 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139283&tnum=2"}
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: http://127.0.0.1:49387 "POST /session/55a9a26597a550e1a0efbc46b6615891/url HTTP/1.1" 200 14
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/source {}
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: http://127.0.0.1:49387 "GET /session/55a9a26597a550e1a0efbc46b6615891/source HTTP/1.1" 200 155416
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/url {}
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: http://127.0.0.1:49387 "GET /session/55a9a26597a550e1a0efbc46b6615891/url HTTP/1.1" 200 72
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:14:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139283&tnum=2> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/url {"url": "https://forum.gamer.com.tw/B.php?page=2&bsn=18966"}
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: http://127.0.0.1:49387 "POST /session/55a9a26597a550e1a0efbc46b6615891/url HTTP/1.1" 200 14
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/source {}
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: http://127.0.0.1:49387 "GET /session/55a9a26597a550e1a0efbc46b6615891/source HTTP/1.1" 200 246812
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/url {}
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: http://127.0.0.1:49387 "GET /session/55a9a26597a550e1a0efbc46b6615891/url HTTP/1.1" 200 61
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:14:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/B.php?page=2&bsn=18966> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=138700&tnum=5"}
2025-01-16 18:14:15 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: http://127.0.0.1:49387 "POST /session/55a9a26597a550e1a0efbc46b6615891/url HTTP/1.1" 200 14
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/source {}
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Resetting dropped connection: 127.0.0.1
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/source'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104c371f0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/source
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (2): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/source'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104d8ebe0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/source
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (3): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/source'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104d8e220>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/source
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (4): 127.0.0.1:49387
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139274&tnum=3"}
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (5): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104dc92e0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (6): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104dc90d0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (7): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104db9e20>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (8): 127.0.0.1:49387
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139275&tnum=1"}
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (9): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104db9af0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (10): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104db98b0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (11): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e040a0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (12): 127.0.0.1:49387
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139231&tnum=11"}
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (13): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e04d90>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (14): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e04f40>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (15): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e0a070>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (16): 127.0.0.1:49387
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=138616&tnum=5"}
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (17): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e0ad60>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (18): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e0af10>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (19): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e19070>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (20): 127.0.0.1:49387
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=138913&tnum=16"}
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (21): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e19d30>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (22): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104d8e2e0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (23): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e19ee0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (24): 127.0.0.1:49387
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139276&tnum=1"}
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (25): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e25c10>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (26): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e25dc0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (27): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e25eb0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (28): 127.0.0.1:49387
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139277&tnum=1"}
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (29): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e35be0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (30): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e35d90>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (31): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e35e80>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (32): 127.0.0.1:49387
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=138031&tnum=19"}
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (33): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e47bb0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (34): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e47d60>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (35): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e47e50>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (36): 127.0.0.1:49387
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=137397&tnum=37"}
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (37): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e56b80>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (38): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e56d30>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (39): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e56e20>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (40): 127.0.0.1:49387
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=138723&tnum=21"}
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (41): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e62b50>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (42): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e62d00>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (43): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e62df0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (44): 127.0.0.1:49387
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=138377&tnum=7"}
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (45): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e75b20>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (46): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e75cd0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (47): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e75dc0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (48): 127.0.0.1:49387
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=138161&tnum=9"}
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (49): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e85af0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (50): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e85ca0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (51): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e85d90>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (52): 127.0.0.1:49387
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139281&tnum=1"}
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (53): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e92ac0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (54): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e92c70>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (55): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e92d60>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (56): 127.0.0.1:49387
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=136522&tnum=120"}
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (57): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104ea5a90>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (58): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104ea5c40>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (59): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104ea5d30>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (60): 127.0.0.1:49387
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139282&tnum=1"}
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (61): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104eb4a60>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (62): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104eb4c10>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (63): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104eb4d00>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (64): 127.0.0.1:49387
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139154&tnum=6"}
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (65): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104ec4a30>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (66): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104ec4be0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (67): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104ec4cd0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (68): 127.0.0.1:49387
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139171&tnum=24"}
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (69): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x105101a00>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (70): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x105101bb0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (71): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x105101ca0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (72): 127.0.0.1:49387
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139280&tnum=2"}
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (73): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x1051109d0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (74): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x105110b80>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (75): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x105110c70>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (76): 127.0.0.1:49387
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139238&tnum=13"}
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (77): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10511c9a0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (78): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10511cb50>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (79): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10511cc40>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (80): 127.0.0.1:49387
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=136809&tnum=154"}
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (81): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10512e970>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (82): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10512eb20>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (83): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10512ec10>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (84): 127.0.0.1:49387
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139278&tnum=24"}
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (85): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x1051408e0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (86): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x105140a90>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (87): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x105140b80>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (88): 127.0.0.1:49387
2025-01-16 18:14:15 [scrapy.core.engine] INFO: Closing spider (shutdown)
2025-01-16 18:14:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139283&tnum=2>
{'content': '我花兩分鐘就是為了插一張碑文 那幹嘛不直接讓我路過直插就好了 裡面又沒什麼特殊經濟單位怪讓我打 輿圖抄LE抄成這樣 '
            '不如照搬LE的的塔 裡面直接放一個BOSS打完就加類似雕文效…',
 'img': 'https://truth.bahamut.com.tw/s01/202501/forum/18966/c85354234d3c5862f128fd5529d949d9.JPG?w=300&h=300&fit=o',
 'title': '【問題】其實我一直覺得要進入失落之塔很沒意義',
 'userName': '維尼坦克車'}
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/execute/sync {"script": "return document.body.scrollHeight", "args": []}
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (89): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/execute/sync'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x1051c4070>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/execute/sync
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (90): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/execute/sync'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x1051c4160>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/execute/sync
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (91): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/execute/sync'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x1051c42b0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/execute/sync
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (92): 127.0.0.1:49387
2025-01-16 18:14:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://forum.gamer.com.tw/B.php?page=2&bsn=18966> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x1051c4400>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/utils/defer.py", line 327, in iter_errback
    yield next(it)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 368, in __next__
    return next(self.data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 368, in __next__
    return next(self.data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 379, in <genexpr>
    return (self._set_referer(r, response) for r in result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 57, in <genexpr>
    return (r for r in result if self._filter(r, spider))
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 54, in <genexpr>
    return (r for r in result if self._filter(r, response, spider))
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/Users/admin/PycharmProjects/WebCrawler/a_scrapy/example/example/spiders/game_content.py", line 49, in parse
    last_height = driver.execute_script("return document.body.scrollHeight")
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 634, in execute_script
    return self.execute(command, {
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=49387): Max retries exceeded with url: /session/55a9a26597a550e1a0efbc46b6615891/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x1051c4400>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:14:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=138700&tnum=5>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x104d8eb20>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 105, in process_request
    body = str.encode(self.driver.page_source)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 77, in request
    return self.request_encode_url(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 99, in request_encode_url
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=49387): Max retries exceeded with url: /session/55a9a26597a550e1a0efbc46b6615891/source (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104d8eb20>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:14:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139274&tnum=3>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x104db9970>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=49387): Max retries exceeded with url: /session/55a9a26597a550e1a0efbc46b6615891/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104db9970>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:14:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139275&tnum=1>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x104e04220>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=49387): Max retries exceeded with url: /session/55a9a26597a550e1a0efbc46b6615891/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e04220>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:14:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139231&tnum=11>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x104e0a1f0>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=49387): Max retries exceeded with url: /session/55a9a26597a550e1a0efbc46b6615891/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e0a1f0>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:14:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=138616&tnum=5>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x104e191c0>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=49387): Max retries exceeded with url: /session/55a9a26597a550e1a0efbc46b6615891/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e191c0>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:14:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=138913&tnum=16>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x104e250a0>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=49387): Max retries exceeded with url: /session/55a9a26597a550e1a0efbc46b6615891/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e250a0>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:14:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139276&tnum=1>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x104e35070>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=49387): Max retries exceeded with url: /session/55a9a26597a550e1a0efbc46b6615891/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e35070>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:14:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139277&tnum=1>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x104e47070>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=49387): Max retries exceeded with url: /session/55a9a26597a550e1a0efbc46b6615891/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e47070>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:14:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=138031&tnum=19>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x104e56040>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=49387): Max retries exceeded with url: /session/55a9a26597a550e1a0efbc46b6615891/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e56040>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:14:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=137397&tnum=37>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x104e62070>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=49387): Max retries exceeded with url: /session/55a9a26597a550e1a0efbc46b6615891/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e62070>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:14:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=138723&tnum=21>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x104e75040>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=49387): Max retries exceeded with url: /session/55a9a26597a550e1a0efbc46b6615891/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e75040>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:14:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=138377&tnum=7>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x104e75f40>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=49387): Max retries exceeded with url: /session/55a9a26597a550e1a0efbc46b6615891/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e75f40>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:14:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=138161&tnum=9>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x104e85f10>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=49387): Max retries exceeded with url: /session/55a9a26597a550e1a0efbc46b6615891/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e85f10>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:14:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139281&tnum=1>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x104e92ee0>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=49387): Max retries exceeded with url: /session/55a9a26597a550e1a0efbc46b6615891/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e92ee0>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:14:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=136522&tnum=120>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x104ea5eb0>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=49387): Max retries exceeded with url: /session/55a9a26597a550e1a0efbc46b6615891/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104ea5eb0>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:14:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139282&tnum=1>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x104eb4e80>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=49387): Max retries exceeded with url: /session/55a9a26597a550e1a0efbc46b6615891/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104eb4e80>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:14:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139154&tnum=6>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x104ec4e50>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=49387): Max retries exceeded with url: /session/55a9a26597a550e1a0efbc46b6615891/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104ec4e50>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:14:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139171&tnum=24>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x105101e20>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=49387): Max retries exceeded with url: /session/55a9a26597a550e1a0efbc46b6615891/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x105101e20>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:14:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139280&tnum=2>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x105110df0>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=49387): Max retries exceeded with url: /session/55a9a26597a550e1a0efbc46b6615891/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x105110df0>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:14:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139238&tnum=13>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x10511cdc0>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=49387): Max retries exceeded with url: /session/55a9a26597a550e1a0efbc46b6615891/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10511cdc0>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:14:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=136809&tnum=154>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x10512ed90>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=49387): Max retries exceeded with url: /session/55a9a26597a550e1a0efbc46b6615891/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10512ed90>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:14:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139278&tnum=24>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x105140d00>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=49387): Max retries exceeded with url: /session/55a9a26597a550e1a0efbc46b6615891/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x105140d00>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:14:15 [scrapy.crawler] INFO: Received SIGINT twice, forcing unclean shutdown
2025-01-16 22:16:26 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: example)
2025-01-16 22:16:26 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.11.0, Python 3.10.16 (main, Jan 16 2025, 13:43:45) [Clang 13.1.6 (clang-1316.0.21.2.5)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform macOS-12.2.1-x86_64-i386-64bit
2025-01-16 22:16:26 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-16 22:16:26 [asyncio] DEBUG: Using selector: KqueueSelector
2025-01-16 22:16:26 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-16 22:16:26 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-16 22:16:26 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-16 22:16:26 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-16 22:16:26 [scrapy.extensions.telnet] INFO: Telnet Password: e846f8b1c4e8b169
2025-01-16 22:16:26 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-16 22:16:26 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'example',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': '../log/example.log',
 'NEWSPIDER_MODULE': 'example.spiders',
 'SPIDER_MODULES': ['example.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-16 22:16:26 [twisted] CRITICAL: Unhandled error in Deferred:
2025-01-16 22:16:26 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/common/service.py", line 72, in start
    self.process = subprocess.Popen(cmd, env=self.env,
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/subprocess.py", line 971, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/subprocess.py", line 1863, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/admin/.wdm/drivers/chromedriver/mac64/131.0.6778.264/chromedriver-mac-arm64/chromedriver'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/crawler.py", line 152, in crawl
    self.engine = self._create_engine()
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/crawler.py", line 166, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/core/engine.py", line 101, in __init__
    self.downloader: Downloader = downloader_cls(crawler)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/core/downloader/__init__.py", line 109, in __init__
    DownloaderMiddlewareManager.from_crawler(crawler)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/middleware.py", line 77, in from_crawler
    return cls._from_settings(crawler.settings, crawler)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/middleware.py", line 88, in _from_settings
    mw = build_from_crawler(mwcls, crawler)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/utils/misc.py", line 187, in build_from_crawler
    instance = objcls.from_crawler(crawler, *args, **kwargs)  # type: ignore[attr-defined]
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy_selenium/middlewares.py", line 67, in from_crawler
    middleware = cls(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy_selenium/middlewares.py", line 51, in __init__
    self.driver = driver_klass(**driver_kwargs)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/chrome/webdriver.py", line 73, in __init__
    self.service.start()
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/common/service.py", line 81, in start
    raise WebDriverException(
selenium.common.exceptions.WebDriverException: Message: 'chromedriver' executable needs to be in PATH. Please see https://sites.google.com/a/chromium.org/chromedriver/home

2025-01-16 22:17:02 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: example)
2025-01-16 22:17:02 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.11.0, Python 3.10.16 (main, Jan 16 2025, 13:43:45) [Clang 13.1.6 (clang-1316.0.21.2.5)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform macOS-12.2.1-x86_64-i386-64bit
2025-01-16 22:17:02 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-16 22:17:02 [asyncio] DEBUG: Using selector: KqueueSelector
2025-01-16 22:17:02 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-16 22:17:02 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-16 22:17:02 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-16 22:17:02 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-16 22:17:02 [scrapy.extensions.telnet] INFO: Telnet Password: 085744b1446bd135
2025-01-16 22:17:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-16 22:17:02 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'example',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': '../log/example.log',
 'NEWSPIDER_MODULE': 'example.spiders',
 'SPIDER_MODULES': ['example.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-16 22:17:02 [twisted] CRITICAL: Unhandled error in Deferred:
2025-01-16 22:17:02 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/common/service.py", line 72, in start
    self.process = subprocess.Popen(cmd, env=self.env,
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/subprocess.py", line 971, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/subprocess.py", line 1863, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/admin/.wdm/drivers/chromedriver/mac64/131.0.6778.264/chromedriver-mac-arm64/chromedriver'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/crawler.py", line 152, in crawl
    self.engine = self._create_engine()
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/crawler.py", line 166, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/core/engine.py", line 101, in __init__
    self.downloader: Downloader = downloader_cls(crawler)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/core/downloader/__init__.py", line 109, in __init__
    DownloaderMiddlewareManager.from_crawler(crawler)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/middleware.py", line 77, in from_crawler
    return cls._from_settings(crawler.settings, crawler)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/middleware.py", line 88, in _from_settings
    mw = build_from_crawler(mwcls, crawler)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/utils/misc.py", line 187, in build_from_crawler
    instance = objcls.from_crawler(crawler, *args, **kwargs)  # type: ignore[attr-defined]
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy_selenium/middlewares.py", line 67, in from_crawler
    middleware = cls(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy_selenium/middlewares.py", line 51, in __init__
    self.driver = driver_klass(**driver_kwargs)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/chrome/webdriver.py", line 73, in __init__
    self.service.start()
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/common/service.py", line 81, in start
    raise WebDriverException(
selenium.common.exceptions.WebDriverException: Message: 'chromedriver' executable needs to be in PATH. Please see https://sites.google.com/a/chromium.org/chromedriver/home

2025-01-16 22:22:09 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: example)
2025-01-16 22:22:09 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.11.0, Python 3.10.16 (main, Jan 16 2025, 13:43:45) [Clang 13.1.6 (clang-1316.0.21.2.5)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform macOS-12.2.1-x86_64-i386-64bit
2025-01-16 22:22:09 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-16 22:22:09 [asyncio] DEBUG: Using selector: KqueueSelector
2025-01-16 22:22:09 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-16 22:22:09 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-16 22:22:09 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-16 22:22:09 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-16 22:22:09 [scrapy.extensions.telnet] INFO: Telnet Password: 8eba7648bacb2549
2025-01-16 22:22:09 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-16 22:22:09 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'example',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': '../log/example.log',
 'NEWSPIDER_MODULE': 'example.spiders',
 'SPIDER_MODULES': ['example.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-16 22:22:09 [twisted] CRITICAL: Unhandled error in Deferred:
2025-01-16 22:22:09 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/common/service.py", line 72, in start
    self.process = subprocess.Popen(cmd, env=self.env,
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/subprocess.py", line 971, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/subprocess.py", line 1863, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/admin/.wdm/drivers/chromedriver/mac64/131.0.6778.264/chromedriver-mac-arm64/chromedriver'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/crawler.py", line 152, in crawl
    self.engine = self._create_engine()
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/crawler.py", line 166, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/core/engine.py", line 101, in __init__
    self.downloader: Downloader = downloader_cls(crawler)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/core/downloader/__init__.py", line 109, in __init__
    DownloaderMiddlewareManager.from_crawler(crawler)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/middleware.py", line 77, in from_crawler
    return cls._from_settings(crawler.settings, crawler)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/middleware.py", line 88, in _from_settings
    mw = build_from_crawler(mwcls, crawler)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/utils/misc.py", line 187, in build_from_crawler
    instance = objcls.from_crawler(crawler, *args, **kwargs)  # type: ignore[attr-defined]
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy_selenium/middlewares.py", line 67, in from_crawler
    middleware = cls(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy_selenium/middlewares.py", line 51, in __init__
    self.driver = driver_klass(**driver_kwargs)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/chrome/webdriver.py", line 73, in __init__
    self.service.start()
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/common/service.py", line 81, in start
    raise WebDriverException(
selenium.common.exceptions.WebDriverException: Message: 'chromedriver' executable needs to be in PATH. Please see https://sites.google.com/a/chromium.org/chromedriver/home

2025-01-16 22:25:02 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: example)
2025-01-16 22:25:02 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.11.0, Python 3.10.16 (main, Jan 16 2025, 13:43:45) [Clang 13.1.6 (clang-1316.0.21.2.5)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform macOS-12.2.1-x86_64-i386-64bit
2025-01-16 22:25:02 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-16 22:25:02 [asyncio] DEBUG: Using selector: KqueueSelector
2025-01-16 22:25:02 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-16 22:25:02 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-16 22:25:02 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-16 22:25:02 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-16 22:25:02 [scrapy.extensions.telnet] INFO: Telnet Password: d30efa8e8ed4bf62
2025-01-16 22:25:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-16 22:25:02 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'example',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': '../log/example.log',
 'NEWSPIDER_MODULE': 'example.spiders',
 'SPIDER_MODULES': ['example.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-16 22:25:03 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:52141/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"extensions": [], "args": ["--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"extensions": [], "args": ["--headless"]}}}
2025-01-16 22:25:03 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:52141
2025-01-16 22:25:30 [urllib3.connectionpool] DEBUG: http://127.0.0.1:52141 "POST /session HTTP/1.1" 200 892
2025-01-16 22:25:30 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 22:25:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy_selenium.SeleniumMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-16 22:25:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-16 22:25:30 [scrapy.middleware] INFO: Enabled item pipelines:
['example.pipelines.ExamplePipeline', 'example.pipelines.ExampleDownloadImg']
2025-01-16 22:25:30 [scrapy.core.engine] INFO: Spider opened
2025-01-16 22:25:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-16 22:25:30 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-01-16 22:25:30 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:52141/session/9318fd7179f938b7b88bccbeecc41758/url {"url": "https://forum.gamer.com.tw/B.php?page=1&bsn=18966"}
2025-01-16 22:25:58 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2025-01-16 22:25:58 [scrapy.core.engine] INFO: Closing spider (shutdown)
2025-01-16 22:25:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/B.php?page=1&bsn=18966>
Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 468, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 463, in _make_request
    httplib_response = conn.getresponse()
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1375, in getresponse
    response.begin()
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 287, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/retry.py", line 552, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/packages/six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 468, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 463, in _make_request
    httplib_response = conn.getresponse()
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1375, in getresponse
    response.begin()
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 287, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
2025-01-16 22:25:58 [scrapy.crawler] INFO: Received SIGINT twice, forcing unclean shutdown
2025-01-16 22:26:00 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: example)
2025-01-16 22:26:00 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.11.0, Python 3.10.16 (main, Jan 16 2025, 13:43:45) [Clang 13.1.6 (clang-1316.0.21.2.5)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform macOS-12.2.1-x86_64-i386-64bit
2025-01-16 22:26:00 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-16 22:26:00 [asyncio] DEBUG: Using selector: KqueueSelector
2025-01-16 22:26:00 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-16 22:26:00 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-16 22:26:00 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-16 22:26:00 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-16 22:26:00 [scrapy.extensions.telnet] INFO: Telnet Password: dcffa8d3f285a22b
2025-01-16 22:26:00 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-16 22:26:00 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'example',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': '../log/example.log',
 'NEWSPIDER_MODULE': 'example.spiders',
 'SPIDER_MODULES': ['example.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-16 22:26:01 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:52189/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"extensions": [], "args": ["--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"extensions": [], "args": ["--headless"]}}}
2025-01-16 22:26:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:52189
2025-01-16 22:26:06 [urllib3.connectionpool] DEBUG: http://127.0.0.1:52189 "POST /session HTTP/1.1" 200 892
2025-01-16 22:26:06 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 22:26:06 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy_selenium.SeleniumMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-16 22:26:06 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-16 22:26:06 [scrapy.middleware] INFO: Enabled item pipelines:
['example.pipelines.ExamplePipeline', 'example.pipelines.ExampleDownloadImg']
2025-01-16 22:26:06 [scrapy.core.engine] INFO: Spider opened
2025-01-16 22:26:06 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-16 22:26:06 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-01-16 22:26:06 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:52189/session/1af0c389220192e8602776ca66d14da6/url {"url": "https://forum.gamer.com.tw/B.php?page=1&bsn=18966"}
2025-01-16 22:26:40 [urllib3.connectionpool] DEBUG: http://127.0.0.1:52189 "POST /session/1af0c389220192e8602776ca66d14da6/url HTTP/1.1" 200 14
2025-01-16 22:26:40 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 22:26:40 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:52189/session/1af0c389220192e8602776ca66d14da6/source {}
2025-01-16 22:26:43 [urllib3.connectionpool] DEBUG: http://127.0.0.1:52189 "GET /session/1af0c389220192e8602776ca66d14da6/source HTTP/1.1" 200 249317
2025-01-16 22:26:43 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 22:26:43 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:52189/session/1af0c389220192e8602776ca66d14da6/url {}
2025-01-16 22:26:43 [urllib3.connectionpool] DEBUG: http://127.0.0.1:52189 "GET /session/1af0c389220192e8602776ca66d14da6/url HTTP/1.1" 200 61
2025-01-16 22:26:43 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 22:26:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/B.php?page=1&bsn=18966> (referer: None)
2025-01-16 22:26:43 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:52189/session/1af0c389220192e8602776ca66d14da6/execute/sync {"script": "return document.body.scrollHeight", "args": []}
2025-01-16 22:26:43 [urllib3.connectionpool] DEBUG: http://127.0.0.1:52189 "POST /session/1af0c389220192e8602776ca66d14da6/execute/sync HTTP/1.1" 200 14
2025-01-16 22:26:43 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 22:26:43 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:52189/session/1af0c389220192e8602776ca66d14da6/execute/sync {"script": "window.scrollTo(0, document.body.scrollHeight);", "args": []}
2025-01-16 22:26:43 [urllib3.connectionpool] DEBUG: http://127.0.0.1:52189 "POST /session/1af0c389220192e8602776ca66d14da6/execute/sync HTTP/1.1" 200 14
2025-01-16 22:26:43 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 22:26:45 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:52189/session/1af0c389220192e8602776ca66d14da6/execute/sync {"script": "return document.body.scrollHeight", "args": []}
2025-01-16 22:26:46 [urllib3.connectionpool] DEBUG: http://127.0.0.1:52189 "POST /session/1af0c389220192e8602776ca66d14da6/execute/sync HTTP/1.1" 200 14
2025-01-16 22:26:46 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 22:26:46 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:52189/session/1af0c389220192e8602776ca66d14da6/source {}
2025-01-16 22:26:46 [urllib3.connectionpool] DEBUG: http://127.0.0.1:52189 "GET /session/1af0c389220192e8602776ca66d14da6/source HTTP/1.1" 200 250875
2025-01-16 22:26:46 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 22:26:46 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:52189/session/1af0c389220192e8602776ca66d14da6/url {}
2025-01-16 22:26:46 [urllib3.connectionpool] DEBUG: http://127.0.0.1:52189 "GET /session/1af0c389220192e8602776ca66d14da6/url HTTP/1.1" 200 61
2025-01-16 22:26:46 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 22:26:46 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:52189/session/1af0c389220192e8602776ca66d14da6/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139280&tnum=7"}
2025-01-16 22:26:52 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2025-01-16 22:26:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:52189/session/1af0c389220192e8602776ca66d14da6/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=138031&tnum=21"}
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (2): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10ea1db70>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (3): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10ea1fcd0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (4): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10ea1fbe0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (5): 127.0.0.1:52189
2025-01-16 22:26:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:52189/session/1af0c389220192e8602776ca66d14da6/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=104740&tnum=1068"}
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (6): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eab4940>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (7): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eab4af0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (8): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eab4be0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (9): 127.0.0.1:52189
2025-01-16 22:26:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:52189/session/1af0c389220192e8602776ca66d14da6/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139033&tnum=7"}
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (10): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eab58d0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (11): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eab5a80>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (12): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eab5b70>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (13): 127.0.0.1:52189
2025-01-16 22:26:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:52189/session/1af0c389220192e8602776ca66d14da6/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139290&tnum=1"}
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (14): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eab6860>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (15): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eab6a10>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (16): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eab6b00>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (17): 127.0.0.1:52189
2025-01-16 22:26:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:52189/session/1af0c389220192e8602776ca66d14da6/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139154&tnum=7"}
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (18): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eab77f0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (19): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eab79a0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (20): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eab7a90>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (21): 127.0.0.1:52189
2025-01-16 22:26:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:52189/session/1af0c389220192e8602776ca66d14da6/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139200&tnum=2"}
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (22): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eb347c0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (23): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eb34970>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (24): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eb34a60>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (25): 127.0.0.1:52189
2025-01-16 22:26:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:52189/session/1af0c389220192e8602776ca66d14da6/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139291&tnum=1"}
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (26): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eb35750>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (27): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eb35900>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (28): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eb359f0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (29): 127.0.0.1:52189
2025-01-16 22:26:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:52189/session/1af0c389220192e8602776ca66d14da6/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139292&tnum=1"}
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (30): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eb366e0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (31): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eb36890>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (32): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eb36980>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (33): 127.0.0.1:52189
2025-01-16 22:26:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:52189/session/1af0c389220192e8602776ca66d14da6/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139293&tnum=1"}
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (34): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eb37670>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (35): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eb37820>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (36): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eb37910>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (37): 127.0.0.1:52189
2025-01-16 22:26:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:52189/session/1af0c389220192e8602776ca66d14da6/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139278&tnum=29"}
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (38): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eb78640>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (39): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eb787f0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (40): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eb788e0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (41): 127.0.0.1:52189
2025-01-16 22:26:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:52189/session/1af0c389220192e8602776ca66d14da6/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=138723&tnum=22"}
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (42): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eb795d0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (43): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eb79780>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (44): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eb79870>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (45): 127.0.0.1:52189
2025-01-16 22:26:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:52189/session/1af0c389220192e8602776ca66d14da6/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139171&tnum=26"}
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (46): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eb7a500>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (47): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eb7a6b0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (48): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eb7a7a0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (49): 127.0.0.1:52189
2025-01-16 22:26:52 [scrapy.core.engine] INFO: Closing spider (shutdown)
2025-01-16 22:26:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139280&tnum=7>
Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 468, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 463, in _make_request
    httplib_response = conn.getresponse()
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1375, in getresponse
    response.begin()
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 287, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/retry.py", line 552, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/packages/six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 468, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 463, in _make_request
    httplib_response = conn.getresponse()
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1375, in getresponse
    response.begin()
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 287, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
2025-01-16 22:26:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=138031&tnum=21>
Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1283, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1329, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x10ea1fd90>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=52189): Max retries exceeded with url: /session/1af0c389220192e8602776ca66d14da6/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10ea1fd90>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 22:26:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=104740&tnum=1068>
Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1283, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1329, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x10eab4d60>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=52189): Max retries exceeded with url: /session/1af0c389220192e8602776ca66d14da6/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eab4d60>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 22:26:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139033&tnum=7>
Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1283, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1329, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x10eab5cf0>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=52189): Max retries exceeded with url: /session/1af0c389220192e8602776ca66d14da6/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eab5cf0>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 22:26:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139290&tnum=1>
Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1283, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1329, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x10eab6c80>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=52189): Max retries exceeded with url: /session/1af0c389220192e8602776ca66d14da6/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eab6c80>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 22:26:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139154&tnum=7>
Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1283, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1329, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x10eab7c10>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=52189): Max retries exceeded with url: /session/1af0c389220192e8602776ca66d14da6/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eab7c10>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 22:26:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139200&tnum=2>
Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1283, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1329, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x10eb34be0>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=52189): Max retries exceeded with url: /session/1af0c389220192e8602776ca66d14da6/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eb34be0>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 22:26:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139291&tnum=1>
Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1283, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1329, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x10eb35b70>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=52189): Max retries exceeded with url: /session/1af0c389220192e8602776ca66d14da6/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eb35b70>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 22:26:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139292&tnum=1>
Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1283, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1329, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x10eb36b00>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=52189): Max retries exceeded with url: /session/1af0c389220192e8602776ca66d14da6/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eb36b00>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 22:26:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139293&tnum=1>
Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1283, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1329, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x10eb37a90>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=52189): Max retries exceeded with url: /session/1af0c389220192e8602776ca66d14da6/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eb37a90>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 22:26:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139278&tnum=29>
Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1283, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1329, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x10eb78a60>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=52189): Max retries exceeded with url: /session/1af0c389220192e8602776ca66d14da6/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eb78a60>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 22:26:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=138723&tnum=22>
Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1283, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1329, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x10eb799f0>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=52189): Max retries exceeded with url: /session/1af0c389220192e8602776ca66d14da6/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eb799f0>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 22:26:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139171&tnum=26>
Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1283, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1329, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x10eb7a920>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=52189): Max retries exceeded with url: /session/1af0c389220192e8602776ca66d14da6/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eb7a920>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 22:26:52 [scrapy.crawler] INFO: Received SIGINT twice, forcing unclean shutdown
2025-01-16 22:27:39 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: example)
2025-01-16 22:27:39 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.11.0, Python 3.10.16 (main, Jan 16 2025, 13:43:45) [Clang 13.1.6 (clang-1316.0.21.2.5)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform macOS-12.2.1-x86_64-i386-64bit
2025-01-16 22:27:39 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-16 22:27:39 [asyncio] DEBUG: Using selector: KqueueSelector
2025-01-16 22:27:39 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-16 22:27:39 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-16 22:27:39 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-16 22:27:39 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-16 22:27:39 [scrapy.extensions.telnet] INFO: Telnet Password: aa6d1e53f612fc99
2025-01-16 22:27:39 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-16 22:27:39 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'example',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': '../log/example.log',
 'NEWSPIDER_MODULE': 'example.spiders',
 'SPIDER_MODULES': ['example.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-16 22:27:40 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:52299/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"extensions": [], "args": ["--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"extensions": [], "args": ["--headless"]}}}
2025-01-16 22:27:40 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:52299
2025-01-16 22:27:45 [urllib3.connectionpool] DEBUG: http://127.0.0.1:52299 "POST /session HTTP/1.1" 200 892
2025-01-16 22:27:45 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 22:27:45 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy_selenium.SeleniumMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-16 22:27:45 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-16 22:27:45 [scrapy.middleware] INFO: Enabled item pipelines:
['example.pipelines.ExamplePipeline', 'example.pipelines.ExampleDownloadImg']
2025-01-16 22:27:45 [scrapy.core.engine] INFO: Spider opened
2025-01-16 22:27:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-16 22:27:45 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-01-16 22:27:45 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:52299/session/26866853e95105910a827325666d3a13/url {"url": "https://forum.gamer.com.tw/B.php?page=1&bsn=18966"}
2025-01-16 22:28:00 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2025-01-16 22:28:00 [scrapy.core.engine] INFO: Closing spider (shutdown)
2025-01-16 22:28:00 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/B.php?page=1&bsn=18966>
Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 468, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 463, in _make_request
    httplib_response = conn.getresponse()
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1375, in getresponse
    response.begin()
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 287, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/retry.py", line 552, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/packages/six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 468, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 463, in _make_request
    httplib_response = conn.getresponse()
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1375, in getresponse
    response.begin()
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 287, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
2025-01-16 22:28:00 [selenium.webdriver.remote.remote_connection] DEBUG: DELETE http://127.0.0.1:52299/session/26866853e95105910a827325666d3a13 {}
2025-01-16 22:28:00 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (2): 127.0.0.1:52299
2025-01-16 22:28:00 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/26866853e95105910a827325666d3a13'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:28:00 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10ee5a560>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/26866853e95105910a827325666d3a13
2025-01-16 22:28:00 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (3): 127.0.0.1:52299
2025-01-16 22:28:00 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/26866853e95105910a827325666d3a13'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:28:00 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10ee5aa40>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/26866853e95105910a827325666d3a13
2025-01-16 22:28:00 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (4): 127.0.0.1:52299
2025-01-16 22:28:00 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/26866853e95105910a827325666d3a13'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:28:00 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10ee5ac50>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/26866853e95105910a827325666d3a13
2025-01-16 22:28:00 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (5): 127.0.0.1:52299
2025-01-16 22:28:00 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 1,
 'downloader/exception_type_count/urllib3.exceptions.ProtocolError': 1,
 'elapsed_time_seconds': 15.237893,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2025, 1, 16, 14, 28, 0, 354141, tzinfo=datetime.timezone.utc),
 'items_per_minute': None,
 'log_count/DEBUG': 18,
 'log_count/ERROR': 1,
 'log_count/INFO': 11,
 'log_count/WARNING': 3,
 'memusage/max': 60080128,
 'memusage/startup': 60080128,
 'responses_per_minute': None,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2025, 1, 16, 14, 27, 45, 116248, tzinfo=datetime.timezone.utc)}
2025-01-16 22:28:00 [scrapy.core.engine] INFO: Spider closed (shutdown)
