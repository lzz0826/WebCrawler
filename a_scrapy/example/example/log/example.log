2025-01-16 18:05:09 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: example)
2025-01-16 18:05:09 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.11.0, Python 3.9.6 (default, May  7 2023, 23:32:44) - [Clang 14.0.3 (clang-1403.0.22.14.1)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform macOS-13.2.1-arm64-arm-64bit
2025-01-16 18:05:09 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-16 18:05:09 [asyncio] DEBUG: Using selector: KqueueSelector
2025-01-16 18:05:09 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-16 18:05:09 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-16 18:05:09 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-16 18:05:09 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-16 18:05:09 [scrapy.extensions.telnet] INFO: Telnet Password: 5c66f58255fe13e8
2025-01-16 18:05:09 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-16 18:05:09 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'example',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': '../log/example.log',
 'NEWSPIDER_MODULE': 'example.spiders',
 'SPIDER_MODULES': ['example.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-16 18:05:10 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63030/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"extensions": [], "args": ["--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"extensions": [], "args": ["--headless"]}}}
2025-01-16 18:05:10 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:63030
2025-01-16 18:05:10 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63030 "POST /session HTTP/1.1" 200 892
2025-01-16 18:05:10 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:05:10 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy_selenium.SeleniumMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-16 18:05:10 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-16 18:05:10 [scrapy.middleware] INFO: Enabled item pipelines:
['example.pipelines.ExamplePipeline', 'example.pipelines.ExampleDownloadImg']
2025-01-16 18:05:10 [scrapy.core.engine] INFO: Spider opened
2025-01-16 18:05:10 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-16 18:05:10 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-01-16 18:05:10 [scrapy.core.engine] DEBUG: Crawled (200) <POST https://fanyi.baidu.com/sug> (referer: None)
2025-01-16 18:05:10 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-16 18:05:10 [selenium.webdriver.remote.remote_connection] DEBUG: DELETE http://127.0.0.1:63030/session/af03ad15e1aff806054a6491d26785ea {}
2025-01-16 18:05:10 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63030 "DELETE /session/af03ad15e1aff806054a6491d26785ea HTTP/1.1" 200 14
2025-01-16 18:05:10 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:05:11 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 359,
 'downloader/request_count': 1,
 'downloader/request_method_count/POST': 1,
 'downloader/response_bytes': 881,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.404183,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 16, 10, 5, 10, 930166, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 530,
 'httpcompression/response_count': 1,
 'items_per_minute': None,
 'log_count/DEBUG': 13,
 'log_count/INFO': 10,
 'memusage/max': 60276736,
 'memusage/startup': 60276736,
 'response_received_count': 1,
 'responses_per_minute': None,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2025, 1, 16, 10, 5, 10, 525983, tzinfo=datetime.timezone.utc)}
2025-01-16 18:05:11 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-16 18:05:59 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: example)
2025-01-16 18:05:59 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.11.0, Python 3.9.6 (default, May  7 2023, 23:32:44) - [Clang 14.0.3 (clang-1403.0.22.14.1)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform macOS-13.2.1-arm64-arm-64bit
2025-01-16 18:05:59 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-16 18:05:59 [asyncio] DEBUG: Using selector: KqueueSelector
2025-01-16 18:05:59 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-16 18:05:59 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-16 18:05:59 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-16 18:05:59 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-16 18:05:59 [scrapy.extensions.telnet] INFO: Telnet Password: 8cb72d4974784e65
2025-01-16 18:05:59 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-16 18:05:59 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'example',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': '../log/example.log',
 'NEWSPIDER_MODULE': 'example.spiders',
 'SPIDER_MODULES': ['example.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-16 18:06:00 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63256/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"extensions": [], "args": ["--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"extensions": [], "args": ["--headless"]}}}
2025-01-16 18:06:00 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:63256
2025-01-16 18:06:00 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63256 "POST /session HTTP/1.1" 200 892
2025-01-16 18:06:00 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:00 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy_selenium.SeleniumMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-16 18:06:00 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-16 18:06:00 [scrapy.middleware] INFO: Enabled item pipelines:
['example.pipelines.ExamplePipeline', 'example.pipelines.ExampleDownloadImg']
2025-01-16 18:06:00 [scrapy.core.engine] INFO: Spider opened
2025-01-16 18:06:00 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-16 18:06:00 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-01-16 18:06:00 [scrapy.core.engine] DEBUG: Crawled (200) <POST https://fanyi.baidu.com/sug> (referer: None)
2025-01-16 18:06:01 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-16 18:06:01 [selenium.webdriver.remote.remote_connection] DEBUG: DELETE http://127.0.0.1:63256/session/49805dc75b2b8fe96aba0153300db3e1 {}
2025-01-16 18:06:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63256 "DELETE /session/49805dc75b2b8fe96aba0153300db3e1 HTTP/1.1" 200 14
2025-01-16 18:06:01 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:01 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 359,
 'downloader/request_count': 1,
 'downloader/request_method_count/POST': 1,
 'downloader/response_bytes': 882,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.397878,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 16, 10, 6, 1, 33645, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 530,
 'httpcompression/response_count': 1,
 'items_per_minute': None,
 'log_count/DEBUG': 13,
 'log_count/INFO': 10,
 'memusage/max': 60801024,
 'memusage/startup': 60801024,
 'response_received_count': 1,
 'responses_per_minute': None,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2025, 1, 16, 10, 6, 0, 635767, tzinfo=datetime.timezone.utc)}
2025-01-16 18:06:01 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-16 18:06:48 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: example)
2025-01-16 18:06:48 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.11.0, Python 3.9.6 (default, May  7 2023, 23:32:44) - [Clang 14.0.3 (clang-1403.0.22.14.1)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform macOS-13.2.1-arm64-arm-64bit
2025-01-16 18:06:48 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-16 18:06:48 [asyncio] DEBUG: Using selector: KqueueSelector
2025-01-16 18:06:48 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-16 18:06:48 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-16 18:06:48 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-16 18:06:48 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-16 18:06:48 [scrapy.extensions.telnet] INFO: Telnet Password: 84f0d181dff36ba9
2025-01-16 18:06:48 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-16 18:06:48 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'example',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': '../log/example.log',
 'NEWSPIDER_MODULE': 'example.spiders',
 'SPIDER_MODULES': ['example.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-16 18:06:49 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63481/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"extensions": [], "args": ["--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"extensions": [], "args": ["--headless"]}}}
2025-01-16 18:06:49 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:63481
2025-01-16 18:06:50 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "POST /session HTTP/1.1" 200 892
2025-01-16 18:06:50 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:50 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy_selenium.SeleniumMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-16 18:06:50 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-16 18:06:50 [scrapy.middleware] INFO: Enabled item pipelines:
['example.pipelines.ExamplePipeline', 'example.pipelines.ExampleDownloadImg']
2025-01-16 18:06:50 [scrapy.core.engine] INFO: Spider opened
2025-01-16 18:06:50 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-16 18:06:50 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-01-16 18:06:50 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {"url": "https://forum.gamer.com.tw/B.php?page=1&bsn=18966"}
2025-01-16 18:06:50 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "POST /session/4e850fd1170ee70416590db4df80058e/url HTTP/1.1" 200 14
2025-01-16 18:06:50 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:50 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/source {}
2025-01-16 18:06:50 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "GET /session/4e850fd1170ee70416590db4df80058e/source HTTP/1.1" 200 250876
2025-01-16 18:06:50 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:50 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {}
2025-01-16 18:06:50 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "GET /session/4e850fd1170ee70416590db4df80058e/url HTTP/1.1" 200 61
2025-01-16 18:06:50 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/B.php?page=1&bsn=18966> (referer: None)
2025-01-16 18:06:51 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/execute/sync {"script": "return document.body.scrollHeight", "args": []}
2025-01-16 18:06:51 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "POST /session/4e850fd1170ee70416590db4df80058e/execute/sync HTTP/1.1" 200 14
2025-01-16 18:06:51 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:51 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/execute/sync {"script": "window.scrollTo(0, document.body.scrollHeight);", "args": []}
2025-01-16 18:06:51 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "POST /session/4e850fd1170ee70416590db4df80058e/execute/sync HTTP/1.1" 200 14
2025-01-16 18:06:51 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:53 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/execute/sync {"script": "return document.body.scrollHeight", "args": []}
2025-01-16 18:06:53 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "POST /session/4e850fd1170ee70416590db4df80058e/execute/sync HTTP/1.1" 200 14
2025-01-16 18:06:53 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:53 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/source {}
2025-01-16 18:06:53 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "GET /session/4e850fd1170ee70416590db4df80058e/source HTTP/1.1" 200 252489
2025-01-16 18:06:53 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:53 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {}
2025-01-16 18:06:53 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "GET /session/4e850fd1170ee70416590db4df80058e/url HTTP/1.1" 200 61
2025-01-16 18:06:53 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:53 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139278&tnum=24"}
2025-01-16 18:06:54 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "POST /session/4e850fd1170ee70416590db4df80058e/url HTTP/1.1" 200 14
2025-01-16 18:06:54 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:54 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/source {}
2025-01-16 18:06:54 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "GET /session/4e850fd1170ee70416590db4df80058e/source HTTP/1.1" 200 486506
2025-01-16 18:06:54 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:54 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {}
2025-01-16 18:06:54 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "GET /session/4e850fd1170ee70416590db4df80058e/url HTTP/1.1" 200 73
2025-01-16 18:06:54 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139278&tnum=24> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:06:54 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {"url": "https://forum.gamer.com.tw/B.php?page=2&bsn=18966"}
2025-01-16 18:06:54 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "POST /session/4e850fd1170ee70416590db4df80058e/url HTTP/1.1" 200 14
2025-01-16 18:06:54 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:54 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/source {}
2025-01-16 18:06:54 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "GET /session/4e850fd1170ee70416590db4df80058e/source HTTP/1.1" 200 246793
2025-01-16 18:06:54 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:54 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {}
2025-01-16 18:06:54 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "GET /session/4e850fd1170ee70416590db4df80058e/url HTTP/1.1" 200 61
2025-01-16 18:06:54 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/B.php?page=2&bsn=18966> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:06:54 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=138700&tnum=5"}
2025-01-16 18:06:54 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "POST /session/4e850fd1170ee70416590db4df80058e/url HTTP/1.1" 200 14
2025-01-16 18:06:54 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:54 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/source {}
2025-01-16 18:06:54 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "GET /session/4e850fd1170ee70416590db4df80058e/source HTTP/1.1" 200 215461
2025-01-16 18:06:54 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:54 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {}
2025-01-16 18:06:55 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "GET /session/4e850fd1170ee70416590db4df80058e/url HTTP/1.1" 200 72
2025-01-16 18:06:55 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=138700&tnum=5> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:06:55 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139274&tnum=3"}
2025-01-16 18:06:55 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "POST /session/4e850fd1170ee70416590db4df80058e/url HTTP/1.1" 200 14
2025-01-16 18:06:55 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:55 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/source {}
2025-01-16 18:06:55 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "GET /session/4e850fd1170ee70416590db4df80058e/source HTTP/1.1" 200 163851
2025-01-16 18:06:55 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:55 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {}
2025-01-16 18:06:55 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "GET /session/4e850fd1170ee70416590db4df80058e/url HTTP/1.1" 200 72
2025-01-16 18:06:55 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139274&tnum=3> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:06:55 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139275&tnum=1"}
2025-01-16 18:06:55 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "POST /session/4e850fd1170ee70416590db4df80058e/url HTTP/1.1" 200 14
2025-01-16 18:06:55 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:55 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/source {}
2025-01-16 18:06:55 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "GET /session/4e850fd1170ee70416590db4df80058e/source HTTP/1.1" 200 139596
2025-01-16 18:06:55 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:55 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {}
2025-01-16 18:06:55 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "GET /session/4e850fd1170ee70416590db4df80058e/url HTTP/1.1" 200 72
2025-01-16 18:06:55 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139275&tnum=1> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:06:55 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139231&tnum=11"}
2025-01-16 18:06:56 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "POST /session/4e850fd1170ee70416590db4df80058e/url HTTP/1.1" 200 14
2025-01-16 18:06:56 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:56 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/source {}
2025-01-16 18:06:56 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "GET /session/4e850fd1170ee70416590db4df80058e/source HTTP/1.1" 200 264412
2025-01-16 18:06:56 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:56 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {}
2025-01-16 18:06:56 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "GET /session/4e850fd1170ee70416590db4df80058e/url HTTP/1.1" 200 73
2025-01-16 18:06:56 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139231&tnum=11> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:06:56 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=138616&tnum=5"}
2025-01-16 18:06:57 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "POST /session/4e850fd1170ee70416590db4df80058e/url HTTP/1.1" 200 14
2025-01-16 18:06:57 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:57 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/source {}
2025-01-16 18:06:57 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "GET /session/4e850fd1170ee70416590db4df80058e/source HTTP/1.1" 200 215143
2025-01-16 18:06:57 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:57 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {}
2025-01-16 18:06:57 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "GET /session/4e850fd1170ee70416590db4df80058e/url HTTP/1.1" 200 72
2025-01-16 18:06:57 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=138616&tnum=5> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:06:57 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=138913&tnum=16"}
2025-01-16 18:06:57 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "POST /session/4e850fd1170ee70416590db4df80058e/url HTTP/1.1" 200 14
2025-01-16 18:06:57 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:57 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/source {}
2025-01-16 18:06:57 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "GET /session/4e850fd1170ee70416590db4df80058e/source HTTP/1.1" 200 365850
2025-01-16 18:06:57 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:57 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {}
2025-01-16 18:06:57 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "GET /session/4e850fd1170ee70416590db4df80058e/url HTTP/1.1" 200 73
2025-01-16 18:06:57 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=138913&tnum=16> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:06:57 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139276&tnum=1"}
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "POST /session/4e850fd1170ee70416590db4df80058e/url HTTP/1.1" 200 14
2025-01-16 18:06:58 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:58 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/source {}
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "GET /session/4e850fd1170ee70416590db4df80058e/source HTTP/1.1" 200 149404
2025-01-16 18:06:58 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:58 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {}
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63481 "GET /session/4e850fd1170ee70416590db4df80058e/url HTTP/1.1" 200 72
2025-01-16 18:06:58 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:06:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139276&tnum=1> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:06:58 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139277&tnum=1"}
2025-01-16 18:06:58 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2025-01-16 18:06:58 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=138031&tnum=19"}
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (2): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x106f72400>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (3): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x106f725b0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (4): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x106f726a0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (5): 127.0.0.1:63481
2025-01-16 18:06:58 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=137397&tnum=37"}
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (6): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x106f7b3d0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (7): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x106f7b580>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (8): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x106f7b670>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (9): 127.0.0.1:63481
2025-01-16 18:06:58 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=138723&tnum=21"}
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (10): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x106f843a0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (11): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x106f84550>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (12): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x106f84640>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (13): 127.0.0.1:63481
2025-01-16 18:06:58 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=138377&tnum=7"}
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (14): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x106f8f370>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (15): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x106f41550>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (16): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x106f8f520>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (17): 127.0.0.1:63481
2025-01-16 18:06:58 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=138161&tnum=9"}
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (18): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x106f9e250>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (19): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x106f9e400>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (20): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x106f9e4f0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (21): 127.0.0.1:63481
2025-01-16 18:06:58 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139281&tnum=1"}
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (22): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x106fac220>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (23): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x106fac3d0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (24): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x106fac4c0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (25): 127.0.0.1:63481
2025-01-16 18:06:58 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=136522&tnum=120"}
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (26): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x106fbc1f0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (27): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x106fbc3a0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (28): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x106fbc490>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (29): 127.0.0.1:63481
2025-01-16 18:06:58 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139282&tnum=1"}
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (30): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108b011c0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (31): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108b01370>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (32): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108b01460>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (33): 127.0.0.1:63481
2025-01-16 18:06:58 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139283&tnum=1"}
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (34): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108b12190>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (35): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108b12340>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (36): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108b12430>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (37): 127.0.0.1:63481
2025-01-16 18:06:58 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139154&tnum=6"}
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (38): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108b21160>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (39): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108b21310>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (40): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108b21400>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (41): 127.0.0.1:63481
2025-01-16 18:06:58 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139171&tnum=24"}
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (42): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108b32130>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (43): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108b322e0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (44): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108b323d0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (45): 127.0.0.1:63481
2025-01-16 18:06:58 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139280&tnum=2"}
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (46): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108b41100>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (47): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108b412b0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (48): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108b413a0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (49): 127.0.0.1:63481
2025-01-16 18:06:58 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139238&tnum=13"}
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (50): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108b510d0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (51): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108b51280>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (52): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108b51370>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (53): 127.0.0.1:63481
2025-01-16 18:06:58 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=136809&tnum=154"}
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (54): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108b63040>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (55): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108b631f0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (56): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108b632e0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/url
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (57): 127.0.0.1:63481
2025-01-16 18:06:58 [scrapy.core.engine] INFO: Closing spider (shutdown)
2025-01-16 18:06:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139278&tnum=24>
{'content': 'https://www.pathofexile.com/forum/view-thread/3695606/page/1#p25859331 '
            '1/17      4 ',
 'img': None,
 'title': 'Poe 2 0.1.1 Patch note ',
 'userName': '33456109'}
2025-01-16 18:06:58 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63481/session/4e850fd1170ee70416590db4df80058e/execute/sync {"script": "return document.body.scrollHeight", "args": []}
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (58): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/execute/sync'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108d053d0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/execute/sync
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (59): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/execute/sync'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108d054f0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/execute/sync
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (60): 127.0.0.1:63481
2025-01-16 18:06:58 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/4e850fd1170ee70416590db4df80058e/execute/sync'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:06:58 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108d05670>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/4e850fd1170ee70416590db4df80058e/execute/sync
2025-01-16 18:06:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (61): 127.0.0.1:63481
2025-01-16 18:06:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://forum.gamer.com.tw/B.php?page=2&bsn=18966> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x108d057c0>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/utils/defer.py", line 327, in iter_errback
    yield next(it)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 368, in __next__
    return next(self.data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 368, in __next__
    return next(self.data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 379, in <genexpr>
    return (self._set_referer(r, response) for r in result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 57, in <genexpr>
    return (r for r in result if self._filter(r, spider))
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 54, in <genexpr>
    return (r for r in result if self._filter(r, response, spider))
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/Users/admin/PycharmProjects/WebCrawler/a_scrapy/example/example/spiders/game_content.py", line 51, in parse
    last_height = driver.execute_script("return document.body.scrollHeight")
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 634, in execute_script
    return self.execute(command, {
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=63481): Max retries exceeded with url: /session/4e850fd1170ee70416590db4df80058e/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108d057c0>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:06:58 [scrapy.core.scraper] ERROR: Error processing {'content': ' GGG  BD '
            ' POE ',
 'img': 'https://truth.bahamut.com.tw/s01/202501/forum/18966/8b27d3635e75d203c8db8b2962bd3b11.JPG?w=300&h=300&fit=o',
 'title': ' (2025/1/15)',
 'userName': ''}
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/utils/defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/Users/admin/PycharmProjects/WebCrawler/a_scrapy/example/example/pipelines.py", line 42, in process_item
    request.urlretrieve(url=url, filename=filename)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/urllib/request.py", line 249, in urlretrieve
    tfp = open(filename, 'wb')
FileNotFoundError: [Errno 2] No such file or directory: '../download/imgs/ (2025/1/15).jpg'
2025-01-16 18:06:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139274&tnum=3>
{'content': 'https://ithome.com.tw/news/166964 '
            '266GGG',
 'img': None,
 'title': '2',
 'userName': 'jacket6719'}
2025-01-16 18:06:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139275&tnum=1>
{'content': 'poe  BD   t14 15 '
            ' twitch: ',
 'img': 'https://i1.ytimg.com/vi/WTOkTcOK01I/hqdefault.jpg',
 'title': ' ',
 'userName': ''}
2025-01-16 18:06:58 [scrapy.crawler] INFO: Received SIGINT twice, forcing unclean shutdown
2025-01-16 18:06:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139231&tnum=11>
{'content': ':CI  1! : '
            'MP()!  /: '
            '  ',
 'img': 'https://truth.bahamut.com.tw/s01/202501/forum/18966/98e4358b6a1f12f52901027f80f1915d.JPG?w=300&h=300&fit=o',
 'title': '!',
 'userName': 'az5504156'}
2025-01-16 18:06:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=138616&tnum=5>
{'content': '.GGG   25D '
            '..20, ',
 'img': 'https://i1.ytimg.com/vi/C8ubRMKVFG8/hqdefault.jpg',
 'title': '()',
 'userName': ''}
2025-01-16 18:06:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=138913&tnum=16>
{'content': '~AI  '
            '',
 'img': None,
 'title': 'BUILD !!!',
 'userName': ''}
2025-01-16 18:06:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139276&tnum=1>
{'content': '     18 '
            '  https://max',
 'img': 'https://truth.bahamut.com.tw/s01/202501/forum/18966/7e5589db4dbde93c002c40f938f327bd.JPG?w=300&h=300&fit=o',
 'title': '',
 'userName': ''}
2025-01-16 18:06:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139277&tnum=1>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 468, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 463, in _make_request
    httplib_response = conn.getresponse()
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1349, in getresponse
    response.begin()
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 316, in begin
    version, status, reason = self._read_status()
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 285, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 552, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/packages/six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 468, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 463, in _make_request
    httplib_response = conn.getresponse()
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1349, in getresponse
    response.begin()
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 316, in begin
    version, status, reason = self._read_status()
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 285, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
2025-01-16 18:06:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=138031&tnum=19>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x106f72820>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=63481): Max retries exceeded with url: /session/4e850fd1170ee70416590db4df80058e/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x106f72820>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:06:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=137397&tnum=37>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x106f7b7f0>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=63481): Max retries exceeded with url: /session/4e850fd1170ee70416590db4df80058e/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x106f7b7f0>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:06:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=138723&tnum=21>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x106f847c0>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=63481): Max retries exceeded with url: /session/4e850fd1170ee70416590db4df80058e/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x106f847c0>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:06:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=138377&tnum=7>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x106f8f6a0>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=63481): Max retries exceeded with url: /session/4e850fd1170ee70416590db4df80058e/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x106f8f6a0>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:06:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=138161&tnum=9>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x106f9e670>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=63481): Max retries exceeded with url: /session/4e850fd1170ee70416590db4df80058e/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x106f9e670>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:06:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139281&tnum=1>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x106fac640>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=63481): Max retries exceeded with url: /session/4e850fd1170ee70416590db4df80058e/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x106fac640>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:06:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=136522&tnum=120>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x106fbc610>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=63481): Max retries exceeded with url: /session/4e850fd1170ee70416590db4df80058e/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x106fbc610>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:06:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139282&tnum=1>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x108b015e0>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=63481): Max retries exceeded with url: /session/4e850fd1170ee70416590db4df80058e/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108b015e0>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:06:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139283&tnum=1>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x108b125b0>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=63481): Max retries exceeded with url: /session/4e850fd1170ee70416590db4df80058e/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108b125b0>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:06:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139154&tnum=6>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x108b21580>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=63481): Max retries exceeded with url: /session/4e850fd1170ee70416590db4df80058e/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108b21580>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:06:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139171&tnum=24>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x108b32550>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=63481): Max retries exceeded with url: /session/4e850fd1170ee70416590db4df80058e/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108b32550>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:06:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139280&tnum=2>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x108b41520>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=63481): Max retries exceeded with url: /session/4e850fd1170ee70416590db4df80058e/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108b41520>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:06:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139238&tnum=13>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x108b514f0>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=63481): Max retries exceeded with url: /session/4e850fd1170ee70416590db4df80058e/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108b514f0>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:06:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=136809&tnum=154>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x108b63460>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=63481): Max retries exceeded with url: /session/4e850fd1170ee70416590db4df80058e/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x108b63460>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:07:50 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: example)
2025-01-16 18:07:50 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.11.0, Python 3.9.6 (default, May  7 2023, 23:32:44) - [Clang 14.0.3 (clang-1403.0.22.14.1)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform macOS-13.2.1-arm64-arm-64bit
2025-01-16 18:07:50 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-16 18:07:50 [asyncio] DEBUG: Using selector: KqueueSelector
2025-01-16 18:07:50 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-16 18:07:50 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-16 18:07:50 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-16 18:07:50 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-16 18:07:50 [scrapy.extensions.telnet] INFO: Telnet Password: df8c7ba8a8435f75
2025-01-16 18:07:50 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-16 18:07:50 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'example',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': '../log/example.log',
 'NEWSPIDER_MODULE': 'example.spiders',
 'SPIDER_MODULES': ['example.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-16 18:07:51 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63905/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"extensions": [], "args": ["--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"extensions": [], "args": ["--headless"]}}}
2025-01-16 18:07:51 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:63905
2025-01-16 18:07:51 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63905 "POST /session HTTP/1.1" 200 892
2025-01-16 18:07:51 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:07:51 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy_selenium.SeleniumMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-16 18:07:51 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-16 18:07:51 [scrapy.middleware] INFO: Enabled item pipelines:
['example.pipelines.ExamplePipeline', 'example.pipelines.ExampleDownloadImg']
2025-01-16 18:07:51 [scrapy.core.engine] INFO: Spider opened
2025-01-16 18:07:51 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-16 18:07:51 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-01-16 18:07:52 [scrapy.core.engine] DEBUG: Crawled (200) <POST https://fanyi.baidu.com/sug> (referer: None)
2025-01-16 18:07:52 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-16 18:07:52 [selenium.webdriver.remote.remote_connection] DEBUG: DELETE http://127.0.0.1:63905/session/0ffd12d733b81a30beab7fd0e4359a66 {}
2025-01-16 18:07:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63905 "DELETE /session/0ffd12d733b81a30beab7fd0e4359a66 HTTP/1.1" 200 14
2025-01-16 18:07:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:07:52 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 359,
 'downloader/request_count': 1,
 'downloader/request_method_count/POST': 1,
 'downloader/response_bytes': 881,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.503385,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 16, 10, 7, 52, 421012, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 530,
 'httpcompression/response_count': 1,
 'items_per_minute': None,
 'log_count/DEBUG': 13,
 'log_count/INFO': 10,
 'memusage/max': 60981248,
 'memusage/startup': 60981248,
 'response_received_count': 1,
 'responses_per_minute': None,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2025, 1, 16, 10, 7, 51, 917627, tzinfo=datetime.timezone.utc)}
2025-01-16 18:07:52 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-16 18:09:11 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: example)
2025-01-16 18:09:11 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.11.0, Python 3.9.6 (default, May  7 2023, 23:32:44) - [Clang 14.0.3 (clang-1403.0.22.14.1)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform macOS-13.2.1-arm64-arm-64bit
2025-01-16 18:09:11 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-16 18:09:11 [asyncio] DEBUG: Using selector: KqueueSelector
2025-01-16 18:09:11 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-16 18:09:11 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-16 18:09:11 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-16 18:09:11 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-16 18:09:11 [scrapy.extensions.telnet] INFO: Telnet Password: 0ac6241c892dd3b2
2025-01-16 18:09:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-16 18:09:11 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'example',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': '../log/example.log',
 'NEWSPIDER_MODULE': 'example.spiders',
 'SPIDER_MODULES': ['example.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-16 18:09:12 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"extensions": [], "args": ["--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"extensions": [], "args": ["--headless"]}}}
2025-01-16 18:09:12 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:64261
2025-01-16 18:09:13 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session HTTP/1.1" 200 892
2025-01-16 18:09:13 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy_selenium.SeleniumMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-16 18:09:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-16 18:09:13 [scrapy.middleware] INFO: Enabled item pipelines:
['example.pipelines.ExamplePipeline', 'example.pipelines.ExampleDownloadImg']
2025-01-16 18:09:13 [scrapy.core.engine] INFO: Spider opened
2025-01-16 18:09:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-16 18:09:13 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-01-16 18:09:13 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/B.php?page=1&bsn=18966"}
2025-01-16 18:09:14 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:14 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:14 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:14 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 250324
2025-01-16 18:09:14 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:14 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:14 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 61
2025-01-16 18:09:14 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/B.php?page=1&bsn=18966> (referer: None)
2025-01-16 18:09:14 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync {"script": "return document.body.scrollHeight", "args": []}
2025-01-16 18:09:14 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync HTTP/1.1" 200 14
2025-01-16 18:09:14 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:14 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync {"script": "window.scrollTo(0, document.body.scrollHeight);", "args": []}
2025-01-16 18:09:14 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync HTTP/1.1" 200 14
2025-01-16 18:09:14 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:16 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync {"script": "return document.body.scrollHeight", "args": []}
2025-01-16 18:09:16 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync HTTP/1.1" 200 14
2025-01-16 18:09:16 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:16 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:16 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 253413
2025-01-16 18:09:16 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:16 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:16 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 61
2025-01-16 18:09:16 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:16 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139278&tnum=24"}
2025-01-16 18:09:17 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:17 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:17 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:17 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 485632
2025-01-16 18:09:17 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:17 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:17 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 73
2025-01-16 18:09:17 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139278&tnum=24> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:09:17 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/B.php?page=2&bsn=18966"}
2025-01-16 18:09:17 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:17 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:17 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:17 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 247823
2025-01-16 18:09:17 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:17 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:17 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 61
2025-01-16 18:09:17 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/B.php?page=2&bsn=18966> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:09:17 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=138700&tnum=5"}
2025-01-16 18:09:17 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:17 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:17 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:17 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 215228
2025-01-16 18:09:17 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:17 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:17 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 72
2025-01-16 18:09:17 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=138700&tnum=5> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:09:17 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139274&tnum=3"}
2025-01-16 18:09:18 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:18 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:18 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:18 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 163743
2025-01-16 18:09:18 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:18 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:18 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 72
2025-01-16 18:09:18 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139274&tnum=3> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:09:18 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139275&tnum=1"}
2025-01-16 18:09:18 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:18 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:18 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:18 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 139195
2025-01-16 18:09:18 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:18 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:18 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 72
2025-01-16 18:09:18 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139275&tnum=1> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:09:18 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139231&tnum=11"}
2025-01-16 18:09:19 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:19 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:19 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:19 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 264132
2025-01-16 18:09:19 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:19 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:19 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 73
2025-01-16 18:09:19 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139231&tnum=11> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:09:19 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=138616&tnum=5"}
2025-01-16 18:09:19 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:19 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:19 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:19 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 214531
2025-01-16 18:09:19 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:19 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:19 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 72
2025-01-16 18:09:19 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=138616&tnum=5> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:09:19 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=138913&tnum=16"}
2025-01-16 18:09:20 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:20 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:20 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:20 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 370931
2025-01-16 18:09:20 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:20 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:20 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 73
2025-01-16 18:09:20 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=138913&tnum=16> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:09:20 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139276&tnum=1"}
2025-01-16 18:09:20 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:20 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:20 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:20 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 148235
2025-01-16 18:09:20 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:20 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:20 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 72
2025-01-16 18:09:20 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139276&tnum=1> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:09:20 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139277&tnum=1"}
2025-01-16 18:09:21 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:21 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:21 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:21 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 152301
2025-01-16 18:09:21 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:21 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:21 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 72
2025-01-16 18:09:21 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139277&tnum=1> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:09:21 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=138031&tnum=19"}
2025-01-16 18:09:21 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:21 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:21 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:21 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 479828
2025-01-16 18:09:21 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:21 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:21 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 73
2025-01-16 18:09:21 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=138031&tnum=19> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:09:21 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=137397&tnum=37"}
2025-01-16 18:09:22 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:22 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:22 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:22 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 413215
2025-01-16 18:09:22 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:22 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:22 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 73
2025-01-16 18:09:22 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=137397&tnum=37> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:09:22 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=138723&tnum=21"}
2025-01-16 18:09:23 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:23 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:23 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:23 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 397261
2025-01-16 18:09:23 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:23 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:23 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 73
2025-01-16 18:09:23 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=138723&tnum=21> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:09:23 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=138377&tnum=7"}
2025-01-16 18:09:24 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:24 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:24 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:24 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 291884
2025-01-16 18:09:24 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:24 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:24 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 72
2025-01-16 18:09:24 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=138377&tnum=7> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:09:24 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=138161&tnum=9"}
2025-01-16 18:09:24 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:24 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:24 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:24 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 266859
2025-01-16 18:09:24 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:24 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:24 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 72
2025-01-16 18:09:24 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=138161&tnum=9> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:09:24 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139281&tnum=1"}
2025-01-16 18:09:24 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:24 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:24 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:24 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 145069
2025-01-16 18:09:24 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:24 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:24 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 72
2025-01-16 18:09:24 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139281&tnum=1> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:09:24 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=136522&tnum=120"}
2025-01-16 18:09:25 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:25 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:25 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:25 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 613024
2025-01-16 18:09:25 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:25 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:25 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 74
2025-01-16 18:09:25 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=136522&tnum=120> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:09:25 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139282&tnum=1"}
2025-01-16 18:09:25 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:25 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:25 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:25 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 139353
2025-01-16 18:09:25 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:25 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:25 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 72
2025-01-16 18:09:25 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139282&tnum=1> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:09:25 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139283&tnum=1"}
2025-01-16 18:09:26 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:26 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:26 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:26 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 147020
2025-01-16 18:09:26 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:26 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:26 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 72
2025-01-16 18:09:26 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139283&tnum=1> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:09:26 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139154&tnum=6"}
2025-01-16 18:09:26 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:26 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:26 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:26 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 246664
2025-01-16 18:09:26 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:26 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:26 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 72
2025-01-16 18:09:26 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139154&tnum=6> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:09:26 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139171&tnum=24"}
2025-01-16 18:09:27 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:27 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:27 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:27 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 451299
2025-01-16 18:09:27 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:27 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:27 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 73
2025-01-16 18:09:27 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139171&tnum=24> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:09:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139278&tnum=24>
{'content': 'https://www.pathofexile.com/forum/view-thread/3695606/page/1#p25859331 '
            '1/17      4 ',
 'img': None,
 'title': 'Poe 2 0.1.1 Patch note ',
 'userName': '33456109'}
2025-01-16 18:09:27 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync {"script": "return document.body.scrollHeight", "args": []}
2025-01-16 18:09:27 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync HTTP/1.1" 200 15
2025-01-16 18:09:27 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:27 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync {"script": "window.scrollTo(0, document.body.scrollHeight);", "args": []}
2025-01-16 18:09:27 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync HTTP/1.1" 200 14
2025-01-16 18:09:27 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:29 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync {"script": "return document.body.scrollHeight", "args": []}
2025-01-16 18:09:29 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync HTTP/1.1" 200 15
2025-01-16 18:09:29 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:29 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync {"script": "window.scrollTo(0, document.body.scrollHeight);", "args": []}
2025-01-16 18:09:29 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync HTTP/1.1" 200 14
2025-01-16 18:09:29 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:31 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync {"script": "return document.body.scrollHeight", "args": []}
2025-01-16 18:09:31 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync HTTP/1.1" 200 15
2025-01-16 18:09:31 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:31 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:31 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 455331
2025-01-16 18:09:31 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:31 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:31 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 73
2025-01-16 18:09:31 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:31 [scrapy.core.scraper] ERROR: Error processing {'content': ' GGG  BD '
            ' POE ',
 'img': 'https://truth.bahamut.com.tw/s01/202501/forum/18966/8b27d3635e75d203c8db8b2962bd3b11.JPG?w=300&h=300&fit=o',
 'title': ' (2025/1/15)',
 'userName': ''}
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/utils/defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/Users/admin/PycharmProjects/WebCrawler/a_scrapy/example/example/pipelines.py", line 42, in process_item
    request.urlretrieve(url=url, filename=filename)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/urllib/request.py", line 249, in urlretrieve
    tfp = open(filename, 'wb')
FileNotFoundError: [Errno 2] No such file or directory: '../download/imgs/ (2025/1/15).jpg'
2025-01-16 18:09:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139274&tnum=3>
{'content': 'https://ithome.com.tw/news/166964 '
            '266GGG',
 'img': None,
 'title': '2',
 'userName': 'jacket6719'}
2025-01-16 18:09:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139275&tnum=1>
{'content': 'poe  BD   t14 15 '
            ' twitch: ',
 'img': 'https://i1.ytimg.com/vi/WTOkTcOK01I/hqdefault.jpg',
 'title': ' ',
 'userName': ''}
2025-01-16 18:09:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139231&tnum=11>
{'content': ':CI  1! : '
            'MP()!  /: '
            '  ',
 'img': 'https://truth.bahamut.com.tw/s01/202501/forum/18966/98e4358b6a1f12f52901027f80f1915d.JPG?w=300&h=300&fit=o',
 'title': '!',
 'userName': 'az5504156'}
2025-01-16 18:09:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=138616&tnum=5>
{'content': '.GGG   25D '
            '..20, ',
 'img': 'https://i1.ytimg.com/vi/C8ubRMKVFG8/hqdefault.jpg',
 'title': '()',
 'userName': ''}
2025-01-16 18:09:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=138913&tnum=16>
{'content': '~AI  '
            '',
 'img': None,
 'title': 'BUILD !!!',
 'userName': ''}
2025-01-16 18:09:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139276&tnum=1>
{'content': '     18 '
            '  https://max',
 'img': 'https://truth.bahamut.com.tw/s01/202501/forum/18966/7e5589db4dbde93c002c40f938f327bd.JPG?w=300&h=300&fit=o',
 'title': '',
 'userName': ''}
2025-01-16 18:09:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139277&tnum=1>
{'content': 'https://www.pixiv.net/artworks/125927689 16% '
            '  1. 2.()  3./ 4. 1.  '
            ':EX EX',
 'img': 'https://truth.bahamut.com.tw/s01/202501/forum/18966/de8451ed4907cd51622081300a329b38.JPG?w=300&h=300&fit=o',
 'title': 'T450',
 'userName': ''}
2025-01-16 18:09:31 [scrapy.core.scraper] ERROR: Error processing {'content': 'Never sinkNeversink_Strict '
            ' ',
 'img': 'https://truth.bahamut.com.tw/s01/202412/forum/18966/75848e01cf1a2cb2ecb3203b65809fd4.JPG?w=300&h=300&fit=o',
 'title': '1/14 Neversink',
 'userName': ''}
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/utils/defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/Users/admin/PycharmProjects/WebCrawler/a_scrapy/example/example/pipelines.py", line 42, in process_item
    request.urlretrieve(url=url, filename=filename)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/urllib/request.py", line 249, in urlretrieve
    tfp = open(filename, 'wb')
FileNotFoundError: [Errno 2] No such file or directory: '../download/imgs/1/14 Neversink.jpg'
2025-01-16 18:09:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=137397&tnum=37>
{'content': ': reddit poe  : '
            'GGGPOE1POE2 EA() ',
 'img': None,
 'title': 'POE 1&2 ',
 'userName': 'baha0079'}
2025-01-16 18:09:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=138723&tnum=21>
{'content': '   ()  (/) CI (/)  () '
            '()()',
 'img': None,
 'title': 'POE 2    1/12 ',
 'userName': ''}
2025-01-16 18:09:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=138377&tnum=7>
{'content': 'RuzRain  build   '
            'T0 ',
 'img': None,
 'title': '1DBOSS ,feat COC ,  ',
 'userName': 'Ruz'}
2025-01-16 18:09:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=138161&tnum=9>
{'content': ' DC,  '
            ', ',
 'img': None,
 'title': ',',
 'userName': ''}
2025-01-16 18:09:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139281&tnum=1>
{'content': '    D1 D2   '
            'D2     90',
 'img': None,
 'title': 'poe2  ',
 'userName': 'evilalways'}
2025-01-16 18:09:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=136522&tnum=120>
{'content': '      (ctrl+f) 12/11 '
            ' 12/13 ',
 'img': None,
 'title': '[]-POE2  (1/2 ',
 'userName': ''}
2025-01-16 18:09:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139282&tnum=1>
{'content': ' +10%?',
 'img': None,
 'title': '?',
 'userName': 'PosiVibe'}
2025-01-16 18:09:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139283&tnum=1>
{'content': '   LE '
            'LE BOSS',
 'img': None,
 'title': '',
 'userName': ''}
2025-01-16 18:09:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139154&tnum=6>
{'content': '==  2  '
            ' NPC ',
 'img': None,
 'title': 'NPC ()',
 'userName': ''}
2025-01-16 18:09:31 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/B.php?page=3&bsn=18966"}
2025-01-16 18:09:32 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:32 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:32 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:32 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 242920
2025-01-16 18:09:32 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:32 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:32 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 61
2025-01-16 18:09:32 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/B.php?page=3&bsn=18966> (referer: https://forum.gamer.com.tw/B.php?page=2&bsn=18966)
2025-01-16 18:09:32 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139280&tnum=2"}
2025-01-16 18:09:32 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:32 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:32 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:32 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 159249
2025-01-16 18:09:32 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:32 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:32 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 72
2025-01-16 18:09:32 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139280&tnum=2> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:09:32 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139238&tnum=13"}
2025-01-16 18:09:33 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:33 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:33 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:33 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 314171
2025-01-16 18:09:33 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:33 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:33 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 73
2025-01-16 18:09:33 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139238&tnum=13> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:09:33 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=136809&tnum=154"}
2025-01-16 18:09:33 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:33 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:33 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:33 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 437249
2025-01-16 18:09:33 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:33 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:33 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 74
2025-01-16 18:09:33 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=136809&tnum=154> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:09:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139171&tnum=24>
{'content': '  D4 /POE2/  '
            ' ///',
 'img': None,
 'title': ' POE2',
 'userName': 'allen'}
2025-01-16 18:09:33 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync {"script": "return document.body.scrollHeight", "args": []}
2025-01-16 18:09:33 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync HTTP/1.1" 200 15
2025-01-16 18:09:33 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:33 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync {"script": "window.scrollTo(0, document.body.scrollHeight);", "args": []}
2025-01-16 18:09:33 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync HTTP/1.1" 200 14
2025-01-16 18:09:33 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:35 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync {"script": "return document.body.scrollHeight", "args": []}
2025-01-16 18:09:35 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync HTTP/1.1" 200 15
2025-01-16 18:09:35 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:35 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync {"script": "window.scrollTo(0, document.body.scrollHeight);", "args": []}
2025-01-16 18:09:35 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync HTTP/1.1" 200 14
2025-01-16 18:09:35 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:37 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync {"script": "return document.body.scrollHeight", "args": []}
2025-01-16 18:09:37 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync HTTP/1.1" 200 15
2025-01-16 18:09:37 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:37 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:38 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 438954
2025-01-16 18:09:38 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:38 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:38 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 74
2025-01-16 18:09:38 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:38 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139280&tnum=2>
{'content': '1D 55Dok ?_? '
            '  ',
 'img': 'https://truth.bahamut.com.tw/s01/202501/forum/18966/ab4322a4fb4cc154ede306ddc03c0a92.JPG?w=300&h=300&fit=o',
 'title': ' ',
 'userName': ''}
2025-01-16 18:09:38 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139238&tnum=13>
{'content': ' : POE '
            ' ...',
 'img': 'https://truth.bahamut.com.tw/s01/202501/forum/18966/562818bb7e9382fdb0637dff8f6ae9e4.JPG?w=300&h=300&fit=o',
 'title': '...',
 'userName': ''}
2025-01-16 18:09:38 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/B.php?page=4&bsn=18966"}
2025-01-16 18:09:38 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:38 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:38 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:38 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 245650
2025-01-16 18:09:38 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:38 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:38 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 61
2025-01-16 18:09:38 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/B.php?page=4&bsn=18966> (referer: https://forum.gamer.com.tw/B.php?page=3&bsn=18966)
2025-01-16 18:09:38 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=136809&tnum=154>
{'content': 'POE2 '
            '',
 'img': 'https://truth.bahamut.com.tw/s01/202412/forum/18966/404f00297ce9b876763a192534b2e3e9.JPG?w=300&h=300&fit=o',
 'title': 'POE2',
 'userName': 'War'}
2025-01-16 18:09:38 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync {"script": "return document.body.scrollHeight", "args": []}
2025-01-16 18:09:38 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync HTTP/1.1" 200 14
2025-01-16 18:09:38 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:38 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync {"script": "window.scrollTo(0, document.body.scrollHeight);", "args": []}
2025-01-16 18:09:38 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync HTTP/1.1" 200 14
2025-01-16 18:09:38 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:40 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync {"script": "return document.body.scrollHeight", "args": []}
2025-01-16 18:09:40 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync HTTP/1.1" 200 14
2025-01-16 18:09:40 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:40 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync {"script": "window.scrollTo(0, document.body.scrollHeight);", "args": []}
2025-01-16 18:09:40 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync HTTP/1.1" 200 14
2025-01-16 18:09:40 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:42 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync {"script": "return document.body.scrollHeight", "args": []}
2025-01-16 18:09:42 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync HTTP/1.1" 200 14
2025-01-16 18:09:42 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:42 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:42 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 249022
2025-01-16 18:09:42 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:42 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:42 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 61
2025-01-16 18:09:42 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:42 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139226&tnum=3&bPage=4"}
2025-01-16 18:09:42 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:42 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:42 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:42 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 163046
2025-01-16 18:09:42 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:42 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:42 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 80
2025-01-16 18:09:42 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139226&tnum=3&bPage=4> (referer: https://forum.gamer.com.tw/B.php?page=4&bsn=18966)
2025-01-16 18:09:42 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/B.php?page=5&bsn=18966"}
2025-01-16 18:09:43 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:43 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:43 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:43 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 247436
2025-01-16 18:09:43 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:43 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:43 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 61
2025-01-16 18:09:43 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/B.php?page=5&bsn=18966> (referer: https://forum.gamer.com.tw/B.php?page=4&bsn=18966)
2025-01-16 18:09:43 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139197&tnum=4&bPage=4"}
2025-01-16 18:09:43 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:43 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:43 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:43 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 194677
2025-01-16 18:09:43 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:43 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:43 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 80
2025-01-16 18:09:43 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139197&tnum=4&bPage=4> (referer: https://forum.gamer.com.tw/B.php?page=4&bsn=18966)
2025-01-16 18:09:43 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139201&tnum=1&bPage=4"}
2025-01-16 18:09:44 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:44 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:44 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:44 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 138597
2025-01-16 18:09:44 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:44 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:44 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 80
2025-01-16 18:09:44 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139201&tnum=1&bPage=4> (referer: https://forum.gamer.com.tw/B.php?page=4&bsn=18966)
2025-01-16 18:09:44 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=104740&tnum=1067&bPage=4"}
2025-01-16 18:09:44 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:44 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:44 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:44 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 501232
2025-01-16 18:09:44 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:44 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:44 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 83
2025-01-16 18:09:44 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=104740&tnum=1067&bPage=4> (referer: https://forum.gamer.com.tw/B.php?page=4&bsn=18966)
2025-01-16 18:09:44 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139202&tnum=1&bPage=4"}
2025-01-16 18:09:45 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:45 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:45 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:45 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 152620
2025-01-16 18:09:45 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:45 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:45 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 80
2025-01-16 18:09:45 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139202&tnum=1&bPage=4> (referer: https://forum.gamer.com.tw/B.php?page=4&bsn=18966)
2025-01-16 18:09:45 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139177&tnum=2&bPage=4"}
2025-01-16 18:09:45 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:45 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:45 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:45 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 165409
2025-01-16 18:09:45 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:45 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:45 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 80
2025-01-16 18:09:45 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139177&tnum=2&bPage=4> (referer: https://forum.gamer.com.tw/B.php?page=4&bsn=18966)
2025-01-16 18:09:45 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139204&tnum=1&bPage=4"}
2025-01-16 18:09:45 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:45 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:45 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:45 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 137930
2025-01-16 18:09:45 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:45 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:45 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 80
2025-01-16 18:09:45 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139204&tnum=1&bPage=4> (referer: https://forum.gamer.com.tw/B.php?page=4&bsn=18966)
2025-01-16 18:09:45 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139205&tnum=1&bPage=4"}
2025-01-16 18:09:46 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:46 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:46 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:46 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 154321
2025-01-16 18:09:46 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:46 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:46 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 80
2025-01-16 18:09:46 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139205&tnum=1&bPage=4> (referer: https://forum.gamer.com.tw/B.php?page=4&bsn=18966)
2025-01-16 18:09:46 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139207&tnum=1&bPage=4"}
2025-01-16 18:09:46 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:46 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:46 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:46 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 134894
2025-01-16 18:09:46 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:46 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:46 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 80
2025-01-16 18:09:46 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139207&tnum=1&bPage=4> (referer: https://forum.gamer.com.tw/B.php?page=4&bsn=18966)
2025-01-16 18:09:46 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139208&tnum=1&bPage=4"}
2025-01-16 18:09:46 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:46 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:46 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:46 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 139456
2025-01-16 18:09:46 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:46 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:46 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 80
2025-01-16 18:09:46 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139208&tnum=1&bPage=4> (referer: https://forum.gamer.com.tw/B.php?page=4&bsn=18966)
2025-01-16 18:09:46 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139127&tnum=2&bPage=4"}
2025-01-16 18:09:47 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:47 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:47 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:47 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 149212
2025-01-16 18:09:47 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:47 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:47 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 80
2025-01-16 18:09:47 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139127&tnum=2&bPage=4> (referer: https://forum.gamer.com.tw/B.php?page=4&bsn=18966)
2025-01-16 18:09:47 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139209&tnum=1&bPage=4"}
2025-01-16 18:09:47 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:47 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:47 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:47 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 137861
2025-01-16 18:09:47 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:47 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:47 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 80
2025-01-16 18:09:47 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139209&tnum=1&bPage=4> (referer: https://forum.gamer.com.tw/B.php?page=4&bsn=18966)
2025-01-16 18:09:47 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139211&tnum=1&bPage=4"}
2025-01-16 18:09:47 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:47 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:47 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:47 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 138006
2025-01-16 18:09:47 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:47 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:47 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 80
2025-01-16 18:09:47 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139211&tnum=1&bPage=4> (referer: https://forum.gamer.com.tw/B.php?page=4&bsn=18966)
2025-01-16 18:09:47 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139212&tnum=1&bPage=4"}
2025-01-16 18:09:48 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:48 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:48 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:48 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 153269
2025-01-16 18:09:48 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:48 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:48 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 80
2025-01-16 18:09:48 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139212&tnum=1&bPage=4> (referer: https://forum.gamer.com.tw/B.php?page=4&bsn=18966)
2025-01-16 18:09:48 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139214&tnum=1&bPage=4"}
2025-01-16 18:09:48 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:48 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:48 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:48 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 140596
2025-01-16 18:09:48 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:48 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:48 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 80
2025-01-16 18:09:48 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139214&tnum=1&bPage=4> (referer: https://forum.gamer.com.tw/B.php?page=4&bsn=18966)
2025-01-16 18:09:48 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139215&tnum=1&bPage=4"}
2025-01-16 18:09:48 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:48 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:48 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:48 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 140057
2025-01-16 18:09:48 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:48 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:48 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 80
2025-01-16 18:09:48 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139215&tnum=1&bPage=4> (referer: https://forum.gamer.com.tw/B.php?page=4&bsn=18966)
2025-01-16 18:09:48 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=135168&tnum=3&bPage=4"}
2025-01-16 18:09:49 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:49 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:49 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:49 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 158226
2025-01-16 18:09:49 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:49 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:49 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 80
2025-01-16 18:09:49 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=135168&tnum=3&bPage=4> (referer: https://forum.gamer.com.tw/B.php?page=4&bsn=18966)
2025-01-16 18:09:49 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139216&tnum=1&bPage=4"}
2025-01-16 18:09:49 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:49 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:49 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:49 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 135446
2025-01-16 18:09:49 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:49 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:49 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 80
2025-01-16 18:09:49 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139216&tnum=1&bPage=4> (referer: https://forum.gamer.com.tw/B.php?page=4&bsn=18966)
2025-01-16 18:09:49 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139206&tnum=4&bPage=4"}
2025-01-16 18:09:50 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:50 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:50 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:50 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 207502
2025-01-16 18:09:50 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:50 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:50 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 80
2025-01-16 18:09:50 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139206&tnum=4&bPage=4> (referer: https://forum.gamer.com.tw/B.php?page=4&bsn=18966)
2025-01-16 18:09:50 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139218&tnum=1&bPage=4"}
2025-01-16 18:09:50 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:50 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:50 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:50 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 139524
2025-01-16 18:09:50 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:50 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:50 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 80
2025-01-16 18:09:50 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139218&tnum=1&bPage=4> (referer: https://forum.gamer.com.tw/B.php?page=4&bsn=18966)
2025-01-16 18:09:50 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139219&tnum=1&bPage=4"}
2025-01-16 18:09:50 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:50 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:50 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:50 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 137605
2025-01-16 18:09:50 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:50 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:50 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 80
2025-01-16 18:09:50 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139219&tnum=1&bPage=4> (referer: https://forum.gamer.com.tw/B.php?page=4&bsn=18966)
2025-01-16 18:09:50 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139213&tnum=2&bPage=4"}
2025-01-16 18:09:51 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:51 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:51 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:51 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 131078
2025-01-16 18:09:51 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:51 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:51 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 80
2025-01-16 18:09:51 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139213&tnum=2&bPage=4> (referer: https://forum.gamer.com.tw/B.php?page=4&bsn=18966)
2025-01-16 18:09:51 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139220&tnum=1&bPage=4"}
2025-01-16 18:09:51 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:51 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:51 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:51 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 141624
2025-01-16 18:09:51 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:51 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:51 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 80
2025-01-16 18:09:51 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139220&tnum=1&bPage=4> (referer: https://forum.gamer.com.tw/B.php?page=4&bsn=18966)
2025-01-16 18:09:51 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139221&tnum=1&bPage=4"}
2025-01-16 18:09:51 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:51 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:51 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:51 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 128044
2025-01-16 18:09:51 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:51 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:51 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 80
2025-01-16 18:09:51 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139221&tnum=1&bPage=4> (referer: https://forum.gamer.com.tw/B.php?page=4&bsn=18966)
2025-01-16 18:09:51 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139222&tnum=1&bPage=4"}
2025-01-16 18:09:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:52 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 139852
2025-01-16 18:09:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:52 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 80
2025-01-16 18:09:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139222&tnum=1&bPage=4> (referer: https://forum.gamer.com.tw/B.php?page=4&bsn=18966)
2025-01-16 18:09:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139223&tnum=1&bPage=4"}
2025-01-16 18:09:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:52 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 138991
2025-01-16 18:09:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:52 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 80
2025-01-16 18:09:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139223&tnum=1&bPage=4> (referer: https://forum.gamer.com.tw/B.php?page=4&bsn=18966)
2025-01-16 18:09:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139224&tnum=1&bPage=4"}
2025-01-16 18:09:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:52 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 140320
2025-01-16 18:09:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:52 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 80
2025-01-16 18:09:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139224&tnum=1&bPage=4> (referer: https://forum.gamer.com.tw/B.php?page=4&bsn=18966)
2025-01-16 18:09:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139225&tnum=1&bPage=4"}
2025-01-16 18:09:53 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:53 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:53 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:53 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 129180
2025-01-16 18:09:53 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:53 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:53 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 80
2025-01-16 18:09:53 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139225&tnum=1&bPage=4> (referer: https://forum.gamer.com.tw/B.php?page=4&bsn=18966)
2025-01-16 18:09:53 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=138904&tnum=5&bPage=4"}
2025-01-16 18:09:57 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 14
2025-01-16 18:09:57 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:57 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:09:57 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 198534
2025-01-16 18:09:57 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:57 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:09:57 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 80
2025-01-16 18:09:57 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=138904&tnum=5&bPage=4> (referer: https://forum.gamer.com.tw/B.php?page=4&bsn=18966)
2025-01-16 18:09:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139226&tnum=3&bPage=4>
{'content': '    '
            ' ',
 'img': 'https://i1.ytimg.com/vi/uzjXtylbNlg/hqdefault.jpg',
 'title': ' boss ',
 'userName': '~'}
2025-01-16 18:09:57 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync {"script": "return document.body.scrollHeight", "args": []}
2025-01-16 18:09:57 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync HTTP/1.1" 200 14
2025-01-16 18:09:57 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:57 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync {"script": "window.scrollTo(0, document.body.scrollHeight);", "args": []}
2025-01-16 18:09:57 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync HTTP/1.1" 200 14
2025-01-16 18:09:57 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:59 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync {"script": "return document.body.scrollHeight", "args": []}
2025-01-16 18:09:59 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync HTTP/1.1" 200 14
2025-01-16 18:09:59 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:09:59 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync {"script": "window.scrollTo(0, document.body.scrollHeight);", "args": []}
2025-01-16 18:09:59 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync HTTP/1.1" 200 14
2025-01-16 18:09:59 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:01 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync {"script": "return document.body.scrollHeight", "args": []}
2025-01-16 18:10:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "POST /session/dd9226bd0e7ebfbe80a7cd2860d284af/execute/sync HTTP/1.1" 200 14
2025-01-16 18:10:01 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:01 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/source {}
2025-01-16 18:10:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/source HTTP/1.1" 200 201105
2025-01-16 18:10:01 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:01 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af/url {}
2025-01-16 18:10:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "GET /session/dd9226bd0e7ebfbe80a7cd2860d284af/url HTTP/1.1" 200 80
2025-01-16 18:10:01 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139197&tnum=4&bPage=4>
{'content': 'lv44    '
            '',
 'img': None,
 'title': '',
 'userName': 'Oscar8605'}
2025-01-16 18:10:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139201&tnum=1&bPage=4>
{'content': '  9   '
            ' 9',
 'img': None,
 'title': '',
 'userName': 'TGX'}
2025-01-16 18:10:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=104740&tnum=1067&bPage=4>
{'content': ': '
            '(~$$) ,',
 'img': None,
 'title': '()',
 'userName': 'kevin54099'}
2025-01-16 18:10:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139202&tnum=1&bPage=4>
{'content': '200 youtube Youtube '
            'Bug',
 'img': None,
 'title': 'POE2  ',
 'userName': 'Wei'}
2025-01-16 18:10:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139177&tnum=2&bPage=4>
{'content': 'GGG   GGG '
            ' reddit',
 'img': 'https://truth.bahamut.com.tw/s01/202501/forum/18966/8fb8a00f7905891dadaa6b6c2479a8fe.JPG?w=300&h=300&fit=o',
 'title': '(Jonathan)',
 'userName': ''}
2025-01-16 18:10:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139204&tnum=1&bPage=4>
{'content': 'NPC!!!',
 'img': 'https://truth.bahamut.com.tw/s01/202501/forum/18966/d58e9d28358e4ee9083d5f9de42bb3e9.JPG?w=300&h=300&fit=o',
 'title': '~~~',
 'userName': ''}
2025-01-16 18:10:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139205&tnum=1&bPage=4>
{'content': ' ""+ : '
            ' Combo ',
 'img': 'https://truth.bahamut.com.tw/s01/202501/forum/18966/8f4c4dcc738d9c9aeff0548515936a23.JPG?w=300&h=300&fit=o',
 'title': '  ?!(?)',
 'userName': 'BlueGun'}
2025-01-16 18:10:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139207&tnum=1&bPage=4>
{'content': 'POE1',
 'img': None,
 'title': 'POE2',
 'userName': ''}
2025-01-16 18:10:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139208&tnum=1&bPage=4>
{'content': '...    1.  '
            '782 ',
 'img': None,
 'title': 'POE2 ',
 'userName': 'dddd'}
2025-01-16 18:10:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139127&tnum=2&bPage=4>
{'content': ' !  !!!  () '
            '(Exalted)(Di',
 'img': None,
 'title': 'PoE2',
 'userName': 'Sasin'}
2025-01-16 18:10:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139209&tnum=1&bPage=4>
{'content': '~  ',
 'img': None,
 'title': ' ',
 'userName': ''}
2025-01-16 18:10:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139211&tnum=1&bPage=4>
{'content': '15  ',
 'img': None,
 'title': ' ',
 'userName': ''}
2025-01-16 18:10:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139212&tnum=1&bPage=4>
{'content': '1/17PN    ?   '
            'CoD  ',
 'img': None,
 'title': 'POE2  ! CoD(1/17PN)',
 'userName': 'Dizzy2 '}
2025-01-16 18:10:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139214&tnum=1&bPage=4>
{'content': '    '
            ' ',
 'img': None,
 'title': 'PoE2 BUG? ',
 'userName': ''}
2025-01-16 18:10:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139215&tnum=1&bPage=4>
{'content': '+ 80% '
            '2000HP...',
 'img': None,
 'title': '',
 'userName': ''}
2025-01-16 18:10:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=135168&tnum=3&bPage=4>
{'content': '  ? '
            '',
 'img': None,
 'title': '',
 'userName': ''}
2025-01-16 18:10:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139216&tnum=1&bPage=4>
{'content': ',,BUG,',
 'img': None,
 'title': '87GGGbug',
 'userName': 'shouei03'}
2025-01-16 18:10:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139206&tnum=4&bPage=4>
{'content': '. .  .   '
            ' ',
 'img': None,
 'title': 'POE2?',
 'userName': 'Human Being'}
2025-01-16 18:10:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139218&tnum=1&bPage=4>
{'content': ' npc= =',
 'img': None,
 'title': '',
 'userName': ''}
2025-01-16 18:10:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139219&tnum=1&bPage=4>
{'content': 'POE1/POE2 1000    121000 '
            '....499..',
 'img': None,
 'title': '1000',
 'userName': ''}
2025-01-16 18:10:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139213&tnum=2&bPage=4>
{'content': '',
 'img': None,
 'title': '',
 'userName': 'kemp0518'}
2025-01-16 18:10:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139220&tnum=1&bPage=4>
{'content': '     '
            'DPS ',
 'img': 'https://truth.bahamut.com.tw/s01/202501/forum/18966/d4b80a4cdbd2479e436ba1c2622adcf7.JPG?w=300&h=300&fit=o',
 'title': '-? ',
 'userName': ''}
2025-01-16 18:10:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139221&tnum=1&bPage=4>
{'content': ' 20%  ',
 'img': None,
 'title': '',
 'userName': 'Mark'}
2025-01-16 18:10:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139222&tnum=1&bPage=4>
{'content': ' (?      !!!!  '
            ' ????  GGG',
 'img': 'https://i1.ytimg.com/vi/GUQzYwCCWlU/hqdefault.jpg',
 'title': '? ',
 'userName': 'spock0626'}
2025-01-16 18:10:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139223&tnum=1&bPage=4>
{'content': 'nvidia geforce now POE2? POE2   '
            '?',
 'img': None,
 'title': 'nvidia geforce now',
 'userName': ''}
2025-01-16 18:10:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139224&tnum=1&bPage=4>
{'content': ' ! '
            '2025UI...',
 'img': 'https://truth.bahamut.com.tw/s01/202501/forum/18966/c2ca538dc3ee4eef38b344ce60b2ebb7.JPG?w=300&h=300&fit=o',
 'title': '.WASD',
 'userName': 'gary'}
2025-01-16 18:10:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139225&tnum=1&bPage=4>
{'content': ' '
            '',
 'img': None,
 'title': 'PS5',
 'userName': 'Kaws920'}
2025-01-16 18:10:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=138904&tnum=5&bPage=4>
{'content': '  xdd : ? '
            'BUG ',
 'img': 'https://i1.ytimg.com/vi/Y68ImiUOl9g/hqdefault.jpg',
 'title': '',
 'userName': ''}
2025-01-16 18:10:01 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-16 18:10:01 [selenium.webdriver.remote.remote_connection] DEBUG: DELETE http://127.0.0.1:64261/session/dd9226bd0e7ebfbe80a7cd2860d284af {}
2025-01-16 18:10:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64261 "DELETE /session/dd9226bd0e7ebfbe80a7cd2860d284af HTTP/1.1" 200 14
2025-01-16 18:10:01 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:01 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 10818254,
 'downloader/response_count': 57,
 'downloader/response_status_count/200': 57,
 'elapsed_time_seconds': 48.5865,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 16, 10, 10, 1, 714710, tzinfo=datetime.timezone.utc),
 'item_scraped_count': 50,
 'items_per_minute': None,
 'log_count/DEBUG': 731,
 'log_count/ERROR': 2,
 'log_count/INFO': 10,
 'memusage/max': 60506112,
 'memusage/startup': 60506112,
 'request_depth_max': 4,
 'response_received_count': 57,
 'responses_per_minute': None,
 'scheduler/dequeued': 57,
 'scheduler/dequeued/memory': 57,
 'scheduler/enqueued': 57,
 'scheduler/enqueued/memory': 57,
 'start_time': datetime.datetime(2025, 1, 16, 10, 9, 13, 128210, tzinfo=datetime.timezone.utc)}
2025-01-16 18:10:01 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-16 18:10:39 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: example)
2025-01-16 18:10:39 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.11.0, Python 3.9.6 (default, May  7 2023, 23:32:44) - [Clang 14.0.3 (clang-1403.0.22.14.1)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform macOS-13.2.1-arm64-arm-64bit
2025-01-16 18:10:39 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-16 18:10:39 [asyncio] DEBUG: Using selector: KqueueSelector
2025-01-16 18:10:39 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-16 18:10:39 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-16 18:10:39 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-16 18:10:39 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-16 18:10:39 [scrapy.extensions.telnet] INFO: Telnet Password: 5b1aa728aabc249b
2025-01-16 18:10:39 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-16 18:10:39 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'example',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': '../log/example.log',
 'NEWSPIDER_MODULE': 'example.spiders',
 'SPIDER_MODULES': ['example.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-16 18:10:40 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"extensions": [], "args": ["--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"extensions": [], "args": ["--headless"]}}}
2025-01-16 18:10:40 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:64772
2025-01-16 18:10:41 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session HTTP/1.1" 200 892
2025-01-16 18:10:41 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:41 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy_selenium.SeleniumMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-16 18:10:41 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-16 18:10:41 [scrapy.middleware] INFO: Enabled item pipelines:
['example.pipelines.ExamplePipeline', 'example.pipelines.ExampleDownloadImg']
2025-01-16 18:10:41 [scrapy.core.engine] INFO: Spider opened
2025-01-16 18:10:41 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-16 18:10:41 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-01-16 18:10:41 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {"url": "https://forum.gamer.com.tw/B.php?page=1&bsn=18966"}
2025-01-16 18:10:41 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 14
2025-01-16 18:10:41 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:41 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/source {}
2025-01-16 18:10:41 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/source HTTP/1.1" 200 249249
2025-01-16 18:10:41 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:41 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {}
2025-01-16 18:10:41 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 61
2025-01-16 18:10:41 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/B.php?page=1&bsn=18966> (referer: None)
2025-01-16 18:10:41 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/execute/sync {"script": "return document.body.scrollHeight", "args": []}
2025-01-16 18:10:41 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/execute/sync HTTP/1.1" 200 14
2025-01-16 18:10:41 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:41 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/execute/sync {"script": "window.scrollTo(0, document.body.scrollHeight);", "args": []}
2025-01-16 18:10:41 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/execute/sync HTTP/1.1" 200 14
2025-01-16 18:10:41 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:43 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/execute/sync {"script": "return document.body.scrollHeight", "args": []}
2025-01-16 18:10:43 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/execute/sync HTTP/1.1" 200 14
2025-01-16 18:10:43 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:43 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/execute/sync {"script": "window.scrollTo(0, document.body.scrollHeight);", "args": []}
2025-01-16 18:10:43 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/execute/sync HTTP/1.1" 200 14
2025-01-16 18:10:43 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:46 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/execute/sync {"script": "return document.body.scrollHeight", "args": []}
2025-01-16 18:10:46 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/execute/sync HTTP/1.1" 200 14
2025-01-16 18:10:46 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:46 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/source {}
2025-01-16 18:10:46 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/source HTTP/1.1" 200 252120
2025-01-16 18:10:46 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:46 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {}
2025-01-16 18:10:46 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 61
2025-01-16 18:10:46 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:46 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139283&tnum=2"}
2025-01-16 18:10:46 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 14
2025-01-16 18:10:46 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:46 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/source {}
2025-01-16 18:10:46 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/source HTTP/1.1" 200 155318
2025-01-16 18:10:46 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:46 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {}
2025-01-16 18:10:46 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 72
2025-01-16 18:10:46 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139283&tnum=2> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:10:46 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {"url": "https://forum.gamer.com.tw/B.php?page=2&bsn=18966"}
2025-01-16 18:10:47 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 14
2025-01-16 18:10:47 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:47 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/source {}
2025-01-16 18:10:47 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/source HTTP/1.1" 200 246868
2025-01-16 18:10:47 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:47 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {}
2025-01-16 18:10:47 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 61
2025-01-16 18:10:47 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/B.php?page=2&bsn=18966> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:10:47 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=138700&tnum=5"}
2025-01-16 18:10:47 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 14
2025-01-16 18:10:47 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:47 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/source {}
2025-01-16 18:10:47 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/source HTTP/1.1" 200 215852
2025-01-16 18:10:47 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:47 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {}
2025-01-16 18:10:47 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 72
2025-01-16 18:10:47 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=138700&tnum=5> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:10:47 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139274&tnum=3"}
2025-01-16 18:10:47 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 14
2025-01-16 18:10:47 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:47 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/source {}
2025-01-16 18:10:47 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/source HTTP/1.1" 200 164332
2025-01-16 18:10:47 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:47 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {}
2025-01-16 18:10:47 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 72
2025-01-16 18:10:47 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139274&tnum=3> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:10:47 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139275&tnum=1"}
2025-01-16 18:10:48 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 14
2025-01-16 18:10:48 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:48 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/source {}
2025-01-16 18:10:48 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/source HTTP/1.1" 200 139578
2025-01-16 18:10:48 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:48 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {}
2025-01-16 18:10:48 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 72
2025-01-16 18:10:48 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139275&tnum=1> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:10:48 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139231&tnum=11"}
2025-01-16 18:10:48 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 14
2025-01-16 18:10:48 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:48 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/source {}
2025-01-16 18:10:48 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/source HTTP/1.1" 200 264187
2025-01-16 18:10:48 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:48 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {}
2025-01-16 18:10:48 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 73
2025-01-16 18:10:48 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139231&tnum=11> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:10:48 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=138616&tnum=5"}
2025-01-16 18:10:49 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 14
2025-01-16 18:10:49 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:49 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/source {}
2025-01-16 18:10:49 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/source HTTP/1.1" 200 216156
2025-01-16 18:10:49 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:49 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {}
2025-01-16 18:10:49 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 72
2025-01-16 18:10:49 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=138616&tnum=5> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:10:49 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=138913&tnum=16"}
2025-01-16 18:10:49 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 14
2025-01-16 18:10:49 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:49 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/source {}
2025-01-16 18:10:49 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/source HTTP/1.1" 200 370228
2025-01-16 18:10:49 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:49 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {}
2025-01-16 18:10:49 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 73
2025-01-16 18:10:49 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=138913&tnum=16> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:10:49 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139276&tnum=1"}
2025-01-16 18:10:50 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 14
2025-01-16 18:10:50 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:50 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/source {}
2025-01-16 18:10:50 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/source HTTP/1.1" 200 148144
2025-01-16 18:10:50 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:50 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {}
2025-01-16 18:10:50 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 72
2025-01-16 18:10:50 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139276&tnum=1> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:10:50 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139277&tnum=1"}
2025-01-16 18:10:50 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 14
2025-01-16 18:10:50 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:50 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/source {}
2025-01-16 18:10:50 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/source HTTP/1.1" 200 152907
2025-01-16 18:10:50 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:50 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {}
2025-01-16 18:10:50 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 72
2025-01-16 18:10:50 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139277&tnum=1> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:10:50 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=138031&tnum=19"}
2025-01-16 18:10:51 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 14
2025-01-16 18:10:51 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:51 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/source {}
2025-01-16 18:10:51 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/source HTTP/1.1" 200 479853
2025-01-16 18:10:51 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:51 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {}
2025-01-16 18:10:51 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 73
2025-01-16 18:10:51 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=138031&tnum=19> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:10:51 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=137397&tnum=37"}
2025-01-16 18:10:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 14
2025-01-16 18:10:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:52 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/source {}
2025-01-16 18:10:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/source HTTP/1.1" 200 413454
2025-01-16 18:10:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:52 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {}
2025-01-16 18:10:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 73
2025-01-16 18:10:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=137397&tnum=37> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:10:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=138723&tnum=21"}
2025-01-16 18:10:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 14
2025-01-16 18:10:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:52 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/source {}
2025-01-16 18:10:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/source HTTP/1.1" 200 397263
2025-01-16 18:10:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:52 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {}
2025-01-16 18:10:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 73
2025-01-16 18:10:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=138723&tnum=21> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:10:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=138377&tnum=7"}
2025-01-16 18:10:53 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 14
2025-01-16 18:10:53 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:53 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/source {}
2025-01-16 18:10:53 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/source HTTP/1.1" 200 291313
2025-01-16 18:10:53 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:53 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {}
2025-01-16 18:10:53 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 72
2025-01-16 18:10:53 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=138377&tnum=7> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:10:53 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=138161&tnum=9"}
2025-01-16 18:10:54 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 14
2025-01-16 18:10:54 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:54 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/source {}
2025-01-16 18:10:54 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/source HTTP/1.1" 200 266982
2025-01-16 18:10:54 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:54 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {}
2025-01-16 18:10:54 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 72
2025-01-16 18:10:54 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=138161&tnum=9> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:10:54 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139281&tnum=1"}
2025-01-16 18:10:54 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 14
2025-01-16 18:10:54 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:54 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/source {}
2025-01-16 18:10:54 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/source HTTP/1.1" 200 144359
2025-01-16 18:10:54 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:54 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {}
2025-01-16 18:10:54 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 72
2025-01-16 18:10:54 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139281&tnum=1> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:10:54 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=136522&tnum=120"}
2025-01-16 18:10:55 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 14
2025-01-16 18:10:55 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:55 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/source {}
2025-01-16 18:10:55 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/source HTTP/1.1" 200 613553
2025-01-16 18:10:55 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:55 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {}
2025-01-16 18:10:55 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 74
2025-01-16 18:10:55 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=136522&tnum=120> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:10:55 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139282&tnum=1"}
2025-01-16 18:10:55 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 14
2025-01-16 18:10:55 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:55 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/source {}
2025-01-16 18:10:55 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/source HTTP/1.1" 200 140053
2025-01-16 18:10:55 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:55 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {}
2025-01-16 18:10:55 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 72
2025-01-16 18:10:55 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139282&tnum=1> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:10:55 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139154&tnum=6"}
2025-01-16 18:10:56 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 14
2025-01-16 18:10:56 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:56 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/source {}
2025-01-16 18:10:56 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/source HTTP/1.1" 200 247576
2025-01-16 18:10:56 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:56 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {}
2025-01-16 18:10:56 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 72
2025-01-16 18:10:56 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139154&tnum=6> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:10:56 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139171&tnum=24"}
2025-01-16 18:10:56 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 14
2025-01-16 18:10:56 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:56 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/source {}
2025-01-16 18:10:56 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/source HTTP/1.1" 200 451750
2025-01-16 18:10:56 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:56 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {}
2025-01-16 18:10:56 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 73
2025-01-16 18:10:56 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139171&tnum=24> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:10:56 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139280&tnum=2"}
2025-01-16 18:10:57 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 14
2025-01-16 18:10:57 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:57 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/source {}
2025-01-16 18:10:57 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/source HTTP/1.1" 200 159087
2025-01-16 18:10:57 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:57 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {}
2025-01-16 18:10:57 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 72
2025-01-16 18:10:57 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139280&tnum=2> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:10:57 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139238&tnum=13"}
2025-01-16 18:10:57 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 14
2025-01-16 18:10:57 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:57 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/source {}
2025-01-16 18:10:57 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/source HTTP/1.1" 200 314701
2025-01-16 18:10:57 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:57 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {}
2025-01-16 18:10:57 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 73
2025-01-16 18:10:57 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139238&tnum=13> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:10:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139283&tnum=2>
{'content': '   LE '
            'LE BOSS',
 'img': 'https://truth.bahamut.com.tw/s01/202501/forum/18966/c85354234d3c5862f128fd5529d949d9.JPG?w=300&h=300&fit=o',
 'title': '',
 'userName': ''}
2025-01-16 18:10:57 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/execute/sync {"script": "return document.body.scrollHeight", "args": []}
2025-01-16 18:10:57 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/execute/sync HTTP/1.1" 200 14
2025-01-16 18:10:57 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:57 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/execute/sync {"script": "window.scrollTo(0, document.body.scrollHeight);", "args": []}
2025-01-16 18:10:57 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/execute/sync HTTP/1.1" 200 14
2025-01-16 18:10:57 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:59 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/execute/sync {"script": "return document.body.scrollHeight", "args": []}
2025-01-16 18:10:59 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/execute/sync HTTP/1.1" 200 14
2025-01-16 18:10:59 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:59 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/source {}
2025-01-16 18:10:59 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/source HTTP/1.1" 200 317778
2025-01-16 18:10:59 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:59 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {}
2025-01-16 18:10:59 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 73
2025-01-16 18:10:59 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:10:59 [scrapy.core.scraper] ERROR: Error processing {'content': ' GGG  BD '
            ' POE ',
 'img': 'https://truth.bahamut.com.tw/s01/202501/forum/18966/8b27d3635e75d203c8db8b2962bd3b11.JPG?w=300&h=300&fit=o',
 'title': ' (2025/1/15)',
 'userName': ''}
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/utils/defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/Users/admin/PycharmProjects/WebCrawler/a_scrapy/example/example/pipelines.py", line 42, in process_item
    request.urlretrieve(url=url, filename=filename)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/urllib/request.py", line 249, in urlretrieve
    tfp = open(filename, 'wb')
FileNotFoundError: [Errno 2] No such file or directory: '../download/imgs/ (2025/1/15).jpg'
2025-01-16 18:10:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139274&tnum=3>
{'content': 'https://ithome.com.tw/news/166964 '
            '266GGG',
 'img': None,
 'title': '2',
 'userName': 'jacket6719'}
2025-01-16 18:10:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139275&tnum=1>
{'content': 'poe  BD   t14 15 '
            ' twitch: ',
 'img': 'https://i1.ytimg.com/vi/WTOkTcOK01I/hqdefault.jpg',
 'title': ' ',
 'userName': ''}
2025-01-16 18:10:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139231&tnum=11>
{'content': ':CI  1! : '
            'MP()!  /: '
            '  ',
 'img': 'https://truth.bahamut.com.tw/s01/202501/forum/18966/98e4358b6a1f12f52901027f80f1915d.JPG?w=300&h=300&fit=o',
 'title': '!',
 'userName': 'az5504156'}
2025-01-16 18:11:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=138616&tnum=5>
{'content': '.GGG   25D '
            '..20, ',
 'img': 'https://i1.ytimg.com/vi/C8ubRMKVFG8/hqdefault.jpg',
 'title': '()',
 'userName': ''}
2025-01-16 18:11:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=138913&tnum=16>
{'content': '~AI  '
            '',
 'img': None,
 'title': 'BUILD !!!',
 'userName': ''}
2025-01-16 18:11:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139276&tnum=1>
{'content': '     18 '
            '  https://max',
 'img': 'https://truth.bahamut.com.tw/s01/202501/forum/18966/7e5589db4dbde93c002c40f938f327bd.JPG?w=300&h=300&fit=o',
 'title': '',
 'userName': ''}
2025-01-16 18:11:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139277&tnum=1>
{'content': 'https://www.pixiv.net/artworks/125927689 16% '
            '  1. 2.()  3./ 4. 1.  '
            ':EX EX',
 'img': 'https://truth.bahamut.com.tw/s01/202501/forum/18966/de8451ed4907cd51622081300a329b38.JPG?w=300&h=300&fit=o',
 'title': 'T450',
 'userName': ''}
2025-01-16 18:11:00 [scrapy.core.scraper] ERROR: Error processing {'content': 'Never sinkNeversink_Strict '
            ' ',
 'img': 'https://truth.bahamut.com.tw/s01/202412/forum/18966/75848e01cf1a2cb2ecb3203b65809fd4.JPG?w=300&h=300&fit=o',
 'title': '1/14 Neversink',
 'userName': ''}
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/utils/defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/Users/admin/PycharmProjects/WebCrawler/a_scrapy/example/example/pipelines.py", line 42, in process_item
    request.urlretrieve(url=url, filename=filename)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/urllib/request.py", line 249, in urlretrieve
    tfp = open(filename, 'wb')
FileNotFoundError: [Errno 2] No such file or directory: '../download/imgs/1/14 Neversink.jpg'
2025-01-16 18:11:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=137397&tnum=37>
{'content': ': reddit poe  : '
            'GGGPOE1POE2 EA() ',
 'img': None,
 'title': 'POE 1&2 ',
 'userName': 'baha0079'}
2025-01-16 18:11:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=138723&tnum=21>
{'content': '   ()  (/) CI (/)  () '
            '()()',
 'img': None,
 'title': 'POE 2    1/12 ',
 'userName': ''}
2025-01-16 18:11:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=138377&tnum=7>
{'content': 'RuzRain  build   '
            'T0 ',
 'img': None,
 'title': '1DBOSS ,feat COC ,  ',
 'userName': 'Ruz'}
2025-01-16 18:11:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=138161&tnum=9>
{'content': ' DC,  '
            ', ',
 'img': None,
 'title': ',',
 'userName': ''}
2025-01-16 18:11:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139281&tnum=1>
{'content': '    D1 D2   '
            'D2     90',
 'img': None,
 'title': 'poe2  ',
 'userName': 'evilalways'}
2025-01-16 18:11:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=136522&tnum=120>
{'content': '      (ctrl+f) 12/11 '
            ' 12/13 ',
 'img': None,
 'title': '[]-POE2  (1/2 ',
 'userName': ''}
2025-01-16 18:11:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139282&tnum=1>
{'content': ' +10%?',
 'img': None,
 'title': '?',
 'userName': 'PosiVibe'}
2025-01-16 18:11:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139154&tnum=6>
{'content': '==  2  '
            ' NPC ',
 'img': None,
 'title': 'NPC ()',
 'userName': ''}
2025-01-16 18:11:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139171&tnum=24>
{'content': '  D4 /POE2/  '
            ' ///',
 'img': None,
 'title': ' POE2',
 'userName': 'allen'}
2025-01-16 18:11:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139280&tnum=2>
{'content': '1D 55Dok ?_? '
            '  ',
 'img': None,
 'title': ' ',
 'userName': ''}
2025-01-16 18:11:00 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=136809&tnum=154"}
2025-01-16 18:11:00 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 14
2025-01-16 18:11:00 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:11:00 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/source {}
2025-01-16 18:11:00 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/source HTTP/1.1" 200 436700
2025-01-16 18:11:00 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:11:00 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {}
2025-01-16 18:11:00 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 74
2025-01-16 18:11:00 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:11:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=136809&tnum=154> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:11:00 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139278&tnum=24"}
2025-01-16 18:11:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "POST /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 14
2025-01-16 18:11:01 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:11:01 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/source {}
2025-01-16 18:11:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/source HTTP/1.1" 200 486210
2025-01-16 18:11:01 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:11:01 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2/url {}
2025-01-16 18:11:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "GET /session/7703334f5929294336fc39eea45829a2/url HTTP/1.1" 200 73
2025-01-16 18:11:01 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:11:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139278&tnum=24> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:11:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139238&tnum=13>
{'content': ' : POE '
            ' ...',
 'img': 'https://truth.bahamut.com.tw/s01/202501/forum/18966/562818bb7e9382fdb0637dff8f6ae9e4.JPG?w=300&h=300&fit=o',
 'title': '...',
 'userName': ''}
2025-01-16 18:11:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=136809&tnum=154>
{'content': 'POE2 '
            '',
 'img': 'https://truth.bahamut.com.tw/s01/202412/forum/18966/404f00297ce9b876763a192534b2e3e9.JPG?w=300&h=300&fit=o',
 'title': 'POE2',
 'userName': 'War'}
2025-01-16 18:11:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139278&tnum=24>
{'content': 'https://www.pathofexile.com/forum/view-thread/3695606/page/1#p25859331 '
            '1/17      4 ',
 'img': None,
 'title': 'Poe 2 0.1.1 Patch note ',
 'userName': '33456109'}
2025-01-16 18:11:01 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-16 18:11:01 [selenium.webdriver.remote.remote_connection] DEBUG: DELETE http://127.0.0.1:64772/session/7703334f5929294336fc39eea45829a2 {}
2025-01-16 18:11:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64772 "DELETE /session/7703334f5929294336fc39eea45829a2 HTTP/1.1" 200 14
2025-01-16 18:11:01 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:11:01 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 6141261,
 'downloader/response_count': 25,
 'downloader/response_status_count/200': 25,
 'elapsed_time_seconds': 20.462011,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 16, 10, 11, 1, 748929, tzinfo=datetime.timezone.utc),
 'item_scraped_count': 21,
 'items_per_minute': None,
 'log_count/DEBUG': 319,
 'log_count/ERROR': 2,
 'log_count/INFO': 10,
 'memusage/max': 60309504,
 'memusage/startup': 60309504,
 'request_depth_max': 1,
 'response_received_count': 25,
 'responses_per_minute': None,
 'scheduler/dequeued': 25,
 'scheduler/dequeued/memory': 25,
 'scheduler/enqueued': 25,
 'scheduler/enqueued/memory': 25,
 'start_time': datetime.datetime(2025, 1, 16, 10, 10, 41, 286918, tzinfo=datetime.timezone.utc)}
2025-01-16 18:11:01 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-16 18:14:08 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: example)
2025-01-16 18:14:08 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.11.0, Python 3.9.6 (default, May  7 2023, 23:32:44) - [Clang 14.0.3 (clang-1403.0.22.14.1)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform macOS-13.2.1-arm64-arm-64bit
2025-01-16 18:14:08 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-16 18:14:08 [asyncio] DEBUG: Using selector: KqueueSelector
2025-01-16 18:14:08 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-16 18:14:08 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-16 18:14:08 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-16 18:14:08 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-16 18:14:08 [scrapy.extensions.telnet] INFO: Telnet Password: 8cc1d37767ea001f
2025-01-16 18:14:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-16 18:14:08 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'example',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': '../log/example.log',
 'NEWSPIDER_MODULE': 'example.spiders',
 'SPIDER_MODULES': ['example.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-16 18:14:09 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"extensions": [], "args": ["--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"extensions": [], "args": ["--headless"]}}}
2025-01-16 18:14:09 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:49387
2025-01-16 18:14:09 [urllib3.connectionpool] DEBUG: http://127.0.0.1:49387 "POST /session HTTP/1.1" 200 892
2025-01-16 18:14:09 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:14:09 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy_selenium.SeleniumMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-16 18:14:09 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-16 18:14:09 [scrapy.middleware] INFO: Enabled item pipelines:
['example.pipelines.ExamplePipeline', 'example.pipelines.ExampleDownloadImg']
2025-01-16 18:14:09 [scrapy.core.engine] INFO: Spider opened
2025-01-16 18:14:09 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-16 18:14:09 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-01-16 18:14:09 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/url {"url": "https://forum.gamer.com.tw/B.php?page=1&bsn=18966"}
2025-01-16 18:14:10 [urllib3.connectionpool] DEBUG: http://127.0.0.1:49387 "POST /session/55a9a26597a550e1a0efbc46b6615891/url HTTP/1.1" 200 14
2025-01-16 18:14:10 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:14:10 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/source {}
2025-01-16 18:14:10 [urllib3.connectionpool] DEBUG: http://127.0.0.1:49387 "GET /session/55a9a26597a550e1a0efbc46b6615891/source HTTP/1.1" 200 248991
2025-01-16 18:14:10 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:14:10 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/url {}
2025-01-16 18:14:10 [urllib3.connectionpool] DEBUG: http://127.0.0.1:49387 "GET /session/55a9a26597a550e1a0efbc46b6615891/url HTTP/1.1" 200 61
2025-01-16 18:14:10 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:14:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/B.php?page=1&bsn=18966> (referer: None)
2025-01-16 18:14:10 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/execute/sync {"script": "return document.body.scrollHeight", "args": []}
2025-01-16 18:14:10 [urllib3.connectionpool] DEBUG: http://127.0.0.1:49387 "POST /session/55a9a26597a550e1a0efbc46b6615891/execute/sync HTTP/1.1" 200 14
2025-01-16 18:14:10 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:14:10 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/execute/sync {"script": "window.scrollTo(0, document.body.scrollHeight);", "args": []}
2025-01-16 18:14:10 [urllib3.connectionpool] DEBUG: http://127.0.0.1:49387 "POST /session/55a9a26597a550e1a0efbc46b6615891/execute/sync HTTP/1.1" 200 14
2025-01-16 18:14:10 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:14:12 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/execute/sync {"script": "return document.body.scrollHeight", "args": []}
2025-01-16 18:14:12 [urllib3.connectionpool] DEBUG: http://127.0.0.1:49387 "POST /session/55a9a26597a550e1a0efbc46b6615891/execute/sync HTTP/1.1" 200 14
2025-01-16 18:14:12 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:14:12 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/execute/sync {"script": "window.scrollTo(0, document.body.scrollHeight);", "args": []}
2025-01-16 18:14:12 [urllib3.connectionpool] DEBUG: http://127.0.0.1:49387 "POST /session/55a9a26597a550e1a0efbc46b6615891/execute/sync HTTP/1.1" 200 14
2025-01-16 18:14:12 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:14:14 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/execute/sync {"script": "return document.body.scrollHeight", "args": []}
2025-01-16 18:14:14 [urllib3.connectionpool] DEBUG: http://127.0.0.1:49387 "POST /session/55a9a26597a550e1a0efbc46b6615891/execute/sync HTTP/1.1" 200 14
2025-01-16 18:14:14 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:14:14 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/source {}
2025-01-16 18:14:14 [urllib3.connectionpool] DEBUG: http://127.0.0.1:49387 "GET /session/55a9a26597a550e1a0efbc46b6615891/source HTTP/1.1" 200 252130
2025-01-16 18:14:14 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:14:14 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/url {}
2025-01-16 18:14:14 [urllib3.connectionpool] DEBUG: http://127.0.0.1:49387 "GET /session/55a9a26597a550e1a0efbc46b6615891/url HTTP/1.1" 200 61
2025-01-16 18:14:14 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:14:14 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139283&tnum=2"}
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: http://127.0.0.1:49387 "POST /session/55a9a26597a550e1a0efbc46b6615891/url HTTP/1.1" 200 14
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/source {}
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: http://127.0.0.1:49387 "GET /session/55a9a26597a550e1a0efbc46b6615891/source HTTP/1.1" 200 155416
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/url {}
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: http://127.0.0.1:49387 "GET /session/55a9a26597a550e1a0efbc46b6615891/url HTTP/1.1" 200 72
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:14:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139283&tnum=2> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/url {"url": "https://forum.gamer.com.tw/B.php?page=2&bsn=18966"}
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: http://127.0.0.1:49387 "POST /session/55a9a26597a550e1a0efbc46b6615891/url HTTP/1.1" 200 14
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/source {}
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: http://127.0.0.1:49387 "GET /session/55a9a26597a550e1a0efbc46b6615891/source HTTP/1.1" 200 246812
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/url {}
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: http://127.0.0.1:49387 "GET /session/55a9a26597a550e1a0efbc46b6615891/url HTTP/1.1" 200 61
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:14:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/B.php?page=2&bsn=18966> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=138700&tnum=5"}
2025-01-16 18:14:15 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: http://127.0.0.1:49387 "POST /session/55a9a26597a550e1a0efbc46b6615891/url HTTP/1.1" 200 14
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/source {}
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Resetting dropped connection: 127.0.0.1
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/source'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104c371f0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/source
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (2): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/source'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104d8ebe0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/source
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (3): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/source'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104d8e220>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/source
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (4): 127.0.0.1:49387
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139274&tnum=3"}
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (5): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104dc92e0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (6): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104dc90d0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (7): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104db9e20>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (8): 127.0.0.1:49387
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139275&tnum=1"}
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (9): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104db9af0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (10): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104db98b0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (11): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e040a0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (12): 127.0.0.1:49387
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139231&tnum=11"}
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (13): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e04d90>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (14): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e04f40>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (15): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e0a070>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (16): 127.0.0.1:49387
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=138616&tnum=5"}
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (17): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e0ad60>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (18): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e0af10>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (19): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e19070>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (20): 127.0.0.1:49387
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=138913&tnum=16"}
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (21): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e19d30>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (22): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104d8e2e0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (23): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e19ee0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (24): 127.0.0.1:49387
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139276&tnum=1"}
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (25): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e25c10>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (26): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e25dc0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (27): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e25eb0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (28): 127.0.0.1:49387
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139277&tnum=1"}
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (29): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e35be0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (30): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e35d90>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (31): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e35e80>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (32): 127.0.0.1:49387
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=138031&tnum=19"}
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (33): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e47bb0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (34): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e47d60>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (35): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e47e50>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (36): 127.0.0.1:49387
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=137397&tnum=37"}
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (37): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e56b80>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (38): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e56d30>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (39): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e56e20>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (40): 127.0.0.1:49387
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=138723&tnum=21"}
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (41): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e62b50>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (42): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e62d00>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (43): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e62df0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (44): 127.0.0.1:49387
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=138377&tnum=7"}
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (45): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e75b20>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (46): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e75cd0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (47): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e75dc0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (48): 127.0.0.1:49387
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=138161&tnum=9"}
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (49): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e85af0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (50): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e85ca0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (51): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e85d90>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (52): 127.0.0.1:49387
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139281&tnum=1"}
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (53): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e92ac0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (54): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e92c70>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (55): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e92d60>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (56): 127.0.0.1:49387
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=136522&tnum=120"}
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (57): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104ea5a90>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (58): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104ea5c40>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (59): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104ea5d30>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (60): 127.0.0.1:49387
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139282&tnum=1"}
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (61): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104eb4a60>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (62): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104eb4c10>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (63): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104eb4d00>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (64): 127.0.0.1:49387
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139154&tnum=6"}
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (65): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104ec4a30>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (66): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104ec4be0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (67): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104ec4cd0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (68): 127.0.0.1:49387
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139171&tnum=24"}
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (69): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x105101a00>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (70): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x105101bb0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (71): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x105101ca0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (72): 127.0.0.1:49387
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139280&tnum=2"}
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (73): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x1051109d0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (74): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x105110b80>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (75): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x105110c70>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (76): 127.0.0.1:49387
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139238&tnum=13"}
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (77): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10511c9a0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (78): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10511cb50>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (79): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10511cc40>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (80): 127.0.0.1:49387
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=136809&tnum=154"}
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (81): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10512e970>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (82): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10512eb20>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (83): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10512ec10>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (84): 127.0.0.1:49387
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139278&tnum=24"}
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (85): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x1051408e0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (86): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x105140a90>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (87): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x105140b80>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/url
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (88): 127.0.0.1:49387
2025-01-16 18:14:15 [scrapy.core.engine] INFO: Closing spider (shutdown)
2025-01-16 18:14:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://forum.gamer.com.tw/C.php?bsn=18966&snA=139283&tnum=2>
{'content': '   LE '
            'LE BOSS',
 'img': 'https://truth.bahamut.com.tw/s01/202501/forum/18966/c85354234d3c5862f128fd5529d949d9.JPG?w=300&h=300&fit=o',
 'title': '',
 'userName': ''}
2025-01-16 18:14:15 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:49387/session/55a9a26597a550e1a0efbc46b6615891/execute/sync {"script": "return document.body.scrollHeight", "args": []}
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (89): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/execute/sync'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x1051c4070>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/execute/sync
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (90): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/execute/sync'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x1051c4160>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/execute/sync
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (91): 127.0.0.1:49387
2025-01-16 18:14:15 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/55a9a26597a550e1a0efbc46b6615891/execute/sync'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 18:14:15 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x1051c42b0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/55a9a26597a550e1a0efbc46b6615891/execute/sync
2025-01-16 18:14:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (92): 127.0.0.1:49387
2025-01-16 18:14:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://forum.gamer.com.tw/B.php?page=2&bsn=18966> (referer: https://forum.gamer.com.tw/B.php?page=1&bsn=18966)
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x1051c4400>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/utils/defer.py", line 327, in iter_errback
    yield next(it)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 368, in __next__
    return next(self.data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/utils/python.py", line 368, in __next__
    return next(self.data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/referer.py", line 379, in <genexpr>
    return (self._set_referer(r, response) for r in result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/urllength.py", line 57, in <genexpr>
    return (r for r in result if self._filter(r, spider))
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/spidermiddlewares/depth.py", line 54, in <genexpr>
    return (r for r in result if self._filter(r, response, spider))
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/Users/admin/PycharmProjects/WebCrawler/a_scrapy/example/example/spiders/game_content.py", line 49, in parse
    last_height = driver.execute_script("return document.body.scrollHeight")
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 634, in execute_script
    return self.execute(command, {
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=49387): Max retries exceeded with url: /session/55a9a26597a550e1a0efbc46b6615891/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x1051c4400>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:14:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=138700&tnum=5>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x104d8eb20>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 105, in process_request
    body = str.encode(self.driver.page_source)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 77, in request
    return self.request_encode_url(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 99, in request_encode_url
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=49387): Max retries exceeded with url: /session/55a9a26597a550e1a0efbc46b6615891/source (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104d8eb20>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:14:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139274&tnum=3>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x104db9970>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=49387): Max retries exceeded with url: /session/55a9a26597a550e1a0efbc46b6615891/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104db9970>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:14:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139275&tnum=1>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x104e04220>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=49387): Max retries exceeded with url: /session/55a9a26597a550e1a0efbc46b6615891/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e04220>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:14:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139231&tnum=11>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x104e0a1f0>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=49387): Max retries exceeded with url: /session/55a9a26597a550e1a0efbc46b6615891/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e0a1f0>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:14:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=138616&tnum=5>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x104e191c0>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=49387): Max retries exceeded with url: /session/55a9a26597a550e1a0efbc46b6615891/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e191c0>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:14:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=138913&tnum=16>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x104e250a0>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=49387): Max retries exceeded with url: /session/55a9a26597a550e1a0efbc46b6615891/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e250a0>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:14:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139276&tnum=1>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x104e35070>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=49387): Max retries exceeded with url: /session/55a9a26597a550e1a0efbc46b6615891/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e35070>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:14:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139277&tnum=1>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x104e47070>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=49387): Max retries exceeded with url: /session/55a9a26597a550e1a0efbc46b6615891/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e47070>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:14:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=138031&tnum=19>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x104e56040>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=49387): Max retries exceeded with url: /session/55a9a26597a550e1a0efbc46b6615891/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e56040>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:14:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=137397&tnum=37>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x104e62070>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=49387): Max retries exceeded with url: /session/55a9a26597a550e1a0efbc46b6615891/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e62070>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:14:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=138723&tnum=21>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x104e75040>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=49387): Max retries exceeded with url: /session/55a9a26597a550e1a0efbc46b6615891/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e75040>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:14:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=138377&tnum=7>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x104e75f40>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=49387): Max retries exceeded with url: /session/55a9a26597a550e1a0efbc46b6615891/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e75f40>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:14:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=138161&tnum=9>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x104e85f10>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=49387): Max retries exceeded with url: /session/55a9a26597a550e1a0efbc46b6615891/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e85f10>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:14:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139281&tnum=1>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x104e92ee0>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=49387): Max retries exceeded with url: /session/55a9a26597a550e1a0efbc46b6615891/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104e92ee0>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:14:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=136522&tnum=120>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x104ea5eb0>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=49387): Max retries exceeded with url: /session/55a9a26597a550e1a0efbc46b6615891/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104ea5eb0>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:14:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139282&tnum=1>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x104eb4e80>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=49387): Max retries exceeded with url: /session/55a9a26597a550e1a0efbc46b6615891/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104eb4e80>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:14:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139154&tnum=6>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x104ec4e50>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=49387): Max retries exceeded with url: /session/55a9a26597a550e1a0efbc46b6615891/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x104ec4e50>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:14:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139171&tnum=24>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x105101e20>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=49387): Max retries exceeded with url: /session/55a9a26597a550e1a0efbc46b6615891/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x105101e20>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:14:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139280&tnum=2>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x105110df0>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=49387): Max retries exceeded with url: /session/55a9a26597a550e1a0efbc46b6615891/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x105110df0>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:14:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139238&tnum=13>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x10511cdc0>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=49387): Max retries exceeded with url: /session/55a9a26597a550e1a0efbc46b6615891/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10511cdc0>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:14:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=136809&tnum=154>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x10512ed90>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=49387): Max retries exceeded with url: /session/55a9a26597a550e1a0efbc46b6615891/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10512ed90>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:14:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139278&tnum=24>
Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1257, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1303, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1252, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 1012, in _send_output
    self.send(msg)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py", line 952, in send
    self.connect()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x105140d00>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/admin/PycharmProjects/WebCrawler/.venv/lib/python3.9/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=49387): Max retries exceeded with url: /session/55a9a26597a550e1a0efbc46b6615891/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x105140d00>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 18:14:15 [scrapy.crawler] INFO: Received SIGINT twice, forcing unclean shutdown
2025-01-16 22:16:26 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: example)
2025-01-16 22:16:26 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.11.0, Python 3.10.16 (main, Jan 16 2025, 13:43:45) [Clang 13.1.6 (clang-1316.0.21.2.5)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform macOS-12.2.1-x86_64-i386-64bit
2025-01-16 22:16:26 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-16 22:16:26 [asyncio] DEBUG: Using selector: KqueueSelector
2025-01-16 22:16:26 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-16 22:16:26 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-16 22:16:26 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-16 22:16:26 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-16 22:16:26 [scrapy.extensions.telnet] INFO: Telnet Password: e846f8b1c4e8b169
2025-01-16 22:16:26 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-16 22:16:26 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'example',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': '../log/example.log',
 'NEWSPIDER_MODULE': 'example.spiders',
 'SPIDER_MODULES': ['example.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-16 22:16:26 [twisted] CRITICAL: Unhandled error in Deferred:
2025-01-16 22:16:26 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/common/service.py", line 72, in start
    self.process = subprocess.Popen(cmd, env=self.env,
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/subprocess.py", line 971, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/subprocess.py", line 1863, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/admin/.wdm/drivers/chromedriver/mac64/131.0.6778.264/chromedriver-mac-arm64/chromedriver'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/crawler.py", line 152, in crawl
    self.engine = self._create_engine()
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/crawler.py", line 166, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/core/engine.py", line 101, in __init__
    self.downloader: Downloader = downloader_cls(crawler)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/core/downloader/__init__.py", line 109, in __init__
    DownloaderMiddlewareManager.from_crawler(crawler)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/middleware.py", line 77, in from_crawler
    return cls._from_settings(crawler.settings, crawler)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/middleware.py", line 88, in _from_settings
    mw = build_from_crawler(mwcls, crawler)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/utils/misc.py", line 187, in build_from_crawler
    instance = objcls.from_crawler(crawler, *args, **kwargs)  # type: ignore[attr-defined]
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy_selenium/middlewares.py", line 67, in from_crawler
    middleware = cls(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy_selenium/middlewares.py", line 51, in __init__
    self.driver = driver_klass(**driver_kwargs)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/chrome/webdriver.py", line 73, in __init__
    self.service.start()
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/common/service.py", line 81, in start
    raise WebDriverException(
selenium.common.exceptions.WebDriverException: Message: 'chromedriver' executable needs to be in PATH. Please see https://sites.google.com/a/chromium.org/chromedriver/home

2025-01-16 22:17:02 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: example)
2025-01-16 22:17:02 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.11.0, Python 3.10.16 (main, Jan 16 2025, 13:43:45) [Clang 13.1.6 (clang-1316.0.21.2.5)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform macOS-12.2.1-x86_64-i386-64bit
2025-01-16 22:17:02 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-16 22:17:02 [asyncio] DEBUG: Using selector: KqueueSelector
2025-01-16 22:17:02 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-16 22:17:02 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-16 22:17:02 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-16 22:17:02 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-16 22:17:02 [scrapy.extensions.telnet] INFO: Telnet Password: 085744b1446bd135
2025-01-16 22:17:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-16 22:17:02 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'example',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': '../log/example.log',
 'NEWSPIDER_MODULE': 'example.spiders',
 'SPIDER_MODULES': ['example.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-16 22:17:02 [twisted] CRITICAL: Unhandled error in Deferred:
2025-01-16 22:17:02 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/common/service.py", line 72, in start
    self.process = subprocess.Popen(cmd, env=self.env,
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/subprocess.py", line 971, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/subprocess.py", line 1863, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/admin/.wdm/drivers/chromedriver/mac64/131.0.6778.264/chromedriver-mac-arm64/chromedriver'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/crawler.py", line 152, in crawl
    self.engine = self._create_engine()
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/crawler.py", line 166, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/core/engine.py", line 101, in __init__
    self.downloader: Downloader = downloader_cls(crawler)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/core/downloader/__init__.py", line 109, in __init__
    DownloaderMiddlewareManager.from_crawler(crawler)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/middleware.py", line 77, in from_crawler
    return cls._from_settings(crawler.settings, crawler)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/middleware.py", line 88, in _from_settings
    mw = build_from_crawler(mwcls, crawler)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/utils/misc.py", line 187, in build_from_crawler
    instance = objcls.from_crawler(crawler, *args, **kwargs)  # type: ignore[attr-defined]
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy_selenium/middlewares.py", line 67, in from_crawler
    middleware = cls(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy_selenium/middlewares.py", line 51, in __init__
    self.driver = driver_klass(**driver_kwargs)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/chrome/webdriver.py", line 73, in __init__
    self.service.start()
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/common/service.py", line 81, in start
    raise WebDriverException(
selenium.common.exceptions.WebDriverException: Message: 'chromedriver' executable needs to be in PATH. Please see https://sites.google.com/a/chromium.org/chromedriver/home

2025-01-16 22:22:09 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: example)
2025-01-16 22:22:09 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.11.0, Python 3.10.16 (main, Jan 16 2025, 13:43:45) [Clang 13.1.6 (clang-1316.0.21.2.5)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform macOS-12.2.1-x86_64-i386-64bit
2025-01-16 22:22:09 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-16 22:22:09 [asyncio] DEBUG: Using selector: KqueueSelector
2025-01-16 22:22:09 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-16 22:22:09 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-16 22:22:09 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-16 22:22:09 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-16 22:22:09 [scrapy.extensions.telnet] INFO: Telnet Password: 8eba7648bacb2549
2025-01-16 22:22:09 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-16 22:22:09 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'example',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': '../log/example.log',
 'NEWSPIDER_MODULE': 'example.spiders',
 'SPIDER_MODULES': ['example.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-16 22:22:09 [twisted] CRITICAL: Unhandled error in Deferred:
2025-01-16 22:22:09 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/common/service.py", line 72, in start
    self.process = subprocess.Popen(cmd, env=self.env,
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/subprocess.py", line 971, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/subprocess.py", line 1863, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/admin/.wdm/drivers/chromedriver/mac64/131.0.6778.264/chromedriver-mac-arm64/chromedriver'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/crawler.py", line 152, in crawl
    self.engine = self._create_engine()
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/crawler.py", line 166, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/core/engine.py", line 101, in __init__
    self.downloader: Downloader = downloader_cls(crawler)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/core/downloader/__init__.py", line 109, in __init__
    DownloaderMiddlewareManager.from_crawler(crawler)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/middleware.py", line 77, in from_crawler
    return cls._from_settings(crawler.settings, crawler)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/middleware.py", line 88, in _from_settings
    mw = build_from_crawler(mwcls, crawler)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/utils/misc.py", line 187, in build_from_crawler
    instance = objcls.from_crawler(crawler, *args, **kwargs)  # type: ignore[attr-defined]
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy_selenium/middlewares.py", line 67, in from_crawler
    middleware = cls(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy_selenium/middlewares.py", line 51, in __init__
    self.driver = driver_klass(**driver_kwargs)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/chrome/webdriver.py", line 73, in __init__
    self.service.start()
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/common/service.py", line 81, in start
    raise WebDriverException(
selenium.common.exceptions.WebDriverException: Message: 'chromedriver' executable needs to be in PATH. Please see https://sites.google.com/a/chromium.org/chromedriver/home

2025-01-16 22:25:02 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: example)
2025-01-16 22:25:02 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.11.0, Python 3.10.16 (main, Jan 16 2025, 13:43:45) [Clang 13.1.6 (clang-1316.0.21.2.5)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform macOS-12.2.1-x86_64-i386-64bit
2025-01-16 22:25:02 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-16 22:25:02 [asyncio] DEBUG: Using selector: KqueueSelector
2025-01-16 22:25:02 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-16 22:25:02 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-16 22:25:02 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-16 22:25:02 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-16 22:25:02 [scrapy.extensions.telnet] INFO: Telnet Password: d30efa8e8ed4bf62
2025-01-16 22:25:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-16 22:25:02 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'example',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': '../log/example.log',
 'NEWSPIDER_MODULE': 'example.spiders',
 'SPIDER_MODULES': ['example.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-16 22:25:03 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:52141/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"extensions": [], "args": ["--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"extensions": [], "args": ["--headless"]}}}
2025-01-16 22:25:03 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:52141
2025-01-16 22:25:30 [urllib3.connectionpool] DEBUG: http://127.0.0.1:52141 "POST /session HTTP/1.1" 200 892
2025-01-16 22:25:30 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 22:25:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy_selenium.SeleniumMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-16 22:25:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-16 22:25:30 [scrapy.middleware] INFO: Enabled item pipelines:
['example.pipelines.ExamplePipeline', 'example.pipelines.ExampleDownloadImg']
2025-01-16 22:25:30 [scrapy.core.engine] INFO: Spider opened
2025-01-16 22:25:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-16 22:25:30 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-01-16 22:25:30 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:52141/session/9318fd7179f938b7b88bccbeecc41758/url {"url": "https://forum.gamer.com.tw/B.php?page=1&bsn=18966"}
2025-01-16 22:25:58 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2025-01-16 22:25:58 [scrapy.core.engine] INFO: Closing spider (shutdown)
2025-01-16 22:25:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/B.php?page=1&bsn=18966>
Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 468, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 463, in _make_request
    httplib_response = conn.getresponse()
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1375, in getresponse
    response.begin()
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 287, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/retry.py", line 552, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/packages/six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 468, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 463, in _make_request
    httplib_response = conn.getresponse()
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1375, in getresponse
    response.begin()
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 287, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
2025-01-16 22:25:58 [scrapy.crawler] INFO: Received SIGINT twice, forcing unclean shutdown
2025-01-16 22:26:00 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: example)
2025-01-16 22:26:00 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.11.0, Python 3.10.16 (main, Jan 16 2025, 13:43:45) [Clang 13.1.6 (clang-1316.0.21.2.5)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform macOS-12.2.1-x86_64-i386-64bit
2025-01-16 22:26:00 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-16 22:26:00 [asyncio] DEBUG: Using selector: KqueueSelector
2025-01-16 22:26:00 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-16 22:26:00 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-16 22:26:00 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-16 22:26:00 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-16 22:26:00 [scrapy.extensions.telnet] INFO: Telnet Password: dcffa8d3f285a22b
2025-01-16 22:26:00 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-16 22:26:00 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'example',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': '../log/example.log',
 'NEWSPIDER_MODULE': 'example.spiders',
 'SPIDER_MODULES': ['example.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-16 22:26:01 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:52189/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"extensions": [], "args": ["--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"extensions": [], "args": ["--headless"]}}}
2025-01-16 22:26:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:52189
2025-01-16 22:26:06 [urllib3.connectionpool] DEBUG: http://127.0.0.1:52189 "POST /session HTTP/1.1" 200 892
2025-01-16 22:26:06 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 22:26:06 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy_selenium.SeleniumMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-16 22:26:06 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-16 22:26:06 [scrapy.middleware] INFO: Enabled item pipelines:
['example.pipelines.ExamplePipeline', 'example.pipelines.ExampleDownloadImg']
2025-01-16 22:26:06 [scrapy.core.engine] INFO: Spider opened
2025-01-16 22:26:06 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-16 22:26:06 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-01-16 22:26:06 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:52189/session/1af0c389220192e8602776ca66d14da6/url {"url": "https://forum.gamer.com.tw/B.php?page=1&bsn=18966"}
2025-01-16 22:26:40 [urllib3.connectionpool] DEBUG: http://127.0.0.1:52189 "POST /session/1af0c389220192e8602776ca66d14da6/url HTTP/1.1" 200 14
2025-01-16 22:26:40 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 22:26:40 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:52189/session/1af0c389220192e8602776ca66d14da6/source {}
2025-01-16 22:26:43 [urllib3.connectionpool] DEBUG: http://127.0.0.1:52189 "GET /session/1af0c389220192e8602776ca66d14da6/source HTTP/1.1" 200 249317
2025-01-16 22:26:43 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 22:26:43 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:52189/session/1af0c389220192e8602776ca66d14da6/url {}
2025-01-16 22:26:43 [urllib3.connectionpool] DEBUG: http://127.0.0.1:52189 "GET /session/1af0c389220192e8602776ca66d14da6/url HTTP/1.1" 200 61
2025-01-16 22:26:43 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 22:26:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://forum.gamer.com.tw/B.php?page=1&bsn=18966> (referer: None)
2025-01-16 22:26:43 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:52189/session/1af0c389220192e8602776ca66d14da6/execute/sync {"script": "return document.body.scrollHeight", "args": []}
2025-01-16 22:26:43 [urllib3.connectionpool] DEBUG: http://127.0.0.1:52189 "POST /session/1af0c389220192e8602776ca66d14da6/execute/sync HTTP/1.1" 200 14
2025-01-16 22:26:43 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 22:26:43 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:52189/session/1af0c389220192e8602776ca66d14da6/execute/sync {"script": "window.scrollTo(0, document.body.scrollHeight);", "args": []}
2025-01-16 22:26:43 [urllib3.connectionpool] DEBUG: http://127.0.0.1:52189 "POST /session/1af0c389220192e8602776ca66d14da6/execute/sync HTTP/1.1" 200 14
2025-01-16 22:26:43 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 22:26:45 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:52189/session/1af0c389220192e8602776ca66d14da6/execute/sync {"script": "return document.body.scrollHeight", "args": []}
2025-01-16 22:26:46 [urllib3.connectionpool] DEBUG: http://127.0.0.1:52189 "POST /session/1af0c389220192e8602776ca66d14da6/execute/sync HTTP/1.1" 200 14
2025-01-16 22:26:46 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 22:26:46 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:52189/session/1af0c389220192e8602776ca66d14da6/source {}
2025-01-16 22:26:46 [urllib3.connectionpool] DEBUG: http://127.0.0.1:52189 "GET /session/1af0c389220192e8602776ca66d14da6/source HTTP/1.1" 200 250875
2025-01-16 22:26:46 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 22:26:46 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:52189/session/1af0c389220192e8602776ca66d14da6/url {}
2025-01-16 22:26:46 [urllib3.connectionpool] DEBUG: http://127.0.0.1:52189 "GET /session/1af0c389220192e8602776ca66d14da6/url HTTP/1.1" 200 61
2025-01-16 22:26:46 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 22:26:46 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:52189/session/1af0c389220192e8602776ca66d14da6/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139280&tnum=7"}
2025-01-16 22:26:52 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2025-01-16 22:26:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:52189/session/1af0c389220192e8602776ca66d14da6/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=138031&tnum=21"}
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (2): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10ea1db70>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (3): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10ea1fcd0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (4): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10ea1fbe0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (5): 127.0.0.1:52189
2025-01-16 22:26:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:52189/session/1af0c389220192e8602776ca66d14da6/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=104740&tnum=1068"}
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (6): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eab4940>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (7): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eab4af0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (8): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eab4be0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (9): 127.0.0.1:52189
2025-01-16 22:26:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:52189/session/1af0c389220192e8602776ca66d14da6/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139033&tnum=7"}
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (10): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eab58d0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (11): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eab5a80>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (12): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eab5b70>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (13): 127.0.0.1:52189
2025-01-16 22:26:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:52189/session/1af0c389220192e8602776ca66d14da6/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139290&tnum=1"}
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (14): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eab6860>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (15): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eab6a10>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (16): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eab6b00>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (17): 127.0.0.1:52189
2025-01-16 22:26:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:52189/session/1af0c389220192e8602776ca66d14da6/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139154&tnum=7"}
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (18): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eab77f0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (19): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eab79a0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (20): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eab7a90>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (21): 127.0.0.1:52189
2025-01-16 22:26:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:52189/session/1af0c389220192e8602776ca66d14da6/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139200&tnum=2"}
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (22): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eb347c0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (23): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eb34970>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (24): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eb34a60>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (25): 127.0.0.1:52189
2025-01-16 22:26:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:52189/session/1af0c389220192e8602776ca66d14da6/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139291&tnum=1"}
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (26): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eb35750>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (27): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eb35900>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (28): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eb359f0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (29): 127.0.0.1:52189
2025-01-16 22:26:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:52189/session/1af0c389220192e8602776ca66d14da6/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139292&tnum=1"}
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (30): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eb366e0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (31): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eb36890>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (32): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eb36980>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (33): 127.0.0.1:52189
2025-01-16 22:26:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:52189/session/1af0c389220192e8602776ca66d14da6/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139293&tnum=1"}
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (34): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eb37670>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (35): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eb37820>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (36): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eb37910>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (37): 127.0.0.1:52189
2025-01-16 22:26:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:52189/session/1af0c389220192e8602776ca66d14da6/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139278&tnum=29"}
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (38): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eb78640>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (39): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eb787f0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (40): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eb788e0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (41): 127.0.0.1:52189
2025-01-16 22:26:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:52189/session/1af0c389220192e8602776ca66d14da6/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=138723&tnum=22"}
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (42): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eb795d0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (43): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eb79780>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (44): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eb79870>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (45): 127.0.0.1:52189
2025-01-16 22:26:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:52189/session/1af0c389220192e8602776ca66d14da6/url {"url": "https://forum.gamer.com.tw/C.php?bsn=18966&snA=139171&tnum=26"}
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (46): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eb7a500>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (47): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eb7a6b0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (48): 127.0.0.1:52189
2025-01-16 22:26:52 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/1af0c389220192e8602776ca66d14da6/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:26:52 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eb7a7a0>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/1af0c389220192e8602776ca66d14da6/url
2025-01-16 22:26:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (49): 127.0.0.1:52189
2025-01-16 22:26:52 [scrapy.core.engine] INFO: Closing spider (shutdown)
2025-01-16 22:26:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139280&tnum=7>
Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 468, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 463, in _make_request
    httplib_response = conn.getresponse()
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1375, in getresponse
    response.begin()
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 287, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/retry.py", line 552, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/packages/six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 468, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 463, in _make_request
    httplib_response = conn.getresponse()
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1375, in getresponse
    response.begin()
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 287, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
2025-01-16 22:26:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=138031&tnum=21>
Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1283, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1329, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x10ea1fd90>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=52189): Max retries exceeded with url: /session/1af0c389220192e8602776ca66d14da6/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10ea1fd90>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 22:26:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=104740&tnum=1068>
Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1283, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1329, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x10eab4d60>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=52189): Max retries exceeded with url: /session/1af0c389220192e8602776ca66d14da6/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eab4d60>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 22:26:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139033&tnum=7>
Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1283, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1329, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x10eab5cf0>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=52189): Max retries exceeded with url: /session/1af0c389220192e8602776ca66d14da6/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eab5cf0>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 22:26:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139290&tnum=1>
Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1283, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1329, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x10eab6c80>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=52189): Max retries exceeded with url: /session/1af0c389220192e8602776ca66d14da6/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eab6c80>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 22:26:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139154&tnum=7>
Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1283, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1329, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x10eab7c10>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=52189): Max retries exceeded with url: /session/1af0c389220192e8602776ca66d14da6/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eab7c10>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 22:26:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139200&tnum=2>
Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1283, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1329, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x10eb34be0>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=52189): Max retries exceeded with url: /session/1af0c389220192e8602776ca66d14da6/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eb34be0>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 22:26:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139291&tnum=1>
Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1283, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1329, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x10eb35b70>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=52189): Max retries exceeded with url: /session/1af0c389220192e8602776ca66d14da6/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eb35b70>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 22:26:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139292&tnum=1>
Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1283, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1329, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x10eb36b00>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=52189): Max retries exceeded with url: /session/1af0c389220192e8602776ca66d14da6/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eb36b00>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 22:26:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139293&tnum=1>
Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1283, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1329, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x10eb37a90>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=52189): Max retries exceeded with url: /session/1af0c389220192e8602776ca66d14da6/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eb37a90>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 22:26:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139278&tnum=29>
Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1283, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1329, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x10eb78a60>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=52189): Max retries exceeded with url: /session/1af0c389220192e8602776ca66d14da6/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eb78a60>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 22:26:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=138723&tnum=22>
Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1283, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1329, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x10eb799f0>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=52189): Max retries exceeded with url: /session/1af0c389220192e8602776ca66d14da6/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eb799f0>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 22:26:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/C.php?bsn=18966&snA=139171&tnum=26>
Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 416, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 244, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1283, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1329, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x10eb7a920>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 830, in urlopen
    return self.urlopen(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/retry.py", line 594, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=52189): Max retries exceeded with url: /session/1af0c389220192e8602776ca66d14da6/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10eb7a920>: Failed to establish a new connection: [Errno 61] Connection refused'))
2025-01-16 22:26:52 [scrapy.crawler] INFO: Received SIGINT twice, forcing unclean shutdown
2025-01-16 22:27:39 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: example)
2025-01-16 22:27:39 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.11.0, Python 3.10.16 (main, Jan 16 2025, 13:43:45) [Clang 13.1.6 (clang-1316.0.21.2.5)], pyOpenSSL 25.0.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform macOS-12.2.1-x86_64-i386-64bit
2025-01-16 22:27:39 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-16 22:27:39 [asyncio] DEBUG: Using selector: KqueueSelector
2025-01-16 22:27:39 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-16 22:27:39 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-16 22:27:39 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-01-16 22:27:39 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2025-01-16 22:27:39 [scrapy.extensions.telnet] INFO: Telnet Password: aa6d1e53f612fc99
2025-01-16 22:27:39 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-01-16 22:27:39 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'example',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': '../log/example.log',
 'NEWSPIDER_MODULE': 'example.spiders',
 'SPIDER_MODULES': ['example.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-16 22:27:40 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:52299/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "platformName": "any", "goog:chromeOptions": {"extensions": [], "args": ["--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "version": "", "platform": "ANY", "goog:chromeOptions": {"extensions": [], "args": ["--headless"]}}}
2025-01-16 22:27:40 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:52299
2025-01-16 22:27:45 [urllib3.connectionpool] DEBUG: http://127.0.0.1:52299 "POST /session HTTP/1.1" 200 892
2025-01-16 22:27:45 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2025-01-16 22:27:45 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy_selenium.SeleniumMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-16 22:27:45 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-16 22:27:45 [scrapy.middleware] INFO: Enabled item pipelines:
['example.pipelines.ExamplePipeline', 'example.pipelines.ExampleDownloadImg']
2025-01-16 22:27:45 [scrapy.core.engine] INFO: Spider opened
2025-01-16 22:27:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-16 22:27:45 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-01-16 22:27:45 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:52299/session/26866853e95105910a827325666d3a13/url {"url": "https://forum.gamer.com.tw/B.php?page=1&bsn=18966"}
2025-01-16 22:28:00 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2025-01-16 22:28:00 [scrapy.core.engine] INFO: Closing spider (shutdown)
2025-01-16 22:28:00 [scrapy.core.scraper] ERROR: Error downloading <GET https://forum.gamer.com.tw/B.php?page=1&bsn=18966>
Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 468, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 463, in _make_request
    httplib_response = conn.getresponse()
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1375, in getresponse
    response.begin()
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 287, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy/core/downloader/middleware.py", line 57, in process_request
    method(request=request, spider=spider)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/scrapy_selenium/middlewares.py", line 84, in process_request
    self.driver.get(request.url)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py", line 374, in execute
    return self._request(command_info[0], url, body=data)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py", line 397, in _request
    resp = self._conn.request(method, url, body=body, headers=headers)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/request.py", line 81, in request
    return self.request_encode_body(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/request.py", line 173, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 802, in urlopen
    retries = retries.increment(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/util/retry.py", line 552, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/packages/six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 716, in urlopen
    httplib_response = self._make_request(
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 468, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "/Users/sai/PycharmProjects/WebCrawler/venv/lib/python3.10/site-packages/urllib3/connectionpool.py", line 463, in _make_request
    httplib_response = conn.getresponse()
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 1375, in getresponse
    response.begin()
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "/usr/local/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py", line 287, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
2025-01-16 22:28:00 [selenium.webdriver.remote.remote_connection] DEBUG: DELETE http://127.0.0.1:52299/session/26866853e95105910a827325666d3a13 {}
2025-01-16 22:28:00 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (2): 127.0.0.1:52299
2025-01-16 22:28:00 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/26866853e95105910a827325666d3a13'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:28:00 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10ee5a560>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/26866853e95105910a827325666d3a13
2025-01-16 22:28:00 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (3): 127.0.0.1:52299
2025-01-16 22:28:00 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/26866853e95105910a827325666d3a13'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:28:00 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10ee5aa40>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/26866853e95105910a827325666d3a13
2025-01-16 22:28:00 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (4): 127.0.0.1:52299
2025-01-16 22:28:00 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/26866853e95105910a827325666d3a13'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2025-01-16 22:28:00 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10ee5ac50>: Failed to establish a new connection: [Errno 61] Connection refused')': /session/26866853e95105910a827325666d3a13
2025-01-16 22:28:00 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (5): 127.0.0.1:52299
2025-01-16 22:28:00 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 1,
 'downloader/exception_type_count/urllib3.exceptions.ProtocolError': 1,
 'elapsed_time_seconds': 15.237893,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2025, 1, 16, 14, 28, 0, 354141, tzinfo=datetime.timezone.utc),
 'items_per_minute': None,
 'log_count/DEBUG': 18,
 'log_count/ERROR': 1,
 'log_count/INFO': 11,
 'log_count/WARNING': 3,
 'memusage/max': 60080128,
 'memusage/startup': 60080128,
 'responses_per_minute': None,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2025, 1, 16, 14, 27, 45, 116248, tzinfo=datetime.timezone.utc)}
2025-01-16 22:28:00 [scrapy.core.engine] INFO: Spider closed (shutdown)
